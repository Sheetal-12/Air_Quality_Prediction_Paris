{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"traindata_imputed.csv\"   # update if needed\n",
    "TEST_PATH  = \"testdata_preprocessed.csv\"\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# LOAD\n",
    "# -----------------------------\n",
    "df_tr = pd.read_csv(TRAIN_PATH)\n",
    "df_te = pd.read_csv(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\n",
    "    \"valeur_CO_was_missing\",\n",
    "    \"valeur_NO2_was_missing\",\n",
    "    \"valeur_O3_was_missing\",\n",
    "    \"valeur_PM10_was_missing\",\n",
    "    \"valeur_PM25_was_missing\"\n",
    "]\n",
    "\n",
    "df_tr = df_tr.drop(columns=cols_to_drop, errors=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>valeur_NO2</th>\n",
       "      <th>valeur_CO</th>\n",
       "      <th>valeur_O3</th>\n",
       "      <th>valeur_PM10</th>\n",
       "      <th>valeur_PM25</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>relative_humidity_2m</th>\n",
       "      <th>...</th>\n",
       "      <th>et0_fao_evapotranspiration</th>\n",
       "      <th>snowfall</th>\n",
       "      <th>rain</th>\n",
       "      <th>showers</th>\n",
       "      <th>weather_code</th>\n",
       "      <th>lockdown_code</th>\n",
       "      <th>datetime</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01 00</td>\n",
       "      <td>42.9</td>\n",
       "      <td>0.7180</td>\n",
       "      <td>15.7</td>\n",
       "      <td>73.1</td>\n",
       "      <td>64.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01 01</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.5870</td>\n",
       "      <td>10.1</td>\n",
       "      <td>74.8</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01 02</td>\n",
       "      <td>29.3</td>\n",
       "      <td>0.4165</td>\n",
       "      <td>5.1</td>\n",
       "      <td>51.0</td>\n",
       "      <td>44.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>98</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-01 02:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01 03</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.2460</td>\n",
       "      <td>7.2</td>\n",
       "      <td>27.7</td>\n",
       "      <td>25.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-01 03:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  valeur_NO2  valeur_CO  valeur_O3  valeur_PM10  valeur_PM25  \\\n",
       "0  2020-01-01 00        42.9     0.7180       15.7         73.1         64.4   \n",
       "1  2020-01-01 01        33.6     0.5870       10.1         74.8         66.0   \n",
       "2  2020-01-01 02        29.3     0.4165        5.1         51.0         44.9   \n",
       "3  2020-01-01 03        30.5     0.2460        7.2         27.7         25.1   \n",
       "\n",
       "   is_holiday  is_weekend  temperature_2m  relative_humidity_2m  ...  \\\n",
       "0           1           0             0.9                   100  ...   \n",
       "1           1           0            -0.1                    99  ...   \n",
       "2           1           0             2.6                    98  ...   \n",
       "3           1           0             2.1                   100  ...   \n",
       "\n",
       "   et0_fao_evapotranspiration  snowfall  rain  showers  weather_code  \\\n",
       "0                         0.0       0.0   0.0      0.0             3   \n",
       "1                         0.0       0.0   0.0      0.0             3   \n",
       "2                         0.0       0.0   0.0      0.0             3   \n",
       "3                         0.0       0.0   0.0      0.0             3   \n",
       "\n",
       "   lockdown_code             datetime  hour  dayofweek  month  \n",
       "0              0  2020-01-01 00:00:00     0          2      1  \n",
       "1              0  2020-01-01 01:00:00     1          2      1  \n",
       "2              0  2020-01-01 02:00:00     2          2      1  \n",
       "3              0  2020-01-01 03:00:00     3          2      1  \n",
       "\n",
       "[4 rows x 36 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tr.head(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "TIME = \"datetime\"\n",
    "RAW_ID = \"id\"  # use if it repeats; else fallback to single group \"__grp__\"\n",
    "\n",
    "TARGETS = [\"valeur_NO2\",\"valeur_CO\",\"valeur_O3\",\"valeur_PM10\",\"valeur_PM25\"]\n",
    "\n",
    "# treat these as STATIC (known ahead), so: keep raw, NO lags/roll, NO masking\n",
    "STATIC_KNOWN = [\"is_holiday\",\"is_weekend\",\"lockdown_code\"]\n",
    "\n",
    "# your weather candidates (we will REMOVE STATIC_KNOWN & non-existent ones)\n",
    "WEATHER_CANDIDATES = [\n",
    "    'temperature_2m','relative_humidity_2m','dew_point_2m','apparent_temperature',\n",
    "    'pressure_msl','wind_speed_10m','wind_direction_10m','precipitation',\n",
    "    'cloud_cover','cloud_cover_low','cloud_cover_mid','cloud_cover_high',\n",
    "    'shortwave_radiation','direct_radiation','diffuse_radiation','global_tilted_irradiance',\n",
    "    'wind_speed_80m','wind_speed_120m','wind_speed_180m',\n",
    "    'wind_direction_80m','wind_direction_120m','wind_direction_180m',\n",
    "    'wind_gusts_10m','vapour_pressure_deficit','cape','evapotranspiration',\n",
    "    'et0_fao_evapotranspiration','snowfall','rain','showers',\n",
    "    'weather_code',   # categorical-like; we won't roll std on it\n",
    "    'visibility'\n",
    "]\n",
    "\n",
    "# lags/rolls (add 24h lag to reduce early-NaNs on forecast)\n",
    "LAGS  = [6, 12, 24]\n",
    "ROLLS = [6, 24]   # hours\n",
    "\n",
    "def build_dataset(df_tr: pd.DataFrame, df_te: pd.DataFrame):\n",
    "    # --- union ---\n",
    "    df_tr = df_tr.copy(); df_te = df_te.copy()\n",
    "    df_tr[TIME] = pd.to_datetime(df_tr[TIME]); df_te[TIME] = pd.to_datetime(df_te[TIME])\n",
    "    df_tr[\"__split__\"] = \"train\"; df_te[\"__split__\"] = \"test\"\n",
    "    df = pd.concat([df_tr, df_te], ignore_index=True).sort_values([TIME]).reset_index(drop=True)\n",
    "\n",
    "    # --- pick group key (per-station or single group) ---\n",
    "    use_id = RAW_ID if RAW_ID in df.columns else None\n",
    "    if use_id is not None and df[RAW_ID].nunique() == len(df):\n",
    "        use_id = None\n",
    "    if use_id is None:\n",
    "        df[\"__grp__\"] = \"all\"; GROUP = \"__grp__\"\n",
    "    else:\n",
    "        GROUP = RAW_ID\n",
    "        df[GROUP] = df[GROUP].astype(str).str.strip()\n",
    "\n",
    "    # --- build time features early ---\n",
    "    df[\"hour\"] = df[TIME].dt.hour\n",
    "    df[\"is_day\"] = ((df[\"hour\"] >= 6) & (df[\"hour\"] < 18)).astype(int)\n",
    "    df[\"hour_sin\"] = np.sin(2*np.pi*df[\"hour\"]/24)\n",
    "    df[\"hour_cos\"] = np.cos(2*np.pi*df[\"hour\"]/24)\n",
    "    df[\"dow\"] = df[TIME].dt.dayofweek\n",
    "    df[\"dow_sin\"] = np.sin(2*np.pi*df[\"dow\"]/7)\n",
    "    df[\"dow_cos\"] = np.cos(2*np.pi*df[\"dow\"]/7)\n",
    "\n",
    "    # --- choose real weather columns (exclude STATIC_KNOWN) ---\n",
    "    weather_cols = [c for c in WEATHER_CANDIDATES if c in df.columns and c not in STATIC_KNOWN]\n",
    "\n",
    "    # --- mark future test horizon (first row per group with ANY target NaN) ---\n",
    "    te = df[df[\"__split__\"] == \"test\"]\n",
    "    if len(te):\n",
    "        tmp = te.copy()\n",
    "        tmp[\"_nan_any\"] = tmp[TARGETS].isna().any(axis=1)\n",
    "        first_future = (tmp[tmp[\"_nan_any\"]].groupby(GROUP, as_index=True)[TIME].min())\n",
    "        df = df.join(first_future.rename(\"__future_start__\"), on=GROUP)\n",
    "        df[\"__is_future_test__\"] = (df[\"__split__\"]==\"test\") & df[\"__future_start__\"].notna() & (df[TIME] >= df[\"__future_start__\"])\n",
    "        df.drop(columns=\"__future_start__\", inplace=True)\n",
    "    else:\n",
    "        df[\"__is_future_test__\"] = False\n",
    "\n",
    "    # --- MASK ONLY true weather on future test rows (rule).\n",
    "    # DO NOT mask static known cols.\n",
    "    if weather_cols:\n",
    "        df.loc[df[\"__is_future_test__\"], weather_cols] = np.nan\n",
    "\n",
    "    # --- feature assembly into dict (avoid fragmentation) ---\n",
    "    feats = {}\n",
    "    def add_feat(name, series): feats[name] = series\n",
    "\n",
    "    # POLLUTANTS: lags/rolls (past-only)\n",
    "    for col in TARGETS:\n",
    "        g = df.groupby(GROUP)[col]\n",
    "        for l in LAGS:\n",
    "            add_feat(f\"{col}_lag_{l}\", g.shift(l))\n",
    "        s = g.shift(1)\n",
    "        for w in ROLLS:\n",
    "            add_feat(f\"{col}_roll_mean_{w}\", s.groupby(df[GROUP]).rolling(w, min_periods=1).mean().reset_index(level=0, drop=True))\n",
    "            add_feat(f\"{col}_roll_std_{w}\",  s.groupby(df[GROUP]).rolling(w, min_periods=2).std().reset_index(level=0, drop=True))\n",
    "\n",
    "    # Cross-lags (examples)\n",
    "    add_feat(\"NO2_lag1_for_O3\", df.groupby(GROUP)[\"valeur_NO2\"].shift(1))\n",
    "    add_feat(\"PM10_lag1_for_PM25\", df.groupby(GROUP)[\"valeur_PM10\"].shift(1))\n",
    "\n",
    "    # WEATHER: lags/rolls (past-only), but skip std for categorical-like\n",
    "    for col in weather_cols:\n",
    "        g = df.groupby(GROUP)[col]\n",
    "        for l in LAGS:\n",
    "            add_feat(f\"{col}_lag_{l}\", g.shift(l))\n",
    "        s = g.shift(1)\n",
    "        for w in ROLLS:\n",
    "            add_feat(f\"{col}_roll_mean_{w}\", s.groupby(df[GROUP]).rolling(w, min_periods=1).mean().reset_index(level=0, drop=True))\n",
    "            if pd.api.types.is_numeric_dtype(df[col]) and col != \"weather_code\":\n",
    "                add_feat(f\"{col}_roll_std_{w}\",  s.groupby(df[GROUP]).rolling(w, min_periods=2).std().reset_index(level=0, drop=True))\n",
    "\n",
    "    # build features dataframe once\n",
    "    feat_df = pd.DataFrame(feats, index=df.index)\n",
    "\n",
    "    # base (calendar + static known, as raw flags)\n",
    "    base_cols = [\"hour\",\"is_day\",\"hour_sin\",\"hour_cos\",\"dow\",\"dow_sin\",\"dow_cos\"] + [c for c in STATIC_KNOWN if c in df.columns]\n",
    "    X_all = pd.concat([feat_df, df[base_cols]], axis=1)\n",
    "\n",
    "    # --- Impute features (per-group ffill -> train medians; std->0) ---\n",
    "    X_all = X_all.groupby(df[GROUP]).ffill()\n",
    "\n",
    "    # train medians computed on train rows only\n",
    "    train_meds = X_all[df[\"__split__\"]==\"train\"].median(numeric_only=True)\n",
    "    X_all = X_all.fillna(train_meds)\n",
    "\n",
    "    # remaining std NaNs to 0\n",
    "    std_cols = [c for c in X_all.columns if \"_roll_std_\" in c]\n",
    "    if std_cols:\n",
    "        X_all[std_cols] = X_all[std_cols].fillna(0.0)\n",
    "\n",
    "    # --- outputs ---\n",
    "    feat_cols = list(X_all.columns)\n",
    "    meta = df[[GROUP, TIME, \"__split__\", \"__is_future_test__\"]].copy()\n",
    "    Y_all = df[TARGETS].copy()\n",
    "\n",
    "    X_train = X_all[meta[\"__split__\"]==\"train\"].reset_index(drop=True)\n",
    "    Y_train = Y_all[meta[\"__split__\"]==\"train\"].reset_index(drop=True)\n",
    "\n",
    "    mask_pred = (meta[\"__split__\"]==\"test\") & (meta[\"__is_future_test__\"])\n",
    "    X_test_pred = X_all[mask_pred].reset_index(drop=True)\n",
    "    meta_test = df.loc[mask_pred, [GROUP, TIME]].rename(columns={GROUP:\"id\"}).reset_index(drop=True)\n",
    "\n",
    "    print(f\"Groups used: {GROUP} ({df[GROUP].nunique()} unique)\")\n",
    "    print(\"X_train:\", X_train.shape, \"| Y_train:\", Y_train.shape)\n",
    "    print(\"X_test_pred:\", X_test_pred.shape, \"| meta_test:\", meta_test.shape)\n",
    "    print(\"Num features:\", len(feat_cols))\n",
    "\n",
    "    return X_train, Y_train, X_test_pred, meta_test, feat_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groups used: __grp__ (1 unique)\n",
      "X_train: (40991, 206) | Y_train: (40991, 5)\n",
      "X_test_pred: (504, 206) | meta_test: (504, 2)\n",
      "Num features: 206\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test_pred, meta_test, feat_cols = build_dataset(df_tr, df_te)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pred[\"id\"]=df_te[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved train_features.csv and test_features_to_predict.csv\n"
     ]
    }
   ],
   "source": [
    "# 1) Rebuild meta_train\n",
    "meta_train = df_tr[[RAW_ID, TIME]].copy()  # original train metadata\n",
    "meta_train = meta_train.reset_index(drop=True)\n",
    "\n",
    "# 2) Build full train dataset (X + Y + metadata)\n",
    "train_full = X_train.copy()\n",
    "for tgt in TARGETS:\n",
    "    train_full[tgt] = Y_train[tgt].values\n",
    "\n",
    "train_full[\"id\"] = meta_train[RAW_ID].values\n",
    "train_full[\"datetime\"] = meta_train[TIME].values\n",
    "\n",
    "# 3) Build full test dataset (X_test_pred + meta_test)\n",
    "test_full = X_test_pred.copy()\n",
    "# test_full[\"id\"] = meta_test[\"id\"].values\n",
    "test_full[\"datetime\"] = meta_test[\"datetime\"].values\n",
    "\n",
    "# 4) Save to CSV\n",
    "train_full.to_csv(\"train_features.csv\", index=False)\n",
    "test_full.to_csv(\"test_features_to_predict.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Saved train_features.csv and test_features_to_predict.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nandana_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
