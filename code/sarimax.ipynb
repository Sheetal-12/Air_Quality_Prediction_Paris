{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f661036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING AND PREPARING DATA\n",
      "======================================================================\n",
      "\n",
      "âœ“ Loaded train: (40991, 213)\n",
      "âœ“ Loaded test: (504, 208)\n",
      "\n",
      "Feature breakdown:\n",
      "  - Lag/Roll features in data: 194\n",
      "  - Temporal features: 10\n",
      "\n",
      "======================================================================\n",
      "FEATURE STRATEGY: temporal_only\n",
      "======================================================================\n",
      "\n",
      "Example features for valeur_NO2: 10 features\n",
      "  - Temporal: 10\n",
      "  - Weather: 0\n",
      "  - Cross-pollutant: 0\n",
      "\n",
      "Feature list:\n",
      "    hour\n",
      "    is_day\n",
      "    hour_sin\n",
      "    hour_cos\n",
      "    dow\n",
      "    dow_sin\n",
      "    dow_cos\n",
      "    is_holiday\n",
      "    is_weekend\n",
      "    lockdown_code\n",
      "\n",
      "âœ“ Train samples after removing NaNs: 40991\n",
      "\n",
      "======================================================================\n",
      "TRAINING MODELS FOR ALL POLLUTANTS\n",
      "======================================================================\n",
      "\n",
      "[1/5] Processing valeur_NO2...\n",
      "\n",
      "======================================================================\n",
      "TRAINING SARIMAX FOR valeur_NO2\n",
      "======================================================================\n",
      "\n",
      "âœ“ Created 3 CV splits:\n",
      "  Fold 1: Train=24595, Val=8198\n",
      "  Fold 2: Train=28694, Val=8198\n",
      "  Fold 3: Train=32793, Val=8198\n",
      "\n",
      "--- Fold 1/3 ---\n",
      "  RMSE: 15.5591 | MAE: 13.0544 | RÂ²: -0.1726\n",
      "\n",
      "--- Fold 2/3 ---\n",
      "  RMSE: 14.4749 | MAE: 10.5844 | RÂ²: 0.0061\n",
      "\n",
      "--- Fold 3/3 ---\n",
      "  RMSE: 16.6503 | MAE: 14.4529 | RÂ²: -0.4749\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "CV Summary for valeur_NO2:\n",
      " fold      rmse       mae        r2\n",
      "    1 15.559149 13.054439 -0.172557\n",
      "    2 14.474909 10.584416  0.006091\n",
      "    3 16.650277 14.452946 -0.474856\n",
      "\n",
      "Mean RMSE: 15.5614 (Â± 1.0877)\n",
      "Mean MAE:  12.6973 (Â± 1.9588)\n",
      "Mean RÂ²:   -0.2138 (Â± 0.2431)\n",
      "\n",
      "ðŸ”§ Training final model on full training set...\n",
      "âœ“ Final model trained\n",
      "âœ“ valeur_NO2 model trained successfully\n",
      "\n",
      "[2/5] Processing valeur_CO...\n",
      "\n",
      "======================================================================\n",
      "TRAINING SARIMAX FOR valeur_CO\n",
      "======================================================================\n",
      "\n",
      "âœ“ Created 3 CV splits:\n",
      "  Fold 1: Train=24595, Val=8198\n",
      "  Fold 2: Train=28694, Val=8198\n",
      "  Fold 3: Train=32793, Val=8198\n",
      "\n",
      "--- Fold 1/3 ---\n",
      "  RMSE: 0.1106 | MAE: 0.0608 | RÂ²: -0.1916\n",
      "\n",
      "--- Fold 2/3 ---\n",
      "  RMSE: 0.0985 | MAE: 0.0644 | RÂ²: -0.0026\n",
      "\n",
      "--- Fold 3/3 ---\n",
      "  RMSE: 0.1106 | MAE: 0.0752 | RÂ²: -0.0625\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "CV Summary for valeur_CO:\n",
      " fold     rmse      mae        r2\n",
      "    1 0.110608 0.060778 -0.191564\n",
      "    2 0.098459 0.064383 -0.002593\n",
      "    3 0.110590 0.075192 -0.062522\n",
      "\n",
      "Mean RMSE: 0.1066 (Â± 0.0070)\n",
      "Mean MAE:  0.0668 (Â± 0.0075)\n",
      "Mean RÂ²:   -0.0856 (Â± 0.0966)\n",
      "\n",
      "ðŸ”§ Training final model on full training set...\n",
      "âœ“ Final model trained\n",
      "âœ“ valeur_CO model trained successfully\n",
      "\n",
      "[3/5] Processing valeur_O3...\n",
      "\n",
      "======================================================================\n",
      "TRAINING SARIMAX FOR valeur_O3\n",
      "======================================================================\n",
      "\n",
      "âœ“ Created 3 CV splits:\n",
      "  Fold 1: Train=24595, Val=8198\n",
      "  Fold 2: Train=28694, Val=8198\n",
      "  Fold 3: Train=32793, Val=8198\n",
      "\n",
      "--- Fold 1/3 ---\n",
      "  RMSE: 36.6999 | MAE: 30.7132 | RÂ²: -0.8146\n",
      "\n",
      "--- Fold 2/3 ---\n",
      "  RMSE: 25.8017 | MAE: 19.9800 | RÂ²: -0.0141\n",
      "\n",
      "--- Fold 3/3 ---\n",
      "  RMSE: 22.4993 | MAE: 18.2629 | RÂ²: 0.0267\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "CV Summary for valeur_O3:\n",
      " fold      rmse       mae        r2\n",
      "    1 36.699874 30.713206 -0.814618\n",
      "    2 25.801672 19.979966 -0.014148\n",
      "    3 22.499323 18.262938  0.026657\n",
      "\n",
      "Mean RMSE: 28.3336 (Â± 7.4312)\n",
      "Mean MAE:  22.9854 (Â± 6.7473)\n",
      "Mean RÂ²:   -0.2674 (Â± 0.4744)\n",
      "\n",
      "ðŸ”§ Training final model on full training set...\n",
      "âœ“ Final model trained\n",
      "âœ“ valeur_O3 model trained successfully\n",
      "\n",
      "[4/5] Processing valeur_PM10...\n",
      "\n",
      "======================================================================\n",
      "TRAINING SARIMAX FOR valeur_PM10\n",
      "======================================================================\n",
      "\n",
      "âœ“ Created 3 CV splits:\n",
      "  Fold 1: Train=24595, Val=8198\n",
      "  Fold 2: Train=28694, Val=8198\n",
      "  Fold 3: Train=32793, Val=8198\n",
      "\n",
      "--- Fold 1/3 ---\n",
      "  RMSE: 9.8771 | MAE: 6.7536 | RÂ²: 0.0203\n",
      "\n",
      "--- Fold 2/3 ---\n",
      "  RMSE: 8.3895 | MAE: 6.3336 | RÂ²: -0.0019\n",
      "\n",
      "--- Fold 3/3 ---\n",
      "  RMSE: 10.4008 | MAE: 8.8826 | RÂ²: -0.6790\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "CV Summary for valeur_PM10:\n",
      " fold      rmse      mae        r2\n",
      "    1  9.877052 6.753583  0.020338\n",
      "    2  8.389533 6.333587 -0.001921\n",
      "    3 10.400779 8.882622 -0.679045\n",
      "\n",
      "Mean RMSE: 9.5558 (Â± 1.0434)\n",
      "Mean MAE:  7.3233 (Â± 1.3667)\n",
      "Mean RÂ²:   -0.2202 (Â± 0.3975)\n",
      "\n",
      "ðŸ”§ Training final model on full training set...\n",
      "âœ“ Final model trained\n",
      "âœ“ valeur_PM10 model trained successfully\n",
      "\n",
      "[5/5] Processing valeur_PM25...\n",
      "\n",
      "======================================================================\n",
      "TRAINING SARIMAX FOR valeur_PM25\n",
      "======================================================================\n",
      "\n",
      "âœ“ Created 3 CV splits:\n",
      "  Fold 1: Train=24595, Val=8198\n",
      "  Fold 2: Train=28694, Val=8198\n",
      "  Fold 3: Train=32793, Val=8198\n",
      "\n",
      "--- Fold 1/3 ---\n",
      "  RMSE: 8.4618 | MAE: 5.6002 | RÂ²: -0.0389\n",
      "\n",
      "--- Fold 2/3 ---\n",
      "  RMSE: 6.9146 | MAE: 5.6841 | RÂ²: -0.1488\n",
      "\n",
      "--- Fold 3/3 ---\n",
      "  RMSE: 6.0294 | MAE: 4.6057 | RÂ²: -0.0215\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "CV Summary for valeur_PM25:\n",
      " fold     rmse      mae        r2\n",
      "    1 8.461752 5.600164 -0.038858\n",
      "    2 6.914582 5.684145 -0.148847\n",
      "    3 6.029398 4.605743 -0.021467\n",
      "\n",
      "Mean RMSE: 7.1352 (Â± 1.2311)\n",
      "Mean MAE:  5.2967 (Â± 0.5998)\n",
      "Mean RÂ²:   -0.0697 (Â± 0.0691)\n",
      "\n",
      "ðŸ”§ Training final model on full training set...\n",
      "âœ“ Final model trained\n",
      "âœ“ valeur_PM25 model trained successfully\n",
      "\n",
      "======================================================================\n",
      "Training Complete: 5/5 models successful\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "PREPARING TEST DATA\n",
      "======================================================================\n",
      "\n",
      "âœ“ Using last 24 rows of train for lag/roll feature averaging\n",
      "\n",
      "Preparing test features for valeur_NO2...\n",
      "  âœ“ Shape: (504, 10)\n",
      "\n",
      "Preparing test features for valeur_CO...\n",
      "  âœ“ Shape: (504, 10)\n",
      "\n",
      "Preparing test features for valeur_O3...\n",
      "  âœ“ Shape: (504, 10)\n",
      "\n",
      "Preparing test features for valeur_PM10...\n",
      "  âœ“ Shape: (504, 10)\n",
      "\n",
      "Preparing test features for valeur_PM25...\n",
      "  âœ“ Shape: (504, 10)\n",
      "\n",
      "======================================================================\n",
      "GENERATING PREDICTIONS FOR TEST SET\n",
      "======================================================================\n",
      "\n",
      "ðŸ”® Predicting valeur_NO2...\n",
      "  âœ“ Predicted valeur_NO2\n",
      "    Range: [13.98, 20.18]\n",
      "    Mean: 17.43\n",
      "\n",
      "ðŸ”® Predicting valeur_CO...\n",
      "  âœ“ Predicted valeur_CO\n",
      "    Range: [0.17, 0.21]\n",
      "    Mean: 0.18\n",
      "\n",
      "ðŸ”® Predicting valeur_O3...\n",
      "  âœ“ Predicted valeur_O3\n",
      "    Range: [38.82, 65.28]\n",
      "    Mean: 51.94\n",
      "\n",
      "ðŸ”® Predicting valeur_PM10...\n",
      "  âœ“ Predicted valeur_PM10\n",
      "    Range: [8.26, 14.39]\n",
      "    Mean: 12.07\n",
      "\n",
      "ðŸ”® Predicting valeur_PM25...\n",
      "  âœ“ Predicted valeur_PM25\n",
      "    Range: [4.59, 6.65]\n",
      "    Mean: 6.29\n",
      "\n",
      "======================================================================\n",
      "SAVING RESULTS\n",
      "======================================================================\n",
      "\n",
      "âœ“ Submission saved as 'submission.csv'\n",
      "  Shape: (504, 5)\n",
      "\n",
      "First few predictions:\n",
      "   valeur_NO2  valeur_CO  valeur_O3  valeur_PM10  valeur_PM25\n",
      "0         NaN        NaN        NaN          NaN          NaN\n",
      "1         NaN        NaN        NaN          NaN          NaN\n",
      "2         NaN        NaN        NaN          NaN          NaN\n",
      "3         NaN        NaN        NaN          NaN          NaN\n",
      "4         NaN        NaN        NaN          NaN          NaN\n",
      "5         NaN        NaN        NaN          NaN          NaN\n",
      "6         NaN        NaN        NaN          NaN          NaN\n",
      "7         NaN        NaN        NaN          NaN          NaN\n",
      "8         NaN        NaN        NaN          NaN          NaN\n",
      "9         NaN        NaN        NaN          NaN          NaN\n",
      "\n",
      "âœ“ CV scores saved as 'cv_scores_summary.csv'\n",
      "\n",
      "Cross-Validation Summary:\n",
      "     target  mean_rmse  std_rmse  mean_mae  std_mae   mean_r2   std_r2\n",
      " valeur_NO2  15.561445  1.087686 12.697267 1.958841 -0.213774 0.243108\n",
      "  valeur_CO   0.106553  0.007009  0.066784 0.007501 -0.085560 0.096569\n",
      "  valeur_O3  28.333623  7.431151 22.985370 6.747343 -0.267370 0.474370\n",
      "valeur_PM10   9.555788  1.043401  7.323264 1.366674 -0.220209 0.397519\n",
      "valeur_PM25   7.135244  1.231099  5.296684 0.599844 -0.069724 0.069072\n",
      "\n",
      "======================================================================\n",
      "PIPELINE COMPLETE!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "TARGETS = ['valeur_NO2', 'valeur_CO', 'valeur_O3', 'valeur_PM10', 'valeur_PM25']\n",
    "TEMPORAL_FEATURES = ['hour', 'is_day', 'hour_sin', 'hour_cos', 'dow', 'dow_sin',\n",
    "                     'dow_cos', 'is_holiday', 'is_weekend', 'lockdown_code']\n",
    "LAGS = [6, 12, 24]\n",
    "\n",
    "DATE_COL = 'date'  # Adjust to your actual datetime column name\n",
    "\n",
    "# Cross-validation settings\n",
    "N_SPLITS = 3\n",
    "TEST_SIZE_RATIO = 0.2\n",
    "\n",
    "FEATURE_STRATEGY = 'temporal_only'\n",
    "\n",
    "# SARIMAX parameters - adjust based on your data\n",
    "# For hourly data with daily patterns: s=24\n",
    "# For daily data with weekly patterns: s=7\n",
    "SARIMAX_ORDER = (2, 1, 2)  # Increase p,q to compensate\n",
    "SARIMAX_SEASONAL_ORDER = (0, 0, 0, 0)  # No seasonality\n",
    "MAX_ITER = 100\n",
    "\n",
    "# =============================================================================\n",
    "# LOAD AND PREPARE DATA\n",
    "# =============================================================================\n",
    "print(\"=\"*70)\n",
    "print(\"LOADING AND PREPARING DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "train_df = pd.read_csv(\"../data/train_features.csv\")\n",
    "test_df = pd.read_csv(\"../data/test_features_to_predict.csv\")\n",
    "\n",
    "print(f\"\\nâœ“ Loaded train: {train_df.shape}\")\n",
    "print(f\"âœ“ Loaded test: {test_df.shape}\")\n",
    "\n",
    "# Convert date column if it exists\n",
    "if DATE_COL in train_df.columns:\n",
    "    train_df[DATE_COL] = pd.to_datetime(train_df[DATE_COL])\n",
    "    train_df = train_df.sort_values(DATE_COL).reset_index(drop=True)\n",
    "\n",
    "if DATE_COL in test_df.columns:\n",
    "    test_df[DATE_COL] = pd.to_datetime(test_df[DATE_COL])\n",
    "    test_df = test_df.sort_values(DATE_COL).reset_index(drop=True)\n",
    "\n",
    "# Identify all lag/roll columns\n",
    "all_cols = train_df.columns.tolist()\n",
    "lag_roll_cols = [c for c in all_cols if 'lag_' in c or 'roll_' in c]\n",
    "feature_cols = lag_roll_cols + TEMPORAL_FEATURES\n",
    "\n",
    "print(f\"\\nFeature breakdown:\")\n",
    "print(f\"  - Lag/Roll features in data: {len(lag_roll_cols)}\")\n",
    "print(f\"  - Temporal features: {len(TEMPORAL_FEATURES)}\")\n",
    "\n",
    "# =============================================================================\n",
    "# SMART FEATURE SELECTION FOR SARIMAX\n",
    "# =============================================================================\n",
    "def get_cross_pollutant_features(target_col):\n",
    "    \"\"\"\n",
    "    Get rolling means of OTHER pollutants (not the target being predicted).\n",
    "    Only keep rolling means, not lags (SARIMAX handles lags internally).\n",
    "    \"\"\"\n",
    "    target_name = target_col.replace('valeur_', '')\n",
    "\n",
    "    # All pollutants except current target\n",
    "    other_pollutants = [p for p in ['NO2', 'CO', 'O3', 'PM10', 'PM25']\n",
    "                        if p != target_name]\n",
    "\n",
    "    # Only rolling means (more stable than lags, captures smoothed relationships)\n",
    "    cross_features = []\n",
    "    for pollutant in other_pollutants:\n",
    "        cross_features.extend([\n",
    "            f'valeur_{pollutant}_roll_mean_6',\n",
    "            f'valeur_{pollutant}_roll_mean_24'\n",
    "        ])\n",
    "\n",
    "    return cross_features\n",
    "\n",
    "def prepare_features_for_target(df, target_col, strategy='optimized'):\n",
    "    \"\"\"\n",
    "    Prepare optimized feature set for SARIMAX based on strategy.\n",
    "\n",
    "    Strategies:\n",
    "    - 'temporal_only': Just temporal features (fastest, cleanest)\n",
    "    - 'optimized': Temporal + current weather + cross-pollutant rolling means\n",
    "    - 'all': All lag/roll features (not recommended for SARIMAX)\n",
    "    \"\"\"\n",
    "    if strategy == 'temporal_only':\n",
    "        features = TEMPORAL_FEATURES.copy()\n",
    "\n",
    "    elif strategy == 'optimized':\n",
    "        features = TEMPORAL_FEATURES.copy()\n",
    "\n",
    "        # Add current weather if available\n",
    "        weather_available = [w for w in WEATHER_CURRENT if w in df.columns]\n",
    "        features.extend(weather_available)\n",
    "\n",
    "        # Add cross-pollutant rolling means\n",
    "        cross_features = get_cross_pollutant_features(target_col)\n",
    "        cross_available = [f for f in cross_features if f in df.columns]\n",
    "        features.extend(cross_available)\n",
    "\n",
    "    elif strategy == 'all':\n",
    "        # Use all lag/roll features (original approach)\n",
    "        features = lag_roll_cols + TEMPORAL_FEATURES\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown strategy: {strategy}\")\n",
    "\n",
    "    # Filter to only available columns\n",
    "    available_features = [f for f in features if f in df.columns]\n",
    "\n",
    "    return available_features\n",
    "\n",
    "# Display feature strategy\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"FEATURE STRATEGY: {FEATURE_STRATEGY}\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Show what features will be used for first target (as example)\n",
    "sample_features = prepare_features_for_target(train_df, TARGETS[0], FEATURE_STRATEGY)\n",
    "print(f\"\\nExample features for {TARGETS[0]}: {len(sample_features)} features\")\n",
    "print(f\"  - Temporal: {len([f for f in sample_features if f in TEMPORAL_FEATURES])}\")\n",
    "print(f\"  - Weather: {len([f for f in sample_features if f in WEATHER_CURRENT])}\")\n",
    "print(f\"  - Cross-pollutant: {len([f for f in sample_features if 'roll_mean' in f])}\")\n",
    "print(f\"\\nFeature list:\")\n",
    "for f in sample_features[:20]:  # Show first 20\n",
    "    print(f\"    {f}\")\n",
    "if len(sample_features) > 20:\n",
    "    print(f\"    ... and {len(sample_features) - 20} more\")\n",
    "\n",
    "# Clean training data - use selected features + targets\n",
    "feature_cols = prepare_features_for_target(train_df, TARGETS[0], FEATURE_STRATEGY)\n",
    "train_clean = train_df[feature_cols + TARGETS].dropna().reset_index(drop=True)\n",
    "print(f\"\\nâœ“ Train samples after removing NaNs: {len(train_clean)}\")\n",
    "\n",
    "# =============================================================================\n",
    "# TIME SERIES CROSS-VALIDATION SPLITTER\n",
    "# =============================================================================\n",
    "def time_series_cv_split(df, n_splits=5, test_ratio=0.2):\n",
    "    \"\"\"\n",
    "    Creates time series cross-validation splits using expanding window.\n",
    "    \"\"\"\n",
    "    n = len(df)\n",
    "    test_size = int(n * test_ratio)\n",
    "    min_train_size = int(n * 0.5)\n",
    "\n",
    "    splits = []\n",
    "    for i in range(n_splits):\n",
    "        val_end = n - (n_splits - i - 1) * (test_size // 2)\n",
    "        val_start = val_end - test_size\n",
    "        train_end = val_start\n",
    "\n",
    "        if train_end < min_train_size:\n",
    "            continue\n",
    "\n",
    "        train_idx = df.index[:train_end]\n",
    "        val_idx = df.index[val_start:val_end]\n",
    "        splits.append((train_idx, val_idx))\n",
    "\n",
    "    print(f\"\\nâœ“ Created {len(splits)} CV splits:\")\n",
    "    for i, (train_idx, val_idx) in enumerate(splits, 1):\n",
    "        print(f\"  Fold {i}: Train={len(train_idx)}, Val={len(val_idx)}\")\n",
    "\n",
    "    return splits\n",
    "\n",
    "# =============================================================================\n",
    "# PREPARE EXOGENOUS FEATURES\n",
    "# =============================================================================\n",
    "def prepare_exog_features(df, target_col, strategy='optimized'):\n",
    "    \"\"\"\n",
    "    Extract exogenous features from dataframe based on strategy.\n",
    "    Returns None if no features, otherwise returns feature matrix.\n",
    "    \"\"\"\n",
    "    features = prepare_features_for_target(df, target_col, strategy)\n",
    "\n",
    "    if len(features) == 0:\n",
    "        return None\n",
    "\n",
    "    # Get only the feature columns that exist\n",
    "    available_cols = [c for c in features if c in df.columns]\n",
    "\n",
    "    if len(available_cols) == 0:\n",
    "        return None\n",
    "\n",
    "    exog_df = df[available_cols].copy()\n",
    "\n",
    "    # Handle any remaining NaNs\n",
    "    if exog_df.isna().any().any():\n",
    "        exog_df = exog_df.fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "    return exog_df\n",
    "\n",
    "# =============================================================================\n",
    "# TRAIN SARIMAX WITH CROSS-VALIDATION\n",
    "# =============================================================================\n",
    "def train_sarimax_with_cv(df, target_col, n_splits=5):\n",
    "    \"\"\"\n",
    "    Train SARIMAX model using time series cross-validation.\n",
    "    Features are automatically selected based on FEATURE_STRATEGY.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"TRAINING SARIMAX FOR {target_col}\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    splits = time_series_cv_split(df, n_splits=n_splits, test_ratio=TEST_SIZE_RATIO)\n",
    "    cv_scores = []\n",
    "\n",
    "    # Cross-validation loop\n",
    "    for fold, (train_idx, val_idx) in enumerate(splits, 1):\n",
    "        print(f\"\\n--- Fold {fold}/{len(splits)} ---\")\n",
    "\n",
    "        train_data = df.loc[train_idx]\n",
    "        val_data = df.loc[val_idx]\n",
    "\n",
    "        # Prepare target and exogenous features\n",
    "        y_train = train_data[target_col]\n",
    "        y_val = val_data[target_col]\n",
    "\n",
    "        exog_train = prepare_exog_features(train_data, target_col, FEATURE_STRATEGY)\n",
    "        exog_val = prepare_exog_features(val_data, target_col, FEATURE_STRATEGY)\n",
    "\n",
    "        try:\n",
    "            # Fit SARIMAX\n",
    "            model = SARIMAX(\n",
    "                endog=y_train,\n",
    "                exog=exog_train,\n",
    "                order=SARIMAX_ORDER,\n",
    "                seasonal_order=SARIMAX_SEASONAL_ORDER,\n",
    "                enforce_stationarity=False,\n",
    "                enforce_invertibility=False\n",
    "            )\n",
    "\n",
    "            model_fit = model.fit(disp=False, maxiter=MAX_ITER, method='lbfgs')\n",
    "\n",
    "            # Forecast\n",
    "            predictions = model_fit.forecast(steps=len(val_idx), exog=exog_val)\n",
    "            predictions = np.maximum(predictions, 0)  # Non-negative\n",
    "\n",
    "            # Metrics\n",
    "            rmse = np.sqrt(mean_squared_error(y_val, predictions))\n",
    "            mae = mean_absolute_error(y_val, predictions)\n",
    "            r2 = r2_score(y_val, predictions)\n",
    "\n",
    "            cv_scores.append({'fold': fold, 'rmse': rmse, 'mae': mae, 'r2': r2})\n",
    "            print(f\"  RMSE: {rmse:.4f} | MAE: {mae:.4f} | RÂ²: {r2:.4f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  âœ— Error: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    # Display CV results\n",
    "    if cv_scores:\n",
    "        cv_df = pd.DataFrame(cv_scores)\n",
    "        print(f\"\\n{'â”€'*70}\")\n",
    "        print(f\"CV Summary for {target_col}:\")\n",
    "        print(cv_df.to_string(index=False))\n",
    "        print(f\"\\nMean RMSE: {cv_df['rmse'].mean():.4f} (Â± {cv_df['rmse'].std():.4f})\")\n",
    "        print(f\"Mean MAE:  {cv_df['mae'].mean():.4f} (Â± {cv_df['mae'].std():.4f})\")\n",
    "        print(f\"Mean RÂ²:   {cv_df['r2'].mean():.4f} (Â± {cv_df['r2'].std():.4f})\")\n",
    "\n",
    "    # Train final model on full data\n",
    "    print(f\"\\nðŸ”§ Training final model on full training set...\")\n",
    "    y_full = df[target_col]\n",
    "    exog_full = prepare_exog_features(df, target_col, FEATURE_STRATEGY)\n",
    "\n",
    "    final_model = SARIMAX(\n",
    "        endog=y_full,\n",
    "        exog=exog_full,\n",
    "        order=SARIMAX_ORDER,\n",
    "        seasonal_order=SARIMAX_SEASONAL_ORDER,\n",
    "        enforce_stationarity=False,\n",
    "        enforce_invertibility=False\n",
    "    )\n",
    "\n",
    "    final_model_fit = final_model.fit(disp=False, maxiter=MAX_ITER, method='lbfgs')\n",
    "    print(f\"âœ“ Final model trained\")\n",
    "\n",
    "    return final_model_fit, cv_scores\n",
    "\n",
    "# =============================================================================\n",
    "# TRAIN MODELS FOR ALL TARGETS\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"TRAINING MODELS FOR ALL POLLUTANTS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "models = {}\n",
    "all_cv_scores = {}\n",
    "\n",
    "for i, target in enumerate(TARGETS, 1):\n",
    "    print(f\"\\n[{i}/{len(TARGETS)}] Processing {target}...\")\n",
    "\n",
    "    try:\n",
    "        model_fit, cv_scores = train_sarimax_with_cv(\n",
    "            train_clean,\n",
    "            target,\n",
    "            n_splits=N_SPLITS\n",
    "        )\n",
    "        models[target] = model_fit\n",
    "        all_cv_scores[target] = cv_scores\n",
    "        print(f\"âœ“ {target} model trained successfully\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Failed to train {target}: {str(e)}\")\n",
    "        models[target] = None\n",
    "        all_cv_scores[target] = []\n",
    "\n",
    "successful_models = sum(1 for m in models.values() if m is not None)\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Training Complete: {successful_models}/{len(TARGETS)} models successful\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# =============================================================================\n",
    "# PREPARE TEST FEATURES - SMART APPROACH\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"PREPARING TEST DATA\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Get last 24 rows of training data for feature initialization\n",
    "last_24_rows = train_df.iloc[-24:].copy()\n",
    "print(f\"\\nâœ“ Using last 24 rows of train for lag/roll feature averaging\")\n",
    "\n",
    "# Build test features row by row\n",
    "test_features_dict = {}  # Store features per target\n",
    "\n",
    "for target in TARGETS:\n",
    "    print(f\"\\nPreparing test features for {target}...\")\n",
    "\n",
    "    # Get feature list for this target\n",
    "    feature_list = prepare_features_for_target(test_df, target, FEATURE_STRATEGY)\n",
    "\n",
    "    test_features_list = []\n",
    "\n",
    "    for idx in range(len(test_df)):\n",
    "        test_row = test_df.iloc[idx]\n",
    "\n",
    "        row_features = []\n",
    "\n",
    "        for col in feature_list:\n",
    "            if col in TEMPORAL_FEATURES:\n",
    "                # Temporal features: use actual test values\n",
    "                if col in test_row.index:\n",
    "                    feat_val = float(test_row[col])\n",
    "                else:\n",
    "                    feat_val = 0.0\n",
    "\n",
    "            elif col in WEATHER_CURRENT:\n",
    "                # Current weather: use actual test values\n",
    "                if col in test_row.index:\n",
    "                    feat_val = float(test_row[col])\n",
    "                else:\n",
    "                    feat_val = 0.0\n",
    "\n",
    "            elif col in last_24_rows.columns:\n",
    "                # Lag/roll features: average from last 24 train rows\n",
    "                feat_val = float(last_24_rows[col].mean())\n",
    "            else:\n",
    "                feat_val = 0.0\n",
    "\n",
    "            row_features.append(feat_val)\n",
    "\n",
    "        test_features_list.append(row_features)\n",
    "\n",
    "    # Create DataFrame for this target's test features\n",
    "    test_features_df = pd.DataFrame(test_features_list, columns=feature_list)\n",
    "    test_features_dict[target] = test_features_df\n",
    "\n",
    "    print(f\"  âœ“ Shape: {test_features_df.shape}\")\n",
    "\n",
    "# =============================================================================\n",
    "# MAKE PREDICTIONS ON TEST SET\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"GENERATING PREDICTIONS FOR TEST SET\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Initialize predictions dataframe\n",
    "if DATE_COL in test_df.columns:\n",
    "    predictions_df = test_df[[DATE_COL]].copy()\n",
    "else:\n",
    "    predictions_df = pd.DataFrame(index=test_df.index)\n",
    "\n",
    "for target in TARGETS:\n",
    "    print(f\"\\nðŸ”® Predicting {target}...\")\n",
    "\n",
    "    if models[target] is None:\n",
    "        print(f\"  âœ— No model available, using zeros\")\n",
    "        predictions_df[target] = 0\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # Get the correct test features for this target\n",
    "        test_features_df = test_features_dict[target]\n",
    "\n",
    "        # Make predictions using the prepared test features\n",
    "        n_steps = len(test_features_df)\n",
    "        preds = models[target].forecast(steps=n_steps, exog=test_features_df)\n",
    "\n",
    "        # Ensure non-negative predictions\n",
    "        preds = np.maximum(preds, 0)\n",
    "\n",
    "        predictions_df[target] = preds\n",
    "        print(f\"  âœ“ Predicted {target}\")\n",
    "        print(f\"    Range: [{preds.min():.2f}, {preds.max():.2f}]\")\n",
    "        print(f\"    Mean: {preds.mean():.2f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  âœ— Error predicting {target}: {str(e)}\")\n",
    "        predictions_df[target] = 0\n",
    "\n",
    "# =============================================================================\n",
    "# SAVE RESULTS\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"SAVING RESULTS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Save submission file\n",
    "predictions_df.to_csv('submission.csv', index=False)\n",
    "print(f\"\\nâœ“ Submission saved as 'submission.csv'\")\n",
    "print(f\"  Shape: {predictions_df.shape}\")\n",
    "print(f\"\\nFirst few predictions:\")\n",
    "print(predictions_df.head(10))\n",
    "\n",
    "# Save CV scores summary\n",
    "cv_summary = []\n",
    "for target, scores in all_cv_scores.items():\n",
    "    if scores:\n",
    "        cv_df = pd.DataFrame(scores)\n",
    "        cv_summary.append({\n",
    "            'target': target,\n",
    "            'mean_rmse': cv_df['rmse'].mean(),\n",
    "            'std_rmse': cv_df['rmse'].std(),\n",
    "            'mean_mae': cv_df['mae'].mean(),\n",
    "            'std_mae': cv_df['mae'].std(),\n",
    "            'mean_r2': cv_df['r2'].mean(),\n",
    "            'std_r2': cv_df['r2'].std()\n",
    "        })\n",
    "\n",
    "if cv_summary:\n",
    "    cv_summary_df = pd.DataFrame(cv_summary)\n",
    "    cv_summary_df.to_csv('cv_scores_summary.csv', index=False)\n",
    "    print(f\"\\nâœ“ CV scores saved as 'cv_scores_summary.csv'\")\n",
    "    print(\"\\nCross-Validation Summary:\")\n",
    "    print(cv_summary_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"PIPELINE COMPLETE!\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c12869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SARIMAX PIPELINE - TEMPORAL + CROSS-POLLUTANT FEATURES\n",
      "======================================================================\n",
      "\n",
      "âœ“ Loaded train: (40991, 213)\n",
      "âœ“ Loaded test: (504, 208)\n",
      "\n",
      "======================================================================\n",
      "FEATURE CONFIGURATION\n",
      "======================================================================\n",
      "\n",
      "Features for valeur_NO2: 14 total\n",
      "  - Temporal: 10\n",
      "  - Cross-pollutant: 4\n",
      "\n",
      "âœ“ Clean train samples: 40991\n",
      "\n",
      "======================================================================\n",
      "TRAINING ALL POLLUTANT MODELS\n",
      "======================================================================\n",
      "\n",
      "[1/5] valeur_NO2\n",
      "\n",
      "======================================================================\n",
      "TRAINING: valeur_NO2\n",
      "======================================================================\n",
      "âœ“ Created 2 CV splits\n",
      "\n",
      "Fold 1/2 - Train: 31769, Val: 6148 â†’ RMSE: 25.76, MAE: 19.57, RÂ²: -1.699\n",
      "\n",
      "Fold 2/2 - Train: 34843, Val: 6148 â†’ RMSE: 20.98, MAE: 17.35, RÂ²: -2.212\n",
      "\n",
      "ðŸ“Š CV Summary: RMSE=23.37Â±3.38, MAE=18.46Â±1.57, RÂ²=-1.955Â±0.363\n",
      "ðŸ”§ Training final model on full data... âœ“ Done\n",
      "\n",
      "[2/5] valeur_CO\n",
      "\n",
      "======================================================================\n",
      "TRAINING: valeur_CO\n",
      "======================================================================\n",
      "âœ“ Created 2 CV splits\n",
      "\n",
      "Fold 1/2 - Train: 31769, Val: 6148 â†’ RMSE: 0.09, MAE: 0.05, RÂ²: 0.279\n",
      "\n",
      "Fold 2/2 - Train: 34843, Val: 6148 â†’ âœ— Error: Unable to allocate 691. MiB for an array with shap\n",
      "\n",
      "ðŸ“Š CV Summary: RMSE=0.09Â±nan, MAE=0.05Â±nan, RÂ²=0.279Â±nan\n",
      "ðŸ”§ Training final model on full data... âœ— Failed: Unable to allocate 813. MiB for an array with shape (51, 51, 40992) and data type float64\n",
      "\n",
      "[3/5] valeur_O3\n",
      "\n",
      "======================================================================\n",
      "TRAINING: valeur_O3\n",
      "======================================================================\n",
      "âœ“ Created 2 CV splits\n",
      "\n",
      "Fold 1/2 - Train: 31769, Val: 6148 â†’ RMSE: 143.48, MAE: 131.92, RÂ²: -38.117\n",
      "\n",
      "Fold 2/2 - Train: 34843, Val: 6148 â†’ âœ— Error: Unable to allocate 691. MiB for an array with shap\n",
      "\n",
      "ðŸ“Š CV Summary: RMSE=143.48Â±nan, MAE=131.92Â±nan, RÂ²=-38.117Â±nan\n",
      "ðŸ”§ Training final model on full data... âœ— Failed: Unable to allocate 813. MiB for an array with shape (51, 51, 40992) and data type float64\n",
      "\n",
      "[4/5] valeur_PM10\n",
      "\n",
      "======================================================================\n",
      "TRAINING: valeur_PM10\n",
      "======================================================================\n",
      "âœ“ Created 2 CV splits\n",
      "\n",
      "Fold 1/2 - Train: 31769, Val: 6148 â†’ RMSE: 14.90, MAE: 12.00, RÂ²: -1.977\n",
      "\n",
      "Fold 2/2 - Train: 34843, Val: 6148 â†’ âœ— Error: Unable to allocate 691. MiB for an array with shap\n",
      "\n",
      "ðŸ“Š CV Summary: RMSE=14.90Â±nan, MAE=12.00Â±nan, RÂ²=-1.977Â±nan\n",
      "ðŸ”§ Training final model on full data... âœ— Failed: Unable to allocate 813. MiB for an array with shape (51, 51, 40991) and data type float64\n",
      "\n",
      "[5/5] valeur_PM25\n",
      "\n",
      "======================================================================\n",
      "TRAINING: valeur_PM25\n",
      "======================================================================\n",
      "âœ“ Created 2 CV splits\n",
      "\n",
      "Fold 1/2 - Train: 31769, Val: 6148 â†’ RMSE: 9.44, MAE: 6.68, RÂ²: -1.119\n",
      "\n",
      "Fold 2/2 - Train: 34843, Val: 6148 â†’ âœ— Error: Unable to allocate 691. MiB for an array with shap\n",
      "\n",
      "ðŸ“Š CV Summary: RMSE=9.44Â±nan, MAE=6.68Â±nan, RÂ²=-1.119Â±nan\n",
      "ðŸ”§ Training final model on full data... âœ— Failed: Unable to allocate 813. MiB for an array with shape (51, 51, 40991) and data type float64\n",
      "\n",
      "======================================================================\n",
      "âœ“ Training Complete: 1/5 models successful\n",
      "â± Total time: 399.5 minutes\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "PREPARING TEST FEATURES\n",
      "======================================================================\n",
      "âœ“ Test features prepared for all 5 targets\n",
      "\n",
      "======================================================================\n",
      "GENERATING PREDICTIONS\n",
      "======================================================================\n",
      "âœ“ valeur_NO2: [19.0, 36.8], mean=27.2\n",
      "âœ— valeur_CO: No model, using zeros\n",
      "âœ— valeur_O3: No model, using zeros\n",
      "âœ— valeur_PM10: No model, using zeros\n",
      "âœ— valeur_PM25: No model, using zeros\n",
      "\n",
      "======================================================================\n",
      "SAVING RESULTS\n",
      "======================================================================\n",
      "âœ“ Submission saved: submission.csv ((504, 5))\n",
      "âœ“ CV scores saved: cv_scores_summary.csv\n",
      "\n",
      "ðŸ“Š FINAL RESULTS:\n",
      "    target  mean_rmse  std_rmse  mean_mae  std_mae   mean_r2  std_r2\n",
      "valeur_NO2  23.368962  3.381012 18.462693 1.567135 -1.955079 0.36277\n",
      "\n",
      "======================================================================\n",
      "âœ… PIPELINE COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "ðŸ’¡ Model Configuration:\n",
      "   SARIMAX Order: (1, 1, 1) Ã— (1, 1, 1, 24)\n",
      "   Features: Temporal + Cross-Pollutant (NO weather)\n",
      "   CV Folds: 2\n",
      "   Total runtime: 399.5 minutes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION - NO WEATHER FEATURES\n",
    "# =============================================================================\n",
    "TARGETS = ['valeur_NO2', 'valeur_CO', 'valeur_O3', 'valeur_PM10', 'valeur_PM25']\n",
    "\n",
    "TEMPORAL_FEATURES = ['hour', 'is_day', 'hour_sin', 'hour_cos', 'dow', 'dow_sin',\n",
    "                     'dow_cos', 'is_holiday', 'is_weekend', 'lockdown_code']\n",
    "\n",
    "DATE_COL = 'date'\n",
    "\n",
    "# Cross-validation settings - optimized for speed\n",
    "N_SPLITS = 2\n",
    "TEST_SIZE_RATIO = 0.15\n",
    "\n",
    "# SARIMAX with STRONGER seasonality to compensate for missing weather\n",
    "SARIMAX_ORDER = (1, 1, 1)\n",
    "SARIMAX_SEASONAL_ORDER = (1, 1, 1, 24)  # Full seasonality for daily patterns\n",
    "MAX_ITER = 75\n",
    "\n",
    "# =============================================================================\n",
    "# LOAD AND PREPARE DATA\n",
    "# =============================================================================\n",
    "print(\"=\"*70)\n",
    "print(\"SARIMAX PIPELINE - TEMPORAL + CROSS-POLLUTANT FEATURES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "train_df = pd.read_csv(\"../data/train_features.csv\")\n",
    "test_df = pd.read_csv(\"../data/test_features_to_predict.csv\")\n",
    "\n",
    "print(f\"\\nâœ“ Loaded train: {train_df.shape}\")\n",
    "print(f\"âœ“ Loaded test: {test_df.shape}\")\n",
    "\n",
    "# Convert and sort by date\n",
    "if DATE_COL in train_df.columns:\n",
    "    train_df[DATE_COL] = pd.to_datetime(train_df[DATE_COL])\n",
    "    train_df = train_df.sort_values(DATE_COL).reset_index(drop=True)\n",
    "\n",
    "if DATE_COL in test_df.columns:\n",
    "    test_df[DATE_COL] = pd.to_datetime(test_df[DATE_COL])\n",
    "    test_df = test_df.sort_values(DATE_COL).reset_index(drop=True)\n",
    "\n",
    "# =============================================================================\n",
    "# FEATURE SELECTION - TEMPORAL + CROSS-POLLUTANT\n",
    "# =============================================================================\n",
    "def get_cross_pollutant_features(target_col):\n",
    "    \"\"\"Get rolling means of OTHER pollutants.\"\"\"\n",
    "    target_name = target_col.replace('valeur_', '')\n",
    "    other_pollutants = [p for p in ['NO2', 'CO', 'O3', 'PM10', 'PM25']\n",
    "                        if p != target_name]\n",
    "\n",
    "    cross_features = []\n",
    "    for pollutant in other_pollutants:\n",
    "        cross_features.append(f'valeur_{pollutant}_roll_mean_24')\n",
    "\n",
    "    return cross_features\n",
    "\n",
    "def prepare_features_for_target(df, target_col):\n",
    "    \"\"\"Prepare feature set: temporal + cross-pollutant only.\"\"\"\n",
    "    features = TEMPORAL_FEATURES.copy()\n",
    "\n",
    "    # Add cross-pollutant rolling means\n",
    "    cross_features = get_cross_pollutant_features(target_col)\n",
    "    cross_available = [f for f in cross_features if f in df.columns]\n",
    "    features.extend(cross_available)\n",
    "\n",
    "    # Filter to available columns\n",
    "    available_features = [f for f in features if f in df.columns]\n",
    "\n",
    "    return available_features\n",
    "\n",
    "# Display features\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"FEATURE CONFIGURATION\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "sample_features = prepare_features_for_target(train_df, TARGETS[0])\n",
    "print(f\"\\nFeatures for {TARGETS[0]}: {len(sample_features)} total\")\n",
    "print(f\"  - Temporal: {len([f for f in sample_features if f in TEMPORAL_FEATURES])}\")\n",
    "print(f\"  - Cross-pollutant: {len([f for f in sample_features if 'roll_mean' in f])}\")\n",
    "\n",
    "# Clean training data\n",
    "all_needed_cols = set()\n",
    "for target in TARGETS:\n",
    "    all_needed_cols.update(prepare_features_for_target(train_df, target))\n",
    "all_needed_cols.update(TARGETS)\n",
    "\n",
    "train_clean = train_df[list(all_needed_cols)].dropna().reset_index(drop=True)\n",
    "print(f\"\\nâœ“ Clean train samples: {len(train_clean)}\")\n",
    "\n",
    "# =============================================================================\n",
    "# TIME SERIES CROSS-VALIDATION\n",
    "# =============================================================================\n",
    "def time_series_cv_split(df, n_splits=2, test_ratio=0.15):\n",
    "    \"\"\"Expanding window CV splits.\"\"\"\n",
    "    n = len(df)\n",
    "    test_size = int(n * test_ratio)\n",
    "    min_train_size = int(n * 0.6)\n",
    "\n",
    "    splits = []\n",
    "    for i in range(n_splits):\n",
    "        val_end = n - (n_splits - i - 1) * (test_size // 2)\n",
    "        val_start = val_end - test_size\n",
    "        train_end = val_start\n",
    "\n",
    "        if train_end < min_train_size:\n",
    "            continue\n",
    "\n",
    "        train_idx = df.index[:train_end]\n",
    "        val_idx = df.index[val_start:val_end]\n",
    "        splits.append((train_idx, val_idx))\n",
    "\n",
    "    return splits\n",
    "\n",
    "def prepare_exog_features(df, target_col):\n",
    "    \"\"\"Extract exogenous features for target.\"\"\"\n",
    "    features = prepare_features_for_target(df, target_col)\n",
    "\n",
    "    if len(features) == 0:\n",
    "        return None\n",
    "\n",
    "    available_cols = [c for c in features if c in df.columns]\n",
    "    if len(available_cols) == 0:\n",
    "        return None\n",
    "\n",
    "    exog_df = df[available_cols].copy()\n",
    "\n",
    "    # Handle NaNs\n",
    "    if exog_df.isna().any().any():\n",
    "        exog_df = exog_df.fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "    return exog_df\n",
    "\n",
    "# =============================================================================\n",
    "# TRAIN SARIMAX WITH CV\n",
    "# =============================================================================\n",
    "def train_sarimax_with_cv(df, target_col, n_splits=2):\n",
    "    \"\"\"Train SARIMAX with time series cross-validation.\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"TRAINING: {target_col}\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    splits = time_series_cv_split(df, n_splits=n_splits, test_ratio=TEST_SIZE_RATIO)\n",
    "    print(f\"âœ“ Created {len(splits)} CV splits\")\n",
    "\n",
    "    cv_scores = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(splits, 1):\n",
    "        print(f\"\\nFold {fold}/{len(splits)} - Train: {len(train_idx)}, Val: {len(val_idx)}\", end=\" \")\n",
    "\n",
    "        train_data = df.loc[train_idx]\n",
    "        val_data = df.loc[val_idx]\n",
    "\n",
    "        y_train = train_data[target_col]\n",
    "        y_val = val_data[target_col]\n",
    "\n",
    "        exog_train = prepare_exog_features(train_data, target_col)\n",
    "        exog_val = prepare_exog_features(val_data, target_col)\n",
    "\n",
    "        try:\n",
    "            model = SARIMAX(\n",
    "                endog=y_train,\n",
    "                exog=exog_train,\n",
    "                order=SARIMAX_ORDER,\n",
    "                seasonal_order=SARIMAX_SEASONAL_ORDER,\n",
    "                enforce_stationarity=False,\n",
    "                enforce_invertibility=False\n",
    "            )\n",
    "\n",
    "            model_fit = model.fit(disp=False, maxiter=MAX_ITER, method='lbfgs')\n",
    "\n",
    "            predictions = model_fit.forecast(steps=len(val_idx), exog=exog_val)\n",
    "            predictions = np.maximum(predictions, 0)\n",
    "\n",
    "            rmse = np.sqrt(mean_squared_error(y_val, predictions))\n",
    "            mae = mean_absolute_error(y_val, predictions)\n",
    "            r2 = r2_score(y_val, predictions)\n",
    "\n",
    "            cv_scores.append({'fold': fold, 'rmse': rmse, 'mae': mae, 'r2': r2})\n",
    "            print(f\"â†’ RMSE: {rmse:.2f}, MAE: {mae:.2f}, RÂ²: {r2:.3f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"â†’ âœ— Error: {str(e)[:50]}\")\n",
    "            continue\n",
    "\n",
    "    # Summary\n",
    "    if cv_scores:\n",
    "        cv_df = pd.DataFrame(cv_scores)\n",
    "        print(f\"\\nðŸ“Š CV Summary: RMSE={cv_df['rmse'].mean():.2f}Â±{cv_df['rmse'].std():.2f}, \"\n",
    "              f\"MAE={cv_df['mae'].mean():.2f}Â±{cv_df['mae'].std():.2f}, \"\n",
    "              f\"RÂ²={cv_df['r2'].mean():.3f}Â±{cv_df['r2'].std():.3f}\")\n",
    "\n",
    "    # Train final model\n",
    "    print(f\"ðŸ”§ Training final model on full data...\", end=\" \")\n",
    "    y_full = df[target_col]\n",
    "    exog_full = prepare_exog_features(df, target_col)\n",
    "\n",
    "    final_model = SARIMAX(\n",
    "        endog=y_full,\n",
    "        exog=exog_full,\n",
    "        order=SARIMAX_ORDER,\n",
    "        seasonal_order=SARIMAX_SEASONAL_ORDER,\n",
    "        enforce_stationarity=False,\n",
    "        enforce_invertibility=False\n",
    "    )\n",
    "\n",
    "    final_model_fit = final_model.fit(disp=False, maxiter=MAX_ITER, method='lbfgs')\n",
    "    print(f\"âœ“ Done\")\n",
    "\n",
    "    return final_model_fit, cv_scores\n",
    "\n",
    "# =============================================================================\n",
    "# TRAIN ALL MODELS\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"TRAINING ALL POLLUTANT MODELS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "models = {}\n",
    "all_cv_scores = {}\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "for i, target in enumerate(TARGETS, 1):\n",
    "    print(f\"\\n[{i}/{len(TARGETS)}] {target}\")\n",
    "\n",
    "    try:\n",
    "        model_fit, cv_scores = train_sarimax_with_cv(\n",
    "            train_clean,\n",
    "            target,\n",
    "            n_splits=N_SPLITS\n",
    "        )\n",
    "        models[target] = model_fit\n",
    "        all_cv_scores[target] = cv_scores\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Failed: {str(e)[:100]}\")\n",
    "        models[target] = None\n",
    "        all_cv_scores[target] = []\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "successful = sum(1 for m in models.values() if m is not None)\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"âœ“ Training Complete: {successful}/{len(TARGETS)} models successful\")\n",
    "print(f\"â± Total time: {elapsed/60:.1f} minutes\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# =============================================================================\n",
    "# PREPARE TEST FEATURES\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"PREPARING TEST FEATURES\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "last_24_rows = train_df.iloc[-24:].copy()\n",
    "test_features_dict = {}\n",
    "\n",
    "for target in TARGETS:\n",
    "    feature_list = prepare_features_for_target(test_df, target)\n",
    "    test_features_list = []\n",
    "\n",
    "    for idx in range(len(test_df)):\n",
    "        test_row = test_df.iloc[idx]\n",
    "        row_features = []\n",
    "\n",
    "        for col in feature_list:\n",
    "            if col in TEMPORAL_FEATURES:\n",
    "                # Use actual test values for temporal features\n",
    "                feat_val = float(test_row[col]) if col in test_row.index else 0.0\n",
    "            elif col in last_24_rows.columns:\n",
    "                # Use average from last 24 hours for cross-pollutant features\n",
    "                feat_val = float(last_24_rows[col].mean())\n",
    "            else:\n",
    "                feat_val = 0.0\n",
    "\n",
    "            row_features.append(feat_val)\n",
    "\n",
    "        test_features_list.append(row_features)\n",
    "\n",
    "    test_features_dict[target] = pd.DataFrame(test_features_list, columns=feature_list)\n",
    "\n",
    "print(f\"âœ“ Test features prepared for all {len(TARGETS)} targets\")\n",
    "\n",
    "# =============================================================================\n",
    "# MAKE PREDICTIONS\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"GENERATING PREDICTIONS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "if DATE_COL in test_df.columns:\n",
    "    predictions_df = test_df[[DATE_COL]].copy()\n",
    "else:\n",
    "    predictions_df = pd.DataFrame(index=test_df.index)\n",
    "\n",
    "for target in TARGETS:\n",
    "    if models[target] is None:\n",
    "        print(f\"âœ— {target}: No model, using zeros\")\n",
    "        predictions_df[target] = 0\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        test_features = test_features_dict[target]\n",
    "        preds = models[target].forecast(steps=len(test_features), exog=test_features)\n",
    "        preds = np.maximum(preds, 0)\n",
    "\n",
    "        predictions_df[target] = preds\n",
    "        print(f\"âœ“ {target}: [{preds.min():.1f}, {preds.max():.1f}], mean={preds.mean():.1f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— {target}: Error - {str(e)[:50]}\")\n",
    "        predictions_df[target] = 0\n",
    "\n",
    "# =============================================================================\n",
    "# SAVE RESULTS\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"SAVING RESULTS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "predictions_df.to_csv('submission.csv', index=False)\n",
    "print(f\"âœ“ Submission saved: submission.csv ({predictions_df.shape})\")\n",
    "\n",
    "# Save CV scores\n",
    "cv_summary = []\n",
    "for target, scores in all_cv_scores.items():\n",
    "    if scores:\n",
    "        cv_df = pd.DataFrame(scores)\n",
    "        cv_summary.append({\n",
    "            'target': target,\n",
    "            'mean_rmse': cv_df['rmse'].mean(),\n",
    "            'std_rmse': cv_df['rmse'].std(),\n",
    "            'mean_mae': cv_df['mae'].mean(),\n",
    "            'std_mae': cv_df['mae'].std(),\n",
    "            'mean_r2': cv_df['r2'].mean(),\n",
    "            'std_r2': cv_df['r2'].std()\n",
    "        })\n",
    "\n",
    "if cv_summary:\n",
    "    cv_summary_df = pd.DataFrame(cv_summary)\n",
    "    cv_summary_df.to_csv('cv_scores_summary.csv', index=False)\n",
    "    print(f\"âœ“ CV scores saved: cv_scores_summary.csv\")\n",
    "    print(f\"\\nðŸ“Š FINAL RESULTS:\")\n",
    "    print(cv_summary_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"âœ… PIPELINE COMPLETE!\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nðŸ’¡ Model Configuration:\")\n",
    "print(f\"   SARIMAX Order: {SARIMAX_ORDER} Ã— {SARIMAX_SEASONAL_ORDER}\")\n",
    "print(f\"   Features: Temporal + Cross-Pollutant (NO weather)\")\n",
    "print(f\"   CV Folds: {N_SPLITS}\")\n",
    "print(f\"   Total runtime: {elapsed/60:.1f} minutes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
