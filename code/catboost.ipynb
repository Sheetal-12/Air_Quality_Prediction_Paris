{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6657fd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CATBOOST PIPELINE - TEMPORAL + CROSS-POLLUTANT + LAG FEATURES\n",
      "======================================================================\n",
      "\n",
      "‚úì Loaded train: (40991, 213)\n",
      "‚úì Loaded test: (504, 208)\n",
      "\n",
      "======================================================================\n",
      "FEATURE CONFIGURATION\n",
      "======================================================================\n",
      "\n",
      "Features for valeur_NO2: 21 total\n",
      "  - Temporal: 10\n",
      "  - Cross-pollutant: 6\n",
      "  - Lag: 3\n",
      "  - Rolling: 0\n",
      "\n",
      "‚úì Clean train samples: 40991\n",
      "\n",
      "======================================================================\n",
      "TRAINING ALL POLLUTANT MODELS\n",
      "======================================================================\n",
      "\n",
      "[1/5] valeur_NO2\n",
      "\n",
      "======================================================================\n",
      "TRAINING: valeur_NO2\n",
      "======================================================================\n",
      "‚úì Using 21 features\n",
      "‚úì Created 2 CV splits\n",
      "\n",
      "Fold 1/2 - Train: 31769, Val: 6148 ‚Üí RMSE: 7.23, MAE: 4.68, R¬≤: 0.787, Best iter: 588\n",
      "\n",
      "Fold 2/2 - Train: 34843, Val: 6148 ‚Üí RMSE: 5.82, MAE: 3.77, R¬≤: 0.753, Best iter: 956\n",
      "\n",
      "üìä CV Summary: RMSE=6.53¬±1.00, MAE=4.23¬±0.65, R¬≤=0.770¬±0.025\n",
      "   Avg best iteration: 772\n",
      "üîß Training final model on full data... ‚úì Done\n",
      "\n",
      "[2/5] valeur_CO\n",
      "\n",
      "======================================================================\n",
      "TRAINING: valeur_CO\n",
      "======================================================================\n",
      "‚úì Using 21 features\n",
      "‚úì Created 2 CV splits\n",
      "\n",
      "Fold 1/2 - Train: 31769, Val: 6148 ‚Üí RMSE: 0.06, MAE: 0.03, R¬≤: 0.713, Best iter: 109\n",
      "\n",
      "Fold 2/2 - Train: 34843, Val: 6148 ‚Üí RMSE: 0.06, MAE: 0.02, R¬≤: 0.548, Best iter: 116\n",
      "\n",
      "üìä CV Summary: RMSE=0.06¬±0.01, MAE=0.03¬±0.00, R¬≤=0.630¬±0.117\n",
      "   Avg best iteration: 112\n",
      "üîß Training final model on full data... ‚úì Done\n",
      "\n",
      "[3/5] valeur_O3\n",
      "\n",
      "======================================================================\n",
      "TRAINING: valeur_O3\n",
      "======================================================================\n",
      "‚úì Using 21 features\n",
      "‚úì Created 2 CV splits\n",
      "\n",
      "Fold 1/2 - Train: 31769, Val: 6148 ‚Üí RMSE: 8.71, MAE: 6.37, R¬≤: 0.856, Best iter: 780\n",
      "\n",
      "Fold 2/2 - Train: 34843, Val: 6148 ‚Üí RMSE: 8.53, MAE: 6.31, R¬≤: 0.850, Best iter: 999\n",
      "\n",
      "üìä CV Summary: RMSE=8.62¬±0.13, MAE=6.34¬±0.05, R¬≤=0.853¬±0.004\n",
      "   Avg best iteration: 890\n",
      "üîß Training final model on full data... ‚úì Done\n",
      "\n",
      "[4/5] valeur_PM10\n",
      "\n",
      "======================================================================\n",
      "TRAINING: valeur_PM10\n",
      "======================================================================\n",
      "‚úì Using 21 features\n",
      "‚úì Created 2 CV splits\n",
      "\n",
      "Fold 1/2 - Train: 31769, Val: 6148 ‚Üí RMSE: 4.25, MAE: 2.85, R¬≤: 0.758, Best iter: 833\n",
      "\n",
      "Fold 2/2 - Train: 34843, Val: 6148 ‚Üí RMSE: 3.72, MAE: 2.49, R¬≤: 0.777, Best iter: 842\n",
      "\n",
      "üìä CV Summary: RMSE=3.98¬±0.38, MAE=2.67¬±0.25, R¬≤=0.768¬±0.014\n",
      "   Avg best iteration: 838\n",
      "üîß Training final model on full data... ‚úì Done\n",
      "\n",
      "[5/5] valeur_PM25\n",
      "\n",
      "======================================================================\n",
      "TRAINING: valeur_PM25\n",
      "======================================================================\n",
      "‚úì Using 21 features\n",
      "‚úì Created 2 CV splits\n",
      "\n",
      "Fold 1/2 - Train: 31769, Val: 6148 ‚Üí RMSE: 2.89, MAE: 1.89, R¬≤: 0.802, Best iter: 544\n",
      "\n",
      "Fold 2/2 - Train: 34843, Val: 6148 ‚Üí RMSE: 2.53, MAE: 1.69, R¬≤: 0.806, Best iter: 817\n",
      "\n",
      "üìä CV Summary: RMSE=2.71¬±0.25, MAE=1.79¬±0.14, R¬≤=0.804¬±0.003\n",
      "   Avg best iteration: 680\n",
      "üîß Training final model on full data... ‚úì Done\n",
      "\n",
      "======================================================================\n",
      "‚úì Training Complete: 5/5 models successful\n",
      "‚è± Total time: 1.6 minutes\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "FEATURE IMPORTANCE (Top 10 per model)\n",
      "======================================================================\n",
      "\n",
      "valeur_NO2:\n",
      "                feature  importance\n",
      " valeur_NO2_roll_mean_6   34.777163\n",
      "  valeur_NO2_roll_std_6   12.634996\n",
      "               hour_cos   11.808103\n",
      "       valeur_NO2_lag_6    9.458781\n",
      "               hour_sin    8.008060\n",
      "      valeur_NO2_lag_24    6.374391\n",
      "                   hour    3.658738\n",
      " valeur_O3_roll_mean_24    2.510916\n",
      "valeur_NO2_roll_mean_24    2.197245\n",
      " valeur_CO_roll_mean_24    1.294004\n",
      "\n",
      "valeur_CO:\n",
      "                feature  importance\n",
      "  valeur_CO_roll_mean_6   41.871717\n",
      "        valeur_CO_lag_6   10.212325\n",
      "   valeur_CO_roll_std_6    9.432522\n",
      "               hour_cos    7.556981\n",
      "       valeur_CO_lag_24    5.078734\n",
      "               hour_sin    4.250951\n",
      " valeur_O3_roll_mean_24    3.824024\n",
      "                   hour    3.630102\n",
      "  valeur_CO_roll_std_24    3.036570\n",
      "valeur_NO2_roll_mean_24    2.202172\n",
      "\n",
      "valeur_O3:\n",
      "               feature  importance\n",
      " valeur_O3_roll_mean_6   44.014900\n",
      "              hour_cos   19.159040\n",
      "  valeur_O3_roll_std_6   12.128406\n",
      "      valeur_O3_lag_24    6.254477\n",
      "       valeur_O3_lag_6    5.214438\n",
      "              hour_sin    2.400458\n",
      "valeur_O3_roll_mean_24    2.327210\n",
      " valeur_O3_roll_std_24    1.395800\n",
      "                  hour    1.160384\n",
      "                is_day    1.084254\n",
      "\n",
      "valeur_PM10:\n",
      "                 feature  importance\n",
      " valeur_PM10_roll_mean_6   51.093197\n",
      "       valeur_PM10_lag_6    9.614583\n",
      "  valeur_PM10_roll_std_6    7.995367\n",
      "                hour_sin    3.923718\n",
      "                hour_cos    3.834757\n",
      "                    hour    3.635945\n",
      "      valeur_PM10_lag_24    2.877888\n",
      "  valeur_O3_roll_mean_24    2.740083\n",
      "valeur_PM25_roll_mean_24    2.709076\n",
      " valeur_NO2_roll_mean_24    2.176661\n",
      "\n",
      "valeur_PM25:\n",
      "                 feature  importance\n",
      " valeur_PM25_roll_mean_6   56.932810\n",
      "       valeur_PM25_lag_6    9.899381\n",
      "  valeur_PM25_roll_std_6    6.702030\n",
      "                hour_sin    3.113360\n",
      "                hour_cos    2.869670\n",
      "  valeur_O3_roll_mean_24    2.821986\n",
      "                    hour    2.723999\n",
      " valeur_NO2_roll_mean_24    2.298644\n",
      "      valeur_PM25_lag_24    2.194312\n",
      "valeur_PM25_roll_mean_24    1.715249\n",
      "\n",
      "======================================================================\n",
      "PREPARING TEST FEATURES\n",
      "======================================================================\n",
      "‚úì Test features prepared for all 5 targets\n",
      "\n",
      "======================================================================\n",
      "GENERATING PREDICTIONS\n",
      "======================================================================\n",
      "‚úì valeur_NO2: [14.0, 39.5], mean=22.4\n",
      "‚úì valeur_CO: [0.2, 0.2], mean=0.2\n",
      "‚úì valeur_O3: [23.0, 54.4], mean=38.6\n",
      "‚úì valeur_PM10: [7.0, 11.7], mean=9.0\n",
      "‚úì valeur_PM25: [3.8, 6.7], mean=5.0\n",
      "\n",
      "======================================================================\n",
      "SAVING RESULTS\n",
      "======================================================================\n",
      "‚úì Submission saved: submission.csv ((504, 5))\n",
      "‚úì CV scores saved: cv_scores_summary.csv\n",
      "\n",
      "üìä FINAL RESULTS:\n",
      "     target  mean_rmse  std_rmse  mean_mae  std_mae  mean_r2   std_r2  avg_best_iter\n",
      " valeur_NO2   6.527960  0.997224  4.225339 0.645610 0.769903 0.024511          772.0\n",
      "  valeur_CO   0.060735  0.005646  0.027498 0.003594 0.630279 0.116809          112.5\n",
      "  valeur_O3   8.620571  0.132330  6.342162 0.046228 0.852681 0.004277          889.5\n",
      "valeur_PM10   3.983670  0.376896  2.670818 0.254078 0.767690 0.013813          837.5\n",
      "valeur_PM25   2.708711  0.249896  1.790783 0.142660 0.804270 0.003084          680.5\n",
      "\n",
      "======================================================================\n",
      "‚úÖ PIPELINE COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "üí° Model Configuration:\n",
      "   CatBoost Iterations: 1000\n",
      "   Learning Rate: 0.05\n",
      "   Depth: 6\n",
      "   Features: Temporal + Cross-Pollutant + Lag + Rolling\n",
      "   CV Folds: 2\n",
      "   Total runtime: 1.6 minutes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "TARGETS = ['valeur_NO2', 'valeur_CO', 'valeur_O3', 'valeur_PM10', 'valeur_PM25']\n",
    "\n",
    "TEMPORAL_FEATURES = ['hour', 'is_day', 'hour_sin', 'hour_cos', 'dow', 'dow_sin',\n",
    "                     'dow_cos', 'is_holiday', 'is_weekend', 'lockdown_code']\n",
    "\n",
    "DATE_COL = 'date'\n",
    "\n",
    "# Cross-validation settings\n",
    "N_SPLITS = 2\n",
    "TEST_SIZE_RATIO = 0.15\n",
    "\n",
    "# CatBoost settings\n",
    "CATBOOST_PARAMS = {\n",
    "    'iterations': 1000,\n",
    "    'learning_rate': 0.05,\n",
    "    'depth': 6,\n",
    "    'l2_leaf_reg': 3,\n",
    "    'loss_function': 'RMSE',\n",
    "    'eval_metric': 'RMSE',\n",
    "    'random_seed': 42,\n",
    "    'verbose': False,\n",
    "    'early_stopping_rounds': 50,\n",
    "    'task_type': 'CPU',\n",
    "    'thread_count': -1\n",
    "}\n",
    "\n",
    "# =============================================================================\n",
    "# LOAD AND PREPARE DATA\n",
    "# =============================================================================\n",
    "print(\"=\"*70)\n",
    "print(\"CATBOOST PIPELINE - TEMPORAL + CROSS-POLLUTANT + LAG FEATURES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "train_df = pd.read_csv(\"../data/train_features.csv\")\n",
    "test_df = pd.read_csv(\"../data/test_features_to_predict.csv\")\n",
    "\n",
    "print(f\"\\n‚úì Loaded train: {train_df.shape}\")\n",
    "print(f\"‚úì Loaded test: {test_df.shape}\")\n",
    "\n",
    "# Convert and sort by date\n",
    "if DATE_COL in train_df.columns:\n",
    "    train_df[DATE_COL] = pd.to_datetime(train_df[DATE_COL])\n",
    "    train_df = train_df.sort_values(DATE_COL).reset_index(drop=True)\n",
    "\n",
    "if DATE_COL in test_df.columns:\n",
    "    test_df[DATE_COL] = pd.to_datetime(test_df[DATE_COL])\n",
    "    test_df = test_df.sort_values(DATE_COL).reset_index(drop=True)\n",
    "\n",
    "# =============================================================================\n",
    "# FEATURE SELECTION\n",
    "# =============================================================================\n",
    "def get_cross_pollutant_features(target_col):\n",
    "    \"\"\"Get rolling means of OTHER pollutants.\"\"\"\n",
    "    target_name = target_col.replace('valeur_', '')\n",
    "    other_pollutants = [p for p in ['NO2', 'CO', 'O3', 'PM10', 'PM25']\n",
    "                        if p != target_name]\n",
    "\n",
    "    cross_features = []\n",
    "    for pollutant in other_pollutants:\n",
    "        cross_features.append(f'valeur_{pollutant}_roll_mean_24')\n",
    "\n",
    "    return cross_features\n",
    "\n",
    "def get_lag_features(target_col):\n",
    "    \"\"\"Get lag features for the target.\"\"\"\n",
    "    lags = [1, 2, 3, 6, 12, 24]\n",
    "    return [f'{target_col}_lag_{lag}' for lag in lags]\n",
    "\n",
    "def get_rolling_features(target_col):\n",
    "    \"\"\"Get rolling statistics for the target.\"\"\"\n",
    "    windows = [6, 12, 24]\n",
    "    stats = ['mean', 'std', 'min', 'max']\n",
    "    features = []\n",
    "    for window in windows:\n",
    "        for stat in stats:\n",
    "            features.append(f'{target_col}_roll_{stat}_{window}')\n",
    "    return features\n",
    "\n",
    "def prepare_features_for_target(df, target_col):\n",
    "    \"\"\"Prepare feature set: temporal + cross-pollutant + lag + rolling.\"\"\"\n",
    "    features = TEMPORAL_FEATURES.copy()\n",
    "\n",
    "    # Add cross-pollutant features\n",
    "    cross_features = get_cross_pollutant_features(target_col)\n",
    "    cross_available = [f for f in cross_features if f in df.columns]\n",
    "    features.extend(cross_available)\n",
    "\n",
    "    # Add lag features\n",
    "    lag_features = get_lag_features(target_col)\n",
    "    lag_available = [f for f in lag_features if f in df.columns]\n",
    "    features.extend(lag_available)\n",
    "\n",
    "    # Add rolling features\n",
    "    rolling_features = get_rolling_features(target_col)\n",
    "    rolling_available = [f for f in rolling_features if f in df.columns]\n",
    "    features.extend(rolling_available)\n",
    "\n",
    "    # Filter to available columns\n",
    "    available_features = [f for f in features if f in df.columns]\n",
    "\n",
    "    return available_features\n",
    "\n",
    "# Display features\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"FEATURE CONFIGURATION\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "sample_features = prepare_features_for_target(train_df, TARGETS[0])\n",
    "print(f\"\\nFeatures for {TARGETS[0]}: {len(sample_features)} total\")\n",
    "print(f\"  - Temporal: {len([f for f in sample_features if f in TEMPORAL_FEATURES])}\")\n",
    "print(f\"  - Cross-pollutant: {len([f for f in sample_features if 'valeur_' in f and 'roll_mean' in f])}\")\n",
    "print(f\"  - Lag: {len([f for f in sample_features if '_lag_' in f])}\")\n",
    "print(f\"  - Rolling: {len([f for f in sample_features if '_roll_' in f and 'valeur_' not in f])}\")\n",
    "\n",
    "# Clean training data\n",
    "all_needed_cols = set()\n",
    "for target in TARGETS:\n",
    "    all_needed_cols.update(prepare_features_for_target(train_df, target))\n",
    "all_needed_cols.update(TARGETS)\n",
    "\n",
    "train_clean = train_df[list(all_needed_cols)].dropna().reset_index(drop=True)\n",
    "print(f\"\\n‚úì Clean train samples: {len(train_clean)}\")\n",
    "\n",
    "# =============================================================================\n",
    "# TIME SERIES CROSS-VALIDATION\n",
    "# =============================================================================\n",
    "def time_series_cv_split(df, n_splits=2, test_ratio=0.15):\n",
    "    \"\"\"Expanding window CV splits.\"\"\"\n",
    "    n = len(df)\n",
    "    test_size = int(n * test_ratio)\n",
    "    min_train_size = int(n * 0.6)\n",
    "\n",
    "    splits = []\n",
    "    for i in range(n_splits):\n",
    "        val_end = n - (n_splits - i - 1) * (test_size // 2)\n",
    "        val_start = val_end - test_size\n",
    "        train_end = val_start\n",
    "\n",
    "        if train_end < min_train_size:\n",
    "            continue\n",
    "\n",
    "        train_idx = df.index[:train_end]\n",
    "        val_idx = df.index[val_start:val_end]\n",
    "        splits.append((train_idx, val_idx))\n",
    "\n",
    "    return splits\n",
    "\n",
    "# =============================================================================\n",
    "# TRAIN CATBOOST WITH CV\n",
    "# =============================================================================\n",
    "def train_catboost_with_cv(df, target_col, n_splits=2):\n",
    "    \"\"\"Train CatBoost with time series cross-validation.\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"TRAINING: {target_col}\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    # Get features for this target\n",
    "    feature_cols = prepare_features_for_target(df, target_col)\n",
    "    print(f\"‚úì Using {len(feature_cols)} features\")\n",
    "\n",
    "    splits = time_series_cv_split(df, n_splits=n_splits, test_ratio=TEST_SIZE_RATIO)\n",
    "    print(f\"‚úì Created {len(splits)} CV splits\")\n",
    "\n",
    "    cv_scores = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(splits, 1):\n",
    "        print(f\"\\nFold {fold}/{len(splits)} - Train: {len(train_idx)}, Val: {len(val_idx)}\", end=\" \")\n",
    "\n",
    "        train_data = df.loc[train_idx]\n",
    "        val_data = df.loc[val_idx]\n",
    "\n",
    "        X_train = train_data[feature_cols]\n",
    "        y_train = train_data[target_col]\n",
    "        X_val = val_data[feature_cols]\n",
    "        y_val = val_data[target_col]\n",
    "\n",
    "        # Handle any remaining NaNs\n",
    "        X_train = X_train.fillna(0)\n",
    "        X_val = X_val.fillna(0)\n",
    "\n",
    "        try:\n",
    "            # Create CatBoost pools\n",
    "            train_pool = Pool(X_train, y_train)\n",
    "            val_pool = Pool(X_val, y_val)\n",
    "\n",
    "            # Train model\n",
    "            model = CatBoostRegressor(**CATBOOST_PARAMS)\n",
    "            model.fit(\n",
    "                train_pool,\n",
    "                eval_set=val_pool,\n",
    "                use_best_model=True,\n",
    "                plot=False\n",
    "            )\n",
    "\n",
    "            # Predict\n",
    "            predictions = model.predict(X_val)\n",
    "            predictions = np.maximum(predictions, 0)  # Non-negative constraint\n",
    "\n",
    "            # Evaluate\n",
    "            rmse = np.sqrt(mean_squared_error(y_val, predictions))\n",
    "            mae = mean_absolute_error(y_val, predictions)\n",
    "            r2 = r2_score(y_val, predictions)\n",
    "\n",
    "            cv_scores.append({\n",
    "                'fold': fold,\n",
    "                'rmse': rmse,\n",
    "                'mae': mae,\n",
    "                'r2': r2,\n",
    "                'best_iteration': model.get_best_iteration()\n",
    "            })\n",
    "            print(f\"‚Üí RMSE: {rmse:.2f}, MAE: {mae:.2f}, R¬≤: {r2:.3f}, Best iter: {model.get_best_iteration()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚Üí ‚úó Error: {str(e)[:50]}\")\n",
    "            continue\n",
    "\n",
    "    # Summary\n",
    "    if cv_scores:\n",
    "        cv_df = pd.DataFrame(cv_scores)\n",
    "        print(f\"\\nüìä CV Summary: RMSE={cv_df['rmse'].mean():.2f}¬±{cv_df['rmse'].std():.2f}, \"\n",
    "              f\"MAE={cv_df['mae'].mean():.2f}¬±{cv_df['mae'].std():.2f}, \"\n",
    "              f\"R¬≤={cv_df['r2'].mean():.3f}¬±{cv_df['r2'].std():.3f}\")\n",
    "        print(f\"   Avg best iteration: {cv_df['best_iteration'].mean():.0f}\")\n",
    "\n",
    "    # Train final model on full data\n",
    "    print(f\"üîß Training final model on full data...\", end=\" \")\n",
    "    X_full = df[feature_cols].fillna(0)\n",
    "    y_full = df[target_col]\n",
    "\n",
    "    full_pool = Pool(X_full, y_full)\n",
    "\n",
    "    final_model = CatBoostRegressor(**CATBOOST_PARAMS)\n",
    "    final_model.fit(full_pool, plot=False)\n",
    "\n",
    "    print(f\"‚úì Done\")\n",
    "\n",
    "    return final_model, cv_scores, feature_cols\n",
    "\n",
    "# =============================================================================\n",
    "# TRAIN ALL MODELS\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"TRAINING ALL POLLUTANT MODELS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "models = {}\n",
    "all_cv_scores = {}\n",
    "all_feature_cols = {}\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "for i, target in enumerate(TARGETS, 1):\n",
    "    print(f\"\\n[{i}/{len(TARGETS)}] {target}\")\n",
    "\n",
    "    try:\n",
    "        model, cv_scores, feature_cols = train_catboost_with_cv(\n",
    "            train_clean,\n",
    "            target,\n",
    "            n_splits=N_SPLITS\n",
    "        )\n",
    "        models[target] = model\n",
    "        all_cv_scores[target] = cv_scores\n",
    "        all_feature_cols[target] = feature_cols\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Failed: {str(e)[:100]}\")\n",
    "        models[target] = None\n",
    "        all_cv_scores[target] = []\n",
    "        all_feature_cols[target] = []\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "successful = sum(1 for m in models.values() if m is not None)\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"‚úì Training Complete: {successful}/{len(TARGETS)} models successful\")\n",
    "print(f\"‚è± Total time: {elapsed/60:.1f} minutes\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# =============================================================================\n",
    "# FEATURE IMPORTANCE\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"FEATURE IMPORTANCE (Top 10 per model)\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "for target in TARGETS:\n",
    "    if models[target] is not None:\n",
    "        feature_importance = models[target].get_feature_importance()\n",
    "        feature_names = all_feature_cols[target]\n",
    "\n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': feature_importance\n",
    "        }).sort_values('importance', ascending=False)\n",
    "\n",
    "        print(f\"\\n{target}:\")\n",
    "        print(importance_df.head(10).to_string(index=False))\n",
    "\n",
    "# =============================================================================\n",
    "# PREPARE TEST FEATURES\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"PREPARING TEST FEATURES\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# For lag and rolling features, we need to use last known values from train\n",
    "last_24_rows = train_df.iloc[-24:].copy()\n",
    "\n",
    "test_features_dict = {}\n",
    "\n",
    "for target in TARGETS:\n",
    "    feature_list = all_feature_cols[target]\n",
    "    X_test = test_df[feature_list].copy()\n",
    "\n",
    "    # Fill missing lag/rolling features with averages from last 24 hours\n",
    "    for col in feature_list:\n",
    "        if col not in test_df.columns or test_df[col].isna().any():\n",
    "            if col in last_24_rows.columns:\n",
    "                fill_value = last_24_rows[col].mean()\n",
    "            else:\n",
    "                fill_value = 0.0\n",
    "            X_test[col] = X_test[col].fillna(fill_value) if col in X_test.columns else fill_value\n",
    "\n",
    "    X_test = X_test.fillna(0)\n",
    "    test_features_dict[target] = X_test\n",
    "\n",
    "print(f\"‚úì Test features prepared for all {len(TARGETS)} targets\")\n",
    "\n",
    "# =============================================================================\n",
    "# MAKE PREDICTIONS\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"GENERATING PREDICTIONS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "if DATE_COL in test_df.columns:\n",
    "    predictions_df = test_df[[DATE_COL]].copy()\n",
    "else:\n",
    "    predictions_df = pd.DataFrame(index=test_df.index)\n",
    "\n",
    "for target in TARGETS:\n",
    "    if models[target] is None:\n",
    "        print(f\"‚úó {target}: No model, using zeros\")\n",
    "        predictions_df[target] = 0\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        X_test = test_features_dict[target]\n",
    "        preds = models[target].predict(X_test)\n",
    "        preds = np.maximum(preds, 0)  # Non-negative constraint\n",
    "\n",
    "        predictions_df[target] = preds\n",
    "        print(f\"‚úì {target}: [{preds.min():.1f}, {preds.max():.1f}], mean={preds.mean():.1f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚úó {target}: Error - {str(e)[:50]}\")\n",
    "        predictions_df[target] = 0\n",
    "\n",
    "# =============================================================================\n",
    "# SAVE RESULTS\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"SAVING RESULTS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "predictions_df.to_csv('submission.csv', index=False)\n",
    "print(f\"‚úì Submission saved: submission.csv ({predictions_df.shape})\")\n",
    "\n",
    "# Save CV scores\n",
    "cv_summary = []\n",
    "for target, scores in all_cv_scores.items():\n",
    "    if scores:\n",
    "        cv_df = pd.DataFrame(scores)\n",
    "        cv_summary.append({\n",
    "            'target': target,\n",
    "            'mean_rmse': cv_df['rmse'].mean(),\n",
    "            'std_rmse': cv_df['rmse'].std(),\n",
    "            'mean_mae': cv_df['mae'].mean(),\n",
    "            'std_mae': cv_df['mae'].std(),\n",
    "            'mean_r2': cv_df['r2'].mean(),\n",
    "            'std_r2': cv_df['r2'].std(),\n",
    "            'avg_best_iter': cv_df['best_iteration'].mean()\n",
    "        })\n",
    "\n",
    "if cv_summary:\n",
    "    cv_summary_df = pd.DataFrame(cv_summary)\n",
    "    cv_summary_df.to_csv('cv_scores_summary.csv', index=False)\n",
    "    print(f\"‚úì CV scores saved: cv_scores_summary.csv\")\n",
    "    print(f\"\\nüìä FINAL RESULTS:\")\n",
    "    print(cv_summary_df.to_string(index=False))\n",
    "\n",
    "# Save models (optional - can be large files)\n",
    "# import joblib\n",
    "# for target, model in models.items():\n",
    "#     if model is not None:\n",
    "#         joblib.dump(model, f'catboost_{target}.pkl')\n",
    "# print(f\"‚úì Models saved\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"‚úÖ PIPELINE COMPLETE!\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nüí° Model Configuration:\")\n",
    "print(f\"   CatBoost Iterations: {CATBOOST_PARAMS['iterations']}\")\n",
    "print(f\"   Learning Rate: {CATBOOST_PARAMS['learning_rate']}\")\n",
    "print(f\"   Depth: {CATBOOST_PARAMS['depth']}\")\n",
    "print(f\"   Features: Temporal + Cross-Pollutant + Lag + Rolling\")\n",
    "print(f\"   CV Folds: {N_SPLITS}\")\n",
    "print(f\"   Total runtime: {elapsed/60:.1f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb10afcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CATBOOST PIPELINE - NO WEATHER FORECASTS\n",
      "======================================================================\n",
      "\n",
      "‚úì Loaded train: (40991, 213)\n",
      "‚úì Loaded test: (504, 208)\n",
      "\n",
      "======================================================================\n",
      "FEATURE CONFIGURATION - NO WEATHER FORECASTS\n",
      "======================================================================\n",
      "\n",
      "Features for valeur_NO2: 204 total\n",
      "  - Temporal: 10\n",
      "  - Weather (historical only): 159\n",
      "  - Cross-pollutant (historical): 35\n",
      "  - Target (historical): 7\n",
      "\n",
      "‚úì Clean train samples: 40991\n",
      "\n",
      "======================================================================\n",
      "TRAINING ALL POLLUTANT MODELS\n",
      "======================================================================\n",
      "\n",
      "[1/5] valeur_NO2\n",
      "\n",
      "======================================================================\n",
      "TRAINING: valeur_NO2\n",
      "======================================================================\n",
      "‚úì Using 204 features\n",
      "‚úì Created 2 CV splits\n",
      "\n",
      "Fold 1/2 - Train: 31769, Val: 6148 ‚Üí RMSE: 6.78, MAE: 4.47, R¬≤: 0.813, Best iter: 611\n",
      "\n",
      "Fold 2/2 - Train: 34843, Val: 6148 ‚Üí RMSE: 5.54, MAE: 3.67, R¬≤: 0.776, Best iter: 705\n",
      "\n",
      "üìä CV Summary: RMSE=6.16¬±0.88, MAE=4.07¬±0.57, R¬≤=0.795¬±0.026\n",
      "   Avg best iteration: 658\n",
      "üîß Training final model on full data... ‚úì Done\n",
      "\n",
      "[2/5] valeur_CO\n",
      "\n",
      "======================================================================\n",
      "TRAINING: valeur_CO\n",
      "======================================================================\n",
      "‚úì Using 204 features\n",
      "‚úì Created 2 CV splits\n",
      "\n",
      "Fold 1/2 - Train: 31769, Val: 6148 ‚Üí RMSE: 0.05, MAE: 0.03, R¬≤: 0.765, Best iter: 413\n",
      "\n",
      "Fold 2/2 - Train: 34843, Val: 6148 ‚Üí RMSE: 0.06, MAE: 0.02, R¬≤: 0.627, Best iter: 379\n",
      "\n",
      "üìä CV Summary: RMSE=0.06¬±0.01, MAE=0.02¬±0.00, R¬≤=0.696¬±0.098\n",
      "   Avg best iteration: 396\n",
      "üîß Training final model on full data... ‚úì Done\n",
      "\n",
      "[3/5] valeur_O3\n",
      "\n",
      "======================================================================\n",
      "TRAINING: valeur_O3\n",
      "======================================================================\n",
      "‚úì Using 205 features\n",
      "‚úì Created 2 CV splits\n",
      "\n",
      "Fold 1/2 - Train: 31769, Val: 6148 ‚Üí RMSE: 7.41, MAE: 5.43, R¬≤: 0.896, Best iter: 973\n",
      "\n",
      "Fold 2/2 - Train: 34843, Val: 6148 ‚Üí RMSE: 7.55, MAE: 5.57, R¬≤: 0.882, Best iter: 977\n",
      "\n",
      "üìä CV Summary: RMSE=7.48¬±0.10, MAE=5.50¬±0.10, R¬≤=0.889¬±0.010\n",
      "   Avg best iteration: 975\n",
      "üîß Training final model on full data... ‚úì Done\n",
      "\n",
      "[4/5] valeur_PM10\n",
      "\n",
      "======================================================================\n",
      "TRAINING: valeur_PM10\n",
      "======================================================================\n",
      "‚úì Using 204 features\n",
      "‚úì Created 2 CV splits\n",
      "\n",
      "Fold 1/2 - Train: 31769, Val: 6148 ‚Üí RMSE: 4.12, MAE: 2.84, R¬≤: 0.772, Best iter: 845\n",
      "\n",
      "Fold 2/2 - Train: 34843, Val: 6148 ‚Üí RMSE: 3.69, MAE: 2.50, R¬≤: 0.781, Best iter: 997\n",
      "\n",
      "üìä CV Summary: RMSE=3.90¬±0.31, MAE=2.67¬±0.24, R¬≤=0.777¬±0.006\n",
      "   Avg best iteration: 921\n",
      "üîß Training final model on full data... ‚úì Done\n",
      "\n",
      "[5/5] valeur_PM25\n",
      "\n",
      "======================================================================\n",
      "TRAINING: valeur_PM25\n",
      "======================================================================\n",
      "‚úì Using 205 features\n",
      "‚úì Created 2 CV splits\n",
      "\n",
      "Fold 1/2 - Train: 31769, Val: 6148 ‚Üí RMSE: 2.31, MAE: 1.50, R¬≤: 0.874, Best iter: 998\n",
      "\n",
      "Fold 2/2 - Train: 34843, Val: 6148 ‚Üí RMSE: 2.06, MAE: 1.43, R¬≤: 0.872, Best iter: 999\n",
      "\n",
      "üìä CV Summary: RMSE=2.18¬±0.17, MAE=1.46¬±0.05, R¬≤=0.873¬±0.001\n",
      "   Avg best iteration: 998\n",
      "üîß Training final model on full data... ‚úì Done\n",
      "\n",
      "======================================================================\n",
      "‚úì Training Complete: 5/5 models successful\n",
      "‚è± Total time: 9.6 minutes\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "FEATURE IMPORTANCE (Top 15 per model)\n",
      "======================================================================\n",
      "\n",
      "valeur_NO2:\n",
      "                             feature  importance\n",
      "              valeur_NO2_roll_mean_6   31.692393\n",
      "                            hour_cos    9.920457\n",
      "               valeur_NO2_roll_std_6    8.081652\n",
      "                            hour_sin    7.536356\n",
      "                   valeur_NO2_lag_24    4.904656\n",
      "                    valeur_NO2_lag_6    3.740425\n",
      "                valeur_O3_roll_std_6    3.035971\n",
      "                                hour    1.557097\n",
      "     global_tilted_irradiance_lag_24    1.490599\n",
      "          wind_speed_10m_roll_mean_6    1.156346\n",
      "                     valeur_O3_lag_6    1.136865\n",
      "global_tilted_irradiance_roll_mean_6    1.037605\n",
      "          shortwave_radiation_lag_24    0.937665\n",
      "                                 dow    0.809435\n",
      "      diffuse_radiation_roll_mean_24    0.731647\n",
      "\n",
      "valeur_CO:\n",
      "                 feature  importance\n",
      "   valeur_CO_roll_mean_6   38.464233\n",
      "    valeur_CO_roll_std_6    6.817232\n",
      "                hour_cos    4.442568\n",
      "         valeur_CO_lag_6    3.194242\n",
      "                hour_sin    2.781949\n",
      "   valeur_NO2_roll_std_6    2.451694\n",
      "                    hour    2.294268\n",
      "        valeur_NO2_lag_6    1.811149\n",
      "         valeur_O3_lag_6    1.664447\n",
      "    valeur_O3_roll_std_6    1.615299\n",
      "  valeur_NO2_roll_mean_6    1.520093\n",
      "       valeur_NO2_lag_24    1.432563\n",
      "diffuse_radiation_lag_24    1.305428\n",
      "        valeur_O3_lag_24    1.160859\n",
      "        valeur_CO_lag_24    1.000181\n",
      "\n",
      "valeur_O3:\n",
      "                          feature  importance\n",
      "            valeur_O3_roll_mean_6   35.727325\n",
      "                  NO2_lag1_for_O3   11.332672\n",
      "                         hour_cos   10.839183\n",
      "             valeur_O3_roll_std_6    7.853415\n",
      "           valeur_O3_roll_mean_24    2.870308\n",
      "                 valeur_O3_lag_24    2.791315\n",
      "et0_fao_evapotranspiration_lag_24    2.611780\n",
      "           valeur_NO2_roll_mean_6    2.416306\n",
      "       shortwave_radiation_lag_24    2.402154\n",
      "  global_tilted_irradiance_lag_24    1.808175\n",
      "                         hour_sin    1.071736\n",
      "                             hour    0.892452\n",
      "                  valeur_O3_lag_6    0.822258\n",
      "                 valeur_NO2_lag_6    0.815693\n",
      "         diffuse_radiation_lag_24    0.700265\n",
      "\n",
      "valeur_PM10:\n",
      "                      feature  importance\n",
      "      valeur_PM10_roll_mean_6   43.940926\n",
      "            valeur_PM10_lag_6    6.072234\n",
      "       valeur_PM10_roll_std_6    6.015224\n",
      "                     hour_cos    3.005863\n",
      "      valeur_PM25_roll_mean_6    2.908180\n",
      "         valeur_O3_roll_std_6    1.450024\n",
      "           valeur_PM10_lag_24    1.446773\n",
      "                       is_day    1.296681\n",
      "diffuse_radiation_roll_mean_6    1.289758\n",
      "                         hour    1.287054\n",
      "       valeur_NO2_roll_mean_6    1.122825\n",
      "                     hour_sin    1.061276\n",
      "       valeur_PM25_roll_std_6    0.920210\n",
      "            valeur_PM25_lag_6    0.851376\n",
      "        valeur_NO2_roll_std_6    0.741158\n",
      "\n",
      "valeur_PM25:\n",
      "                          feature  importance\n",
      "          valeur_PM25_roll_mean_6   36.158490\n",
      "               PM10_lag1_for_PM25   27.015591\n",
      "           valeur_PM25_roll_std_6    3.427255\n",
      "          valeur_PM10_roll_mean_6    2.555099\n",
      "                valeur_PM25_lag_6    1.622467\n",
      "                valeur_PM10_lag_6    1.381812\n",
      "                             hour    1.363746\n",
      "                         hour_sin    0.972869\n",
      "                         hour_cos    0.960616\n",
      "apparent_temperature_roll_mean_24    0.942423\n",
      "               valeur_PM25_lag_24    0.905641\n",
      "           valeur_PM10_roll_std_6    0.761958\n",
      "  wind_direction_10m_roll_mean_24    0.647200\n",
      "       wind_speed_10m_roll_mean_6    0.628622\n",
      "   vapour_pressure_deficit_lag_24    0.628181\n",
      "\n",
      "======================================================================\n",
      "GENERATING PREDICTIONS\n",
      "======================================================================\n",
      "‚úì valeur_NO2: [15.1, 38.2], mean=26.4\n",
      "‚úì valeur_CO: [0.2, 0.3], mean=0.2\n",
      "‚úì valeur_O3: [27.5, 52.7], mean=36.3\n",
      "‚úì valeur_PM10: [7.8, 12.6], mean=10.4\n",
      "‚úì valeur_PM25: [4.1, 7.5], mean=5.6\n",
      "\n",
      "======================================================================\n",
      "SAVING RESULTS\n",
      "======================================================================\n",
      "‚úì Submission saved: submission.csv ((504, 5))\n",
      "‚úì CV scores saved: cv_scores_summary.csv\n",
      "\n",
      "üìä FINAL RESULTS:\n",
      "     target  mean_rmse  std_rmse  mean_mae  std_mae  mean_r2   std_r2  avg_best_iter\n",
      " valeur_NO2   6.156680  0.875922  4.069886 0.568232 0.794758 0.026187          658.0\n",
      "  valeur_CO   0.055055  0.005280  0.024615 0.002578 0.695998 0.097749          396.0\n",
      "  valeur_O3   7.481953  0.097183  5.499673 0.097585 0.888843 0.009516          975.0\n",
      "valeur_PM10   3.904265  0.310029  2.668213 0.238165 0.776713 0.006469          921.0\n",
      "valeur_PM25   2.182464  0.174525  1.462165 0.049023 0.872805 0.001134          998.5\n",
      "\n",
      "======================================================================\n",
      "‚úÖ PIPELINE COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "üí° Model Configuration:\n",
      "   CatBoost Iterations: 1000\n",
      "   Learning Rate: 0.05\n",
      "   Depth: 6\n",
      "   Features: Temporal + Historical Weather + Historical Pollutants\n",
      "   CV Folds: 2\n",
      "   Total runtime: 9.6 minutes\n",
      "\n",
      "‚ö†Ô∏è  IMPORTANT: NO WEATHER FORECASTS - Using ONLY features we know:\n",
      "   ‚úì Temporal features (hour, day, holidays)\n",
      "   ‚úì Historical weather (lag 6, 12, 24 hours + rolling stats)\n",
      "   ‚úì Historical pollutant data (lag 6, 12, 24 hours + rolling stats)\n",
      "   ‚úó NO current/future weather (no forecasts available!)\n",
      "   ‚úó NO short-term lags (lag 1, 2, 3)\n",
      "   ‚úó NO future pollutant values\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "TARGETS = ['valeur_NO2', 'valeur_CO', 'valeur_O3', 'valeur_PM10', 'valeur_PM25']\n",
    "\n",
    "# Features we WILL KNOW at prediction time (NO WEATHER FORECASTS)\n",
    "TEMPORAL_FEATURES = ['hour', 'is_day', 'hour_sin', 'hour_cos', 'dow', 'dow_sin',\n",
    "                     'dow_cos', 'is_holiday', 'is_weekend', 'lockdown_code']\n",
    "\n",
    "# Weather base features for lag/rolling only\n",
    "WEATHER_BASE = [\n",
    "    'temperature_2m', 'relative_humidity_2m', 'dew_point_2m', 'apparent_temperature',\n",
    "    'pressure_msl', 'wind_speed_10m', 'wind_direction_10m', 'precipitation',\n",
    "    'cloud_cover', 'cloud_cover_low', 'cloud_cover_mid', 'cloud_cover_high',\n",
    "    'shortwave_radiation', 'direct_radiation', 'diffuse_radiation',\n",
    "    'global_tilted_irradiance', 'wind_gusts_10m', 'vapour_pressure_deficit',\n",
    "    'et0_fao_evapotranspiration', 'snowfall', 'rain', 'showers', 'weather_code'\n",
    "]\n",
    "\n",
    "DATE_COL = 'date'\n",
    "\n",
    "# Cross-validation settings\n",
    "N_SPLITS = 2\n",
    "TEST_SIZE_RATIO = 0.15\n",
    "\n",
    "# CatBoost settings\n",
    "CATBOOST_PARAMS = {\n",
    "    'iterations': 1000,\n",
    "    'learning_rate': 0.05,\n",
    "    'depth': 6,\n",
    "    'l2_leaf_reg': 3,\n",
    "    'loss_function': 'RMSE',\n",
    "    'eval_metric': 'RMSE',\n",
    "    'random_seed': 42,\n",
    "    'verbose': False,\n",
    "    'early_stopping_rounds': 50,\n",
    "    'task_type': 'CPU',\n",
    "    'thread_count': -1\n",
    "}\n",
    "\n",
    "# =============================================================================\n",
    "# LOAD AND PREPARE DATA\n",
    "# =============================================================================\n",
    "print(\"=\"*70)\n",
    "print(\"CATBOOST PIPELINE - NO WEATHER FORECASTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "train_df = pd.read_csv(\"../data/train_features.csv\")\n",
    "test_df = pd.read_csv(\"../data/test_features_to_predict.csv\")\n",
    "\n",
    "print(f\"\\n‚úì Loaded train: {train_df.shape}\")\n",
    "print(f\"‚úì Loaded test: {test_df.shape}\")\n",
    "\n",
    "# Convert and sort by date\n",
    "if DATE_COL in train_df.columns:\n",
    "    train_df[DATE_COL] = pd.to_datetime(train_df[DATE_COL])\n",
    "    train_df = train_df.sort_values(DATE_COL).reset_index(drop=True)\n",
    "\n",
    "if DATE_COL in test_df.columns:\n",
    "    test_df[DATE_COL] = pd.to_datetime(test_df[DATE_COL])\n",
    "    test_df = test_df.sort_values(DATE_COL).reset_index(drop=True)\n",
    "\n",
    "# =============================================================================\n",
    "# FEATURE SELECTION - ONLY HISTORICAL DATA (NO FORECASTS)\n",
    "# =============================================================================\n",
    "def get_weather_lag_features():\n",
    "    \"\"\"Get weather lag features (historical weather we know).\"\"\"\n",
    "    features = []\n",
    "    for weather in WEATHER_BASE:\n",
    "        features.extend([\n",
    "            f'{weather}_lag_6',\n",
    "            f'{weather}_lag_12',\n",
    "            f'{weather}_lag_24'\n",
    "        ])\n",
    "    return features\n",
    "\n",
    "def get_weather_rolling_features():\n",
    "    \"\"\"Get weather rolling features (historical weather statistics).\"\"\"\n",
    "    features = []\n",
    "    for weather in WEATHER_BASE:\n",
    "        features.extend([\n",
    "            f'{weather}_roll_mean_6',\n",
    "            f'{weather}_roll_std_6',\n",
    "            f'{weather}_roll_mean_24',\n",
    "            f'{weather}_roll_std_24'\n",
    "        ])\n",
    "    return features\n",
    "\n",
    "def get_cross_pollutant_lag_features(target_col):\n",
    "    \"\"\"\n",
    "    Get lag features of OTHER pollutants.\n",
    "    We can use historical pollutant data (lags) but NOT future predictions.\n",
    "    \"\"\"\n",
    "    target_name = target_col.replace('valeur_', '')\n",
    "    other_pollutants = [p for p in ['NO2', 'CO', 'O3', 'PM10', 'PM25']\n",
    "                        if p != target_name]\n",
    "\n",
    "    cross_features = []\n",
    "    for pollutant in other_pollutants:\n",
    "        # Only use lags 6, 12, 24 (historical data we know)\n",
    "        for lag in [6, 12, 24]:\n",
    "            cross_features.append(f'valeur_{pollutant}_lag_{lag}')\n",
    "        # Rolling means/stds of historical data\n",
    "        cross_features.extend([\n",
    "            f'valeur_{pollutant}_roll_mean_6',\n",
    "            f'valeur_{pollutant}_roll_std_6',\n",
    "            f'valeur_{pollutant}_roll_mean_24',\n",
    "            f'valeur_{pollutant}_roll_std_24'\n",
    "        ])\n",
    "\n",
    "    return cross_features\n",
    "\n",
    "def get_target_historical_features(target_col):\n",
    "    \"\"\"\n",
    "    Get historical features for the target itself.\n",
    "    We can use past values (lags) and rolling statistics.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "\n",
    "    # Lag features (we know past values)\n",
    "    for lag in [6, 12, 24]:\n",
    "        features.append(f'{target_col}_lag_{lag}')\n",
    "\n",
    "    # Rolling statistics (calculated from past values)\n",
    "    for window in [6, 24]:\n",
    "        features.extend([\n",
    "            f'{target_col}_roll_mean_{window}',\n",
    "            f'{target_col}_roll_std_{window}'\n",
    "        ])\n",
    "\n",
    "    return features\n",
    "\n",
    "def get_special_interaction_features(target_col):\n",
    "    \"\"\"Get special interaction features like NO2_lag1_for_O3.\"\"\"\n",
    "    features = []\n",
    "\n",
    "    # These are specific interactions that were pre-computed\n",
    "    if target_col == 'valeur_O3':\n",
    "        features.append('NO2_lag1_for_O3')\n",
    "    elif target_col == 'valeur_PM25':\n",
    "        features.append('PM10_lag1_for_PM25')\n",
    "\n",
    "    return features\n",
    "\n",
    "def prepare_features_for_target(df, target_col):\n",
    "    \"\"\"\n",
    "    Prepare feature set: ONLY features we'll know WITHOUT weather forecasts.\n",
    "\n",
    "    INCLUDED:\n",
    "    - Temporal features (hour, day of week, etc.) - we know when we're predicting\n",
    "    - Weather lag/rolling features - historical weather we know\n",
    "    - Cross-pollutant historical features - past values of other pollutants\n",
    "    - Target historical features - past values of the target itself\n",
    "\n",
    "    EXCLUDED:\n",
    "    - Current/future weather (no forecasts available!)\n",
    "    - Future pollutant values (we're predicting those!)\n",
    "    - Short lags (lag_1, lag_2, lag_3) - might not be available at prediction time\n",
    "    \"\"\"\n",
    "    features = []\n",
    "\n",
    "    # 1. Temporal features (always known)\n",
    "    features.extend(TEMPORAL_FEATURES)\n",
    "\n",
    "    # 2. Historical weather features (NO current weather - no forecasts!)\n",
    "    weather_lag = get_weather_lag_features()\n",
    "    features.extend(weather_lag)\n",
    "\n",
    "    weather_rolling = get_weather_rolling_features()\n",
    "    features.extend(weather_rolling)\n",
    "\n",
    "    # 3. Historical pollutant data (from other pollutants)\n",
    "    cross_features = get_cross_pollutant_lag_features(target_col)\n",
    "    features.extend(cross_features)\n",
    "\n",
    "    # 4. Historical target data (past values of what we're predicting)\n",
    "    target_historical = get_target_historical_features(target_col)\n",
    "    features.extend(target_historical)\n",
    "\n",
    "    # 5. Special interaction features\n",
    "    special_features = get_special_interaction_features(target_col)\n",
    "    features.extend(special_features)\n",
    "\n",
    "    # Filter to only available columns\n",
    "    available_features = [f for f in features if f in df.columns]\n",
    "\n",
    "    return available_features\n",
    "\n",
    "# Display features\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"FEATURE CONFIGURATION - NO WEATHER FORECASTS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "sample_features = prepare_features_for_target(train_df, TARGETS[0])\n",
    "print(f\"\\nFeatures for {TARGETS[0]}: {len(sample_features)} total\")\n",
    "print(f\"  - Temporal: {len([f for f in sample_features if f in TEMPORAL_FEATURES])}\")\n",
    "print(f\"  - Weather (historical only): {len([f for f in sample_features if any(w in f for w in WEATHER_BASE) and ('_lag_' in f or '_roll_' in f)])}\")\n",
    "print(f\"  - Cross-pollutant (historical): {len([f for f in sample_features if 'valeur_' in f and ('_lag_' in f or '_roll_' in f)])}\")\n",
    "print(f\"  - Target (historical): {len([f for f in sample_features if TARGETS[0] in f and ('_lag_' in f or '_roll_' in f)])}\")\n",
    "\n",
    "# Clean training data\n",
    "all_needed_cols = set()\n",
    "for target in TARGETS:\n",
    "    all_needed_cols.update(prepare_features_for_target(train_df, target))\n",
    "all_needed_cols.update(TARGETS)\n",
    "\n",
    "train_clean = train_df[list(all_needed_cols)].dropna().reset_index(drop=True)\n",
    "print(f\"\\n‚úì Clean train samples: {len(train_clean)}\")\n",
    "\n",
    "# =============================================================================\n",
    "# TIME SERIES CROSS-VALIDATION\n",
    "# =============================================================================\n",
    "def time_series_cv_split(df, n_splits=2, test_ratio=0.15):\n",
    "    \"\"\"Expanding window CV splits.\"\"\"\n",
    "    n = len(df)\n",
    "    test_size = int(n * test_ratio)\n",
    "    min_train_size = int(n * 0.6)\n",
    "\n",
    "    splits = []\n",
    "    for i in range(n_splits):\n",
    "        val_end = n - (n_splits - i - 1) * (test_size // 2)\n",
    "        val_start = val_end - test_size\n",
    "        train_end = val_start\n",
    "\n",
    "        if train_end < min_train_size:\n",
    "            continue\n",
    "\n",
    "        train_idx = df.index[:train_end]\n",
    "        val_idx = df.index[val_start:val_end]\n",
    "        splits.append((train_idx, val_idx))\n",
    "\n",
    "    return splits\n",
    "\n",
    "# =============================================================================\n",
    "# TRAIN CATBOOST WITH CV\n",
    "# =============================================================================\n",
    "def train_catboost_with_cv(df, target_col, n_splits=2):\n",
    "    \"\"\"Train CatBoost with time series cross-validation.\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"TRAINING: {target_col}\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    # Get features for this target\n",
    "    feature_cols = prepare_features_for_target(df, target_col)\n",
    "    print(f\"‚úì Using {len(feature_cols)} features\")\n",
    "\n",
    "    splits = time_series_cv_split(df, n_splits=n_splits, test_ratio=TEST_SIZE_RATIO)\n",
    "    print(f\"‚úì Created {len(splits)} CV splits\")\n",
    "\n",
    "    cv_scores = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(splits, 1):\n",
    "        print(f\"\\nFold {fold}/{len(splits)} - Train: {len(train_idx)}, Val: {len(val_idx)}\", end=\" \")\n",
    "\n",
    "        train_data = df.loc[train_idx]\n",
    "        val_data = df.loc[val_idx]\n",
    "\n",
    "        X_train = train_data[feature_cols]\n",
    "        y_train = train_data[target_col]\n",
    "        X_val = val_data[feature_cols]\n",
    "        y_val = val_data[target_col]\n",
    "\n",
    "        # Handle any remaining NaNs\n",
    "        X_train = X_train.fillna(0)\n",
    "        X_val = X_val.fillna(0)\n",
    "\n",
    "        try:\n",
    "            # Create CatBoost pools\n",
    "            train_pool = Pool(X_train, y_train)\n",
    "            val_pool = Pool(X_val, y_val)\n",
    "\n",
    "            # Train model\n",
    "            model = CatBoostRegressor(**CATBOOST_PARAMS)\n",
    "            model.fit(\n",
    "                train_pool,\n",
    "                eval_set=val_pool,\n",
    "                use_best_model=True,\n",
    "                plot=False\n",
    "            )\n",
    "\n",
    "            # Predict\n",
    "            predictions = model.predict(X_val)\n",
    "            predictions = np.maximum(predictions, 0)  # Non-negative constraint\n",
    "\n",
    "            # Evaluate\n",
    "            rmse = np.sqrt(mean_squared_error(y_val, predictions))\n",
    "            mae = mean_absolute_error(y_val, predictions)\n",
    "            r2 = r2_score(y_val, predictions)\n",
    "\n",
    "            cv_scores.append({\n",
    "                'fold': fold,\n",
    "                'rmse': rmse,\n",
    "                'mae': mae,\n",
    "                'r2': r2,\n",
    "                'best_iteration': model.get_best_iteration()\n",
    "            })\n",
    "            print(f\"‚Üí RMSE: {rmse:.2f}, MAE: {mae:.2f}, R¬≤: {r2:.3f}, Best iter: {model.get_best_iteration()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚Üí ‚úó Error: {str(e)[:50]}\")\n",
    "            continue\n",
    "\n",
    "    # Summary\n",
    "    if cv_scores:\n",
    "        cv_df = pd.DataFrame(cv_scores)\n",
    "        print(f\"\\nüìä CV Summary: RMSE={cv_df['rmse'].mean():.2f}¬±{cv_df['rmse'].std():.2f}, \"\n",
    "              f\"MAE={cv_df['mae'].mean():.2f}¬±{cv_df['mae'].std():.2f}, \"\n",
    "              f\"R¬≤={cv_df['r2'].mean():.3f}¬±{cv_df['r2'].std():.3f}\")\n",
    "        print(f\"   Avg best iteration: {cv_df['best_iteration'].mean():.0f}\")\n",
    "\n",
    "    # Train final model on full data\n",
    "    print(f\"üîß Training final model on full data...\", end=\" \")\n",
    "    X_full = df[feature_cols].fillna(0)\n",
    "    y_full = df[target_col]\n",
    "\n",
    "    full_pool = Pool(X_full, y_full)\n",
    "\n",
    "    final_model = CatBoostRegressor(**CATBOOST_PARAMS)\n",
    "    final_model.fit(full_pool, plot=False)\n",
    "\n",
    "    print(f\"‚úì Done\")\n",
    "\n",
    "    return final_model, cv_scores, feature_cols\n",
    "\n",
    "# =============================================================================\n",
    "# TRAIN ALL MODELS\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"TRAINING ALL POLLUTANT MODELS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "models = {}\n",
    "all_cv_scores = {}\n",
    "all_feature_cols = {}\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "for i, target in enumerate(TARGETS, 1):\n",
    "    print(f\"\\n[{i}/{len(TARGETS)}] {target}\")\n",
    "\n",
    "    try:\n",
    "        model, cv_scores, feature_cols = train_catboost_with_cv(\n",
    "            train_clean,\n",
    "            target,\n",
    "            n_splits=N_SPLITS\n",
    "        )\n",
    "        models[target] = model\n",
    "        all_cv_scores[target] = cv_scores\n",
    "        all_feature_cols[target] = feature_cols\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Failed: {str(e)[:100]}\")\n",
    "        models[target] = None\n",
    "        all_cv_scores[target] = []\n",
    "        all_feature_cols[target] = []\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "successful = sum(1 for m in models.values() if m is not None)\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"‚úì Training Complete: {successful}/{len(TARGETS)} models successful\")\n",
    "print(f\"‚è± Total time: {elapsed/60:.1f} minutes\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# =============================================================================\n",
    "# FEATURE IMPORTANCE\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"FEATURE IMPORTANCE (Top 15 per model)\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "for target in TARGETS:\n",
    "    if models[target] is not None:\n",
    "        feature_importance = models[target].get_feature_importance()\n",
    "        feature_names = all_feature_cols[target]\n",
    "\n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': feature_importance\n",
    "        }).sort_values('importance', ascending=False)\n",
    "\n",
    "        print(f\"\\n{target}:\")\n",
    "        print(importance_df.head(15).to_string(index=False))\n",
    "\n",
    "# =============================================================================\n",
    "# MAKE PREDICTIONS\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"GENERATING PREDICTIONS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "if DATE_COL in test_df.columns:\n",
    "    predictions_df = test_df[[DATE_COL]].copy()\n",
    "else:\n",
    "    predictions_df = pd.DataFrame(index=test_df.index)\n",
    "\n",
    "for target in TARGETS:\n",
    "    if models[target] is None:\n",
    "        print(f\"‚úó {target}: No model, using zeros\")\n",
    "        predictions_df[target] = 0\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        feature_cols = all_feature_cols[target]\n",
    "        X_test = test_df[feature_cols].copy()\n",
    "\n",
    "        # Fill any missing values with 0\n",
    "        X_test = X_test.fillna(0)\n",
    "\n",
    "        preds = models[target].predict(X_test)\n",
    "        preds = np.maximum(preds, 0)  # Non-negative constraint\n",
    "\n",
    "        predictions_df[target] = preds\n",
    "        print(f\"‚úì {target}: [{preds.min():.1f}, {preds.max():.1f}], mean={preds.mean():.1f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚úó {target}: Error - {str(e)[:50]}\")\n",
    "        predictions_df[target] = 0\n",
    "\n",
    "# =============================================================================\n",
    "# SAVE RESULTS\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"SAVING RESULTS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "predictions_df.to_csv('submission.csv', index=False)\n",
    "print(f\"‚úì Submission saved: submission.csv ({predictions_df.shape})\")\n",
    "\n",
    "# Save CV scores\n",
    "cv_summary = []\n",
    "for target, scores in all_cv_scores.items():\n",
    "    if scores:\n",
    "        cv_df = pd.DataFrame(scores)\n",
    "        cv_summary.append({\n",
    "            'target': target,\n",
    "            'mean_rmse': cv_df['rmse'].mean(),\n",
    "            'std_rmse': cv_df['rmse'].std(),\n",
    "            'mean_mae': cv_df['mae'].mean(),\n",
    "            'std_mae': cv_df['mae'].std(),\n",
    "            'mean_r2': cv_df['r2'].mean(),\n",
    "            'std_r2': cv_df['r2'].std(),\n",
    "            'avg_best_iter': cv_df['best_iteration'].mean()\n",
    "        })\n",
    "\n",
    "if cv_summary:\n",
    "    cv_summary_df = pd.DataFrame(cv_summary)\n",
    "    cv_summary_df.to_csv('cv_scores_summary.csv', index=False)\n",
    "    print(f\"‚úì CV scores saved: cv_scores_summary.csv\")\n",
    "    print(f\"\\nüìä FINAL RESULTS:\")\n",
    "    print(cv_summary_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"‚úÖ PIPELINE COMPLETE!\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nüí° Model Configuration:\")\n",
    "print(f\"   CatBoost Iterations: {CATBOOST_PARAMS['iterations']}\")\n",
    "print(f\"   Learning Rate: {CATBOOST_PARAMS['learning_rate']}\")\n",
    "print(f\"   Depth: {CATBOOST_PARAMS['depth']}\")\n",
    "print(f\"   Features: Temporal + Historical Weather + Historical Pollutants\")\n",
    "print(f\"   CV Folds: {N_SPLITS}\")\n",
    "print(f\"   Total runtime: {elapsed/60:.1f} minutes\")\n",
    "print(f\"\\n‚ö†Ô∏è  IMPORTANT: NO WEATHER FORECASTS - Using ONLY features we know:\")\n",
    "print(f\"   ‚úì Temporal features (hour, day, holidays)\")\n",
    "print(f\"   ‚úì Historical weather (lag 6, 12, 24 hours + rolling stats)\")\n",
    "print(f\"   ‚úì Historical pollutant data (lag 6, 12, 24 hours + rolling stats)\")\n",
    "print(f\"   ‚úó NO current/future weather (no forecasts available!)\")\n",
    "print(f\"   ‚úó NO short-term lags (lag 1, 2, 3)\")\n",
    "print(f\"   ‚úó NO future pollutant values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c8794c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CATBOOST PIPELINE - PURELY FUTURE FORECASTING\n",
      "======================================================================\n",
      "\n",
      "‚ö†Ô∏è  Approach: TEMPORAL FEATURES ONLY (no lags, purely future dates)\n",
      "\n",
      "‚úì Loaded train: (40991, 213)\n",
      "‚úì Loaded test: (504, 208)\n",
      "\n",
      "======================================================================\n",
      "FEATURE CONFIGURATION - PURELY FUTURE FORECASTING\n",
      "======================================================================\n",
      "\n",
      "Features for prediction: 10\n",
      "  1. hour\n",
      "  2. is_day\n",
      "  3. hour_sin\n",
      "  4. hour_cos\n",
      "  5. dow\n",
      "  6. dow_sin\n",
      "  7. dow_cos\n",
      "  8. is_holiday\n",
      "  9. is_weekend\n",
      "  10. lockdown_code\n",
      "\n",
      "‚úì Clean train samples: 40991\n",
      "\n",
      "======================================================================\n",
      "SETTING UP CROSS-VALIDATION\n",
      "======================================================================\n",
      "‚úì Created 5 time series CV splits\n",
      "\n",
      "\n",
      "######################################################################\n",
      "[1/5] valeur_NO2\n",
      "######################################################################\n",
      "\n",
      "======================================================================\n",
      "HYPERPARAMETER TUNING: valeur_NO2\n",
      "======================================================================\n",
      "Testing 16 parameter combinations with 5 CV folds\n",
      "\n",
      "  [1/16] iter=500 lr=0.030 depth=5 l2=2 ‚Üí CV RMSE: 13.70\n",
      "  [2/16] iter=500 lr=0.050 depth=5 l2=2 ‚Üí CV RMSE: 13.69\n",
      "  [3/16] iter=500 lr=0.030 depth=5 l2=3 ‚Üí CV RMSE: 13.70\n",
      "  [4/16] iter=500 lr=0.050 depth=5 l2=3 ‚Üí CV RMSE: 13.69\n",
      "  [5/16] iter=800 lr=0.030 depth=5 l2=2 ‚Üí CV RMSE: 13.70\n",
      "  [6/16] iter=800 lr=0.050 depth=5 l2=2 ‚Üí CV RMSE: 13.69\n",
      "  [7/16] iter=800 lr=0.030 depth=5 l2=3 ‚Üí CV RMSE: 13.70\n",
      "  [8/16] iter=800 lr=0.050 depth=5 l2=3 ‚Üí CV RMSE: 13.69\n",
      "  [9/16] iter=500 lr=0.030 depth=6 l2=2 ‚Üí CV RMSE: 13.70\n",
      "  [10/16] iter=500 lr=0.050 depth=6 l2=2 ‚Üí CV RMSE: 13.70\n",
      "  [11/16] iter=500 lr=0.030 depth=6 l2=3 ‚Üí CV RMSE: 13.70\n",
      "  [12/16] iter=500 lr=0.050 depth=6 l2=3 ‚Üí CV RMSE: 13.70\n",
      "  [13/16] iter=800 lr=0.030 depth=6 l2=2 ‚Üí CV RMSE: 13.70\n",
      "  [14/16] iter=800 lr=0.050 depth=6 l2=2 ‚Üí CV RMSE: 13.70\n",
      "  [15/16] iter=800 lr=0.030 depth=6 l2=3 ‚Üí CV RMSE: 13.70\n",
      "  [16/16] iter=800 lr=0.050 depth=6 l2=3 ‚Üí CV RMSE: 13.70\n",
      "\n",
      "‚úì Best params found: {'depth': 5, 'iterations': 500, 'l2_leaf_reg': 2, 'learning_rate': 0.05}\n",
      "  Best CV RMSE: 13.69 ¬± 1.50\n",
      "\n",
      "======================================================================\n",
      "TRAINING FINAL MODEL: valeur_NO2\n",
      "======================================================================\n",
      "\n",
      "Fold 1/5 ‚Üí RMSE: 13.71, MAE: 11.23, R¬≤: -0.119\n",
      "\n",
      "Fold 2/5 ‚Üí RMSE: 16.06, MAE: 11.75, R¬≤: 0.094\n",
      "\n",
      "Fold 3/5 ‚Üí RMSE: 14.47, MAE: 10.20, R¬≤: 0.093\n",
      "\n",
      "Fold 4/5 ‚Üí RMSE: 11.95, MAE: 9.58, R¬≤: 0.055\n",
      "\n",
      "Fold 5/5 ‚Üí RMSE: 12.28, MAE: 10.76, R¬≤: -0.481\n",
      "\n",
      "üîß Training final model on full dataset... ‚úì Done\n",
      "\n",
      "üìä Final CV Summary:\n",
      "   RMSE: 13.69 ¬± 1.67\n",
      "   MAE:  10.70 ¬± 0.85\n",
      "   R¬≤:   -0.072 ¬± 0.245\n",
      "\n",
      "\n",
      "######################################################################\n",
      "[2/5] valeur_CO\n",
      "######################################################################\n",
      "\n",
      "======================================================================\n",
      "HYPERPARAMETER TUNING: valeur_CO\n",
      "======================================================================\n",
      "Testing 16 parameter combinations with 5 CV folds\n",
      "\n",
      "  [1/16] iter=500 lr=0.030 depth=5 l2=2 ‚Üí CV RMSE: 0.10\n",
      "  [2/16] iter=500 lr=0.050 depth=5 l2=2 ‚Üí CV RMSE: 0.10\n",
      "  [3/16] iter=500 lr=0.030 depth=5 l2=3 ‚Üí CV RMSE: 0.10\n",
      "  [4/16] iter=500 lr=0.050 depth=5 l2=3 ‚Üí CV RMSE: 0.10\n",
      "  [5/16] iter=800 lr=0.030 depth=5 l2=2 ‚Üí CV RMSE: 0.10\n",
      "  [6/16] iter=800 lr=0.050 depth=5 l2=2 ‚Üí CV RMSE: 0.10\n",
      "  [7/16] iter=800 lr=0.030 depth=5 l2=3 ‚Üí CV RMSE: 0.10\n",
      "  [8/16] iter=800 lr=0.050 depth=5 l2=3 ‚Üí CV RMSE: 0.10\n",
      "  [9/16] iter=500 lr=0.030 depth=6 l2=2 ‚Üí CV RMSE: 0.10\n",
      "  [10/16] iter=500 lr=0.050 depth=6 l2=2 ‚Üí CV RMSE: 0.10\n",
      "  [11/16] iter=500 lr=0.030 depth=6 l2=3 ‚Üí CV RMSE: 0.10\n",
      "  [12/16] iter=500 lr=0.050 depth=6 l2=3 ‚Üí CV RMSE: 0.10\n",
      "  [13/16] iter=800 lr=0.030 depth=6 l2=2 ‚Üí CV RMSE: 0.10\n",
      "  [14/16] iter=800 lr=0.050 depth=6 l2=2 ‚Üí CV RMSE: 0.10\n",
      "  [15/16] iter=800 lr=0.030 depth=6 l2=3 ‚Üí CV RMSE: 0.10\n",
      "  [16/16] iter=800 lr=0.050 depth=6 l2=3 ‚Üí CV RMSE: 0.10\n",
      "\n",
      "‚úì Best params found: {'depth': 6, 'iterations': 500, 'l2_leaf_reg': 2, 'learning_rate': 0.05}\n",
      "  Best CV RMSE: 0.10 ¬± 0.02\n",
      "\n",
      "======================================================================\n",
      "TRAINING FINAL MODEL: valeur_CO\n",
      "======================================================================\n",
      "\n",
      "Fold 1/5 ‚Üí RMSE: 0.07, MAE: 0.06, R¬≤: -0.491\n",
      "\n",
      "Fold 2/5 ‚Üí RMSE: 0.11, MAE: 0.07, R¬≤: 0.034\n",
      "\n",
      "Fold 3/5 ‚Üí RMSE: 0.12, MAE: 0.07, R¬≤: -0.054\n",
      "\n",
      "Fold 4/5 ‚Üí RMSE: 0.09, MAE: 0.06, R¬≤: 0.049\n",
      "\n",
      "Fold 5/5 ‚Üí RMSE: 0.09, MAE: 0.06, R¬≤: -0.325\n",
      "\n",
      "üîß Training final model on full dataset... ‚úì Done\n",
      "\n",
      "üìä Final CV Summary:\n",
      "   RMSE: 0.10 ¬± 0.02\n",
      "   MAE:  0.06 ¬± 0.00\n",
      "   R¬≤:   -0.157 ¬± 0.239\n",
      "\n",
      "\n",
      "######################################################################\n",
      "[3/5] valeur_O3\n",
      "######################################################################\n",
      "\n",
      "======================================================================\n",
      "HYPERPARAMETER TUNING: valeur_O3\n",
      "======================================================================\n",
      "Testing 16 parameter combinations with 5 CV folds\n",
      "\n",
      "  [1/16] iter=500 lr=0.030 depth=5 l2=2 ‚Üí CV RMSE: 22.43\n",
      "  [2/16] iter=500 lr=0.050 depth=5 l2=2 ‚Üí CV RMSE: 22.42\n",
      "  [3/16] iter=500 lr=0.030 depth=5 l2=3 ‚Üí CV RMSE: 22.43\n",
      "  [4/16] iter=500 lr=0.050 depth=5 l2=3 ‚Üí CV RMSE: 22.43\n",
      "  [5/16] iter=800 lr=0.030 depth=5 l2=2 ‚Üí CV RMSE: 22.43\n",
      "  [6/16] iter=800 lr=0.050 depth=5 l2=2 ‚Üí CV RMSE: 22.42\n",
      "  [7/16] iter=800 lr=0.030 depth=5 l2=3 ‚Üí CV RMSE: 22.43\n",
      "  [8/16] iter=800 lr=0.050 depth=5 l2=3 ‚Üí CV RMSE: 22.43\n",
      "  [9/16] iter=500 lr=0.030 depth=6 l2=2 ‚Üí CV RMSE: 22.42\n",
      "  [10/16] iter=500 lr=0.050 depth=6 l2=2 ‚Üí CV RMSE: 22.40\n",
      "  [11/16] iter=500 lr=0.030 depth=6 l2=3 ‚Üí CV RMSE: 22.42\n",
      "  [12/16] iter=500 lr=0.050 depth=6 l2=3 ‚Üí CV RMSE: 22.40\n",
      "  [13/16] iter=800 lr=0.030 depth=6 l2=2 ‚Üí CV RMSE: 22.42\n",
      "  [14/16] iter=800 lr=0.050 depth=6 l2=2 ‚Üí CV RMSE: 22.40\n",
      "  [15/16] iter=800 lr=0.030 depth=6 l2=3 ‚Üí CV RMSE: 22.42\n",
      "  [16/16] iter=800 lr=0.050 depth=6 l2=3 ‚Üí CV RMSE: 22.40\n",
      "\n",
      "‚úì Best params found: {'depth': 6, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.05}\n",
      "  Best CV RMSE: 22.40 ¬± 2.41\n",
      "\n",
      "======================================================================\n",
      "TRAINING FINAL MODEL: valeur_O3\n",
      "======================================================================\n",
      "\n",
      "Fold 1/5 ‚Üí RMSE: 27.01, MAE: 20.92, R¬≤: -0.091\n",
      "\n",
      "Fold 2/5 ‚Üí RMSE: 22.02, MAE: 17.14, R¬≤: 0.159\n",
      "\n",
      "Fold 3/5 ‚Üí RMSE: 21.82, MAE: 17.14, R¬≤: -0.237\n",
      "\n",
      "Fold 4/5 ‚Üí RMSE: 20.03, MAE: 16.23, R¬≤: 0.110\n",
      "\n",
      "Fold 5/5 ‚Üí RMSE: 21.14, MAE: 16.78, R¬≤: 0.030\n",
      "\n",
      "üîß Training final model on full dataset... ‚úì Done\n",
      "\n",
      "üìä Final CV Summary:\n",
      "   RMSE: 22.40 ¬± 2.69\n",
      "   MAE:  17.64 ¬± 1.87\n",
      "   R¬≤:   -0.006 ¬± 0.160\n",
      "\n",
      "\n",
      "######################################################################\n",
      "[4/5] valeur_PM10\n",
      "######################################################################\n",
      "\n",
      "======================================================================\n",
      "HYPERPARAMETER TUNING: valeur_PM10\n",
      "======================================================================\n",
      "Testing 16 parameter combinations with 5 CV folds\n",
      "\n",
      "  [1/16] iter=500 lr=0.030 depth=5 l2=2 ‚Üí CV RMSE: 8.20\n",
      "  [2/16] iter=500 lr=0.050 depth=5 l2=2 ‚Üí CV RMSE: 8.20\n",
      "  [3/16] iter=500 lr=0.030 depth=5 l2=3 ‚Üí CV RMSE: 8.20\n",
      "  [4/16] iter=500 lr=0.050 depth=5 l2=3 ‚Üí CV RMSE: 8.20\n",
      "  [5/16] iter=800 lr=0.030 depth=5 l2=2 ‚Üí CV RMSE: 8.20\n",
      "  [6/16] iter=800 lr=0.050 depth=5 l2=2 ‚Üí CV RMSE: 8.20\n",
      "  [7/16] iter=800 lr=0.030 depth=5 l2=3 ‚Üí CV RMSE: 8.20\n",
      "  [8/16] iter=800 lr=0.050 depth=5 l2=3 ‚Üí CV RMSE: 8.20\n",
      "  [9/16] iter=500 lr=0.030 depth=6 l2=2 ‚Üí CV RMSE: 8.20\n",
      "  [10/16] iter=500 lr=0.050 depth=6 l2=2 ‚Üí CV RMSE: 8.20\n",
      "  [11/16] iter=500 lr=0.030 depth=6 l2=3 ‚Üí CV RMSE: 8.20\n",
      "  [12/16] iter=500 lr=0.050 depth=6 l2=3 ‚Üí CV RMSE: 8.20\n",
      "  [13/16] iter=800 lr=0.030 depth=6 l2=2 ‚Üí CV RMSE: 8.20\n",
      "  [14/16] iter=800 lr=0.050 depth=6 l2=2 ‚Üí CV RMSE: 8.20\n",
      "  [15/16] iter=800 lr=0.030 depth=6 l2=3 ‚Üí CV RMSE: 8.20\n",
      "  [16/16] iter=800 lr=0.050 depth=6 l2=3 ‚Üí CV RMSE: 8.20\n",
      "\n",
      "‚úì Best params found: {'depth': 6, 'iterations': 500, 'l2_leaf_reg': 2, 'learning_rate': 0.05}\n",
      "  Best CV RMSE: 8.20 ¬± 0.86\n",
      "\n",
      "======================================================================\n",
      "TRAINING FINAL MODEL: valeur_PM10\n",
      "======================================================================\n",
      "\n",
      "Fold 1/5 ‚Üí RMSE: 7.58, MAE: 5.67, R¬≤: 0.006\n",
      "\n",
      "Fold 2/5 ‚Üí RMSE: 8.14, MAE: 6.33, R¬≤: -0.119\n",
      "\n",
      "Fold 3/5 ‚Üí RMSE: 9.31, MAE: 7.47, R¬≤: -0.067\n",
      "\n",
      "Fold 4/5 ‚Üí RMSE: 8.98, MAE: 7.36, R¬≤: -0.084\n",
      "\n",
      "Fold 5/5 ‚Üí RMSE: 6.98, MAE: 5.28, R¬≤: -0.025\n",
      "\n",
      "üîß Training final model on full dataset... ‚úì Done\n",
      "\n",
      "üìä Final CV Summary:\n",
      "   RMSE: 8.20 ¬± 0.96\n",
      "   MAE:  6.42 ¬± 0.98\n",
      "   R¬≤:   -0.058 ¬± 0.049\n",
      "\n",
      "\n",
      "######################################################################\n",
      "[5/5] valeur_PM25\n",
      "######################################################################\n",
      "\n",
      "======================================================================\n",
      "HYPERPARAMETER TUNING: valeur_PM25\n",
      "======================================================================\n",
      "Testing 16 parameter combinations with 5 CV folds\n",
      "\n",
      "  [1/16] iter=500 lr=0.030 depth=5 l2=2 ‚Üí CV RMSE: 6.34\n",
      "  [2/16] iter=500 lr=0.050 depth=5 l2=2 ‚Üí CV RMSE: 6.34\n",
      "  [3/16] iter=500 lr=0.030 depth=5 l2=3 ‚Üí CV RMSE: 6.34\n",
      "  [4/16] iter=500 lr=0.050 depth=5 l2=3 ‚Üí CV RMSE: 6.34\n",
      "  [5/16] iter=800 lr=0.030 depth=5 l2=2 ‚Üí CV RMSE: 6.34\n",
      "  [6/16] iter=800 lr=0.050 depth=5 l2=2 ‚Üí CV RMSE: 6.34\n",
      "  [7/16] iter=800 lr=0.030 depth=5 l2=3 ‚Üí CV RMSE: 6.34\n",
      "  [8/16] iter=800 lr=0.050 depth=5 l2=3 ‚Üí CV RMSE: 6.34\n",
      "  [9/16] iter=500 lr=0.030 depth=6 l2=2 ‚Üí CV RMSE: 6.34\n",
      "  [10/16] iter=500 lr=0.050 depth=6 l2=2 ‚Üí CV RMSE: 6.34\n",
      "  [11/16] iter=500 lr=0.030 depth=6 l2=3 ‚Üí CV RMSE: 6.34\n",
      "  [12/16] iter=500 lr=0.050 depth=6 l2=3 ‚Üí CV RMSE: 6.34\n",
      "  [13/16] iter=800 lr=0.030 depth=6 l2=2 ‚Üí CV RMSE: 6.34\n",
      "  [14/16] iter=800 lr=0.050 depth=6 l2=2 ‚Üí CV RMSE: 6.34\n",
      "  [15/16] iter=800 lr=0.030 depth=6 l2=3 ‚Üí CV RMSE: 6.34\n",
      "  [16/16] iter=800 lr=0.050 depth=6 l2=3 ‚Üí CV RMSE: 6.34\n",
      "\n",
      "‚úì Best params found: {'depth': 5, 'iterations': 500, 'l2_leaf_reg': 2, 'learning_rate': 0.03}\n",
      "  Best CV RMSE: 6.34 ¬± 0.59\n",
      "\n",
      "======================================================================\n",
      "TRAINING FINAL MODEL: valeur_PM25\n",
      "======================================================================\n",
      "\n",
      "Fold 1/5 ‚Üí RMSE: 6.17, MAE: 5.01, R¬≤: -0.137\n",
      "\n",
      "Fold 2/5 ‚Üí RMSE: 6.40, MAE: 5.43, R¬≤: -0.269\n",
      "\n",
      "Fold 3/5 ‚Üí RMSE: 7.11, MAE: 5.61, R¬≤: -0.020\n",
      "\n",
      "Fold 4/5 ‚Üí RMSE: 6.67, MAE: 5.38, R¬≤: -0.075\n",
      "\n",
      "Fold 5/5 ‚Üí RMSE: 5.34, MAE: 4.65, R¬≤: -0.452\n",
      "\n",
      "üîß Training final model on full dataset... ‚úì Done\n",
      "\n",
      "üìä Final CV Summary:\n",
      "   RMSE: 6.34 ¬± 0.66\n",
      "   MAE:  5.22 ¬± 0.38\n",
      "   R¬≤:   -0.190 ¬± 0.173\n",
      "\n",
      "\n",
      "======================================================================\n",
      "‚úì Training Complete: 5/5 models successful\n",
      "‚è± Total time: 5.8 minutes\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "FEATURE IMPORTANCE\n",
      "======================================================================\n",
      "\n",
      "valeur_NO2:\n",
      "      feature  importance\n",
      "         hour   21.168607\n",
      "     hour_sin   20.155013\n",
      "     hour_cos   17.465285\n",
      "   is_weekend    9.492320\n",
      "      dow_sin    7.820802\n",
      "   is_holiday    6.640850\n",
      "          dow    6.121559\n",
      "lockdown_code    4.470383\n",
      "       is_day    3.752924\n",
      "      dow_cos    2.912258\n",
      "\n",
      "valeur_CO:\n",
      "      feature  importance\n",
      "         hour   19.235402\n",
      "     hour_sin   17.564036\n",
      "      dow_sin   11.353099\n",
      "lockdown_code    9.612116\n",
      "       is_day    8.948164\n",
      "     hour_cos    8.877635\n",
      "   is_holiday    8.717240\n",
      "          dow    7.031002\n",
      "      dow_cos    6.264781\n",
      "   is_weekend    2.396526\n",
      "\n",
      "valeur_O3:\n",
      "      feature  importance\n",
      "         hour   26.926140\n",
      "     hour_cos   14.354656\n",
      "     hour_sin   12.025196\n",
      "lockdown_code   10.643968\n",
      "   is_holiday   10.399585\n",
      "       is_day    8.457720\n",
      "          dow    6.321777\n",
      "      dow_sin    4.164872\n",
      "      dow_cos    4.015086\n",
      "   is_weekend    2.691001\n",
      "\n",
      "valeur_PM10:\n",
      "      feature  importance\n",
      "         hour   20.201892\n",
      "lockdown_code   18.869731\n",
      "     hour_cos   12.742716\n",
      "     hour_sin   11.883517\n",
      "      dow_sin    8.096438\n",
      "          dow    7.753892\n",
      "      dow_cos    7.636107\n",
      "   is_holiday    7.206450\n",
      "   is_weekend    3.804265\n",
      "       is_day    1.804992\n",
      "\n",
      "valeur_PM25:\n",
      "      feature  importance\n",
      "lockdown_code   33.678121\n",
      "      dow_cos   11.219463\n",
      "     hour_sin   10.810579\n",
      "         hour   10.331284\n",
      "   is_holiday   10.174021\n",
      "      dow_sin    7.421614\n",
      "     hour_cos    5.766119\n",
      "          dow    5.579636\n",
      "       is_day    2.891565\n",
      "   is_weekend    2.127597\n",
      "\n",
      "======================================================================\n",
      "GENERATING PREDICTIONS\n",
      "======================================================================\n",
      "‚úì valeur_NO2: [12.0, 34.9], mean=22.4, median=21.8\n",
      "‚úì valeur_CO: [0.2, 0.3], mean=0.2, median=0.2\n",
      "‚úì valeur_O3: [28.0, 67.8], mean=49.4, median=46.4\n",
      "‚úì valeur_PM10: [13.4, 25.0], mean=18.1, median=18.1\n",
      "‚úì valeur_PM25: [9.1, 14.0], mean=10.9, median=10.8\n",
      "\n",
      "======================================================================\n",
      "SAVING RESULTS\n",
      "======================================================================\n",
      "‚úì Submission saved: submission.csv ((504, 5))\n",
      "‚úì CV scores saved: cv_scores_summary.csv\n",
      "\n",
      "     target  mean_rmse  std_rmse  mean_mae  std_mae   mean_r2   std_r2\n",
      " valeur_NO2  13.692577  1.673898 10.704486 0.847690 -0.071555 0.245034\n",
      "  valeur_CO   0.095678  0.017219  0.062792 0.004897 -0.157289 0.239173\n",
      "  valeur_O3  22.404002  2.690633 17.641576 1.867268 -0.006042 0.160225\n",
      "valeur_PM10   8.198528  0.964870  6.421731 0.982607 -0.057801 0.049064\n",
      "valeur_PM25   6.336211  0.659346  5.217278 0.383668 -0.190340 0.173049\n",
      "‚úì Best hyperparameters saved: best_hyperparameters.csv\n",
      "\n",
      "     target  iterations  learning_rate  depth  l2_leaf_reg\n",
      " valeur_NO2         500           0.05      5            2\n",
      "  valeur_CO         500           0.05      6            2\n",
      "  valeur_O3         500           0.05      6            3\n",
      "valeur_PM10         500           0.05      6            2\n",
      "valeur_PM25         500           0.03      5            2\n",
      "\n",
      "======================================================================\n",
      "‚úÖ PIPELINE COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "üìã Summary:\n",
      "   Models: 5/5 successful\n",
      "   CV Folds: 5\n",
      "   Hyperparameter tuning: 16 combinations\n",
      "   Features: 10 temporal features\n",
      "   Runtime: 5.8 minutes\n",
      "\n",
      "‚ö†Ô∏è  APPROACH:\n",
      "   ‚úì Temporal features only (hour, dow, holidays, etc.)\n",
      "   ‚úì 5-fold time series CV\n",
      "   ‚úì Hyperparameter tuning with limited grid\n",
      "   ‚úó No lags (not available for future dates)\n",
      "   ‚úó No weather data (not available for future dates)\n",
      "\n",
      "üí° Model learns temporal patterns from historical data\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "TARGETS = ['valeur_NO2', 'valeur_CO', 'valeur_O3', 'valeur_PM10', 'valeur_PM25']\n",
    "\n",
    "# Features known at prediction time (TEMPORAL ONLY for purely future dates)\n",
    "TEMPORAL_FEATURES = ['hour', 'is_day', 'hour_sin', 'hour_cos', 'dow', 'dow_sin',\n",
    "                     'dow_cos', 'is_holiday', 'is_weekend', 'lockdown_code']\n",
    "\n",
    "DATE_COL = 'date'\n",
    "\n",
    "# Cross-validation settings\n",
    "N_SPLITS = 5\n",
    "\n",
    "# Hyperparameter tuning grid (limited for speed)\n",
    "CATBOOST_PARAM_GRID = {\n",
    "    'iterations': [500, 800],\n",
    "    'learning_rate': [0.03, 0.05],\n",
    "    'depth': [5, 6],\n",
    "    'l2_leaf_reg': [2, 3]\n",
    "}\n",
    "\n",
    "# Best params found during tuning (will be updated)\n",
    "CATBOOST_BEST_PARAMS = {\n",
    "    'iterations': 500,\n",
    "    'learning_rate': 0.05,\n",
    "    'depth': 6,\n",
    "    'l2_leaf_reg': 3,\n",
    "    'loss_function': 'RMSE',\n",
    "    'eval_metric': 'RMSE',\n",
    "    'random_seed': 42,\n",
    "    'verbose': False,\n",
    "    'early_stopping_rounds': 50,\n",
    "    'task_type': 'CPU',\n",
    "    'thread_count': -1\n",
    "}\n",
    "\n",
    "# =============================================================================\n",
    "# LOAD AND PREPARE DATA\n",
    "# =============================================================================\n",
    "print(\"=\"*70)\n",
    "print(\"CATBOOST PIPELINE - PURELY FUTURE FORECASTING\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n‚ö†Ô∏è  Approach: TEMPORAL FEATURES ONLY (no lags, purely future dates)\")\n",
    "\n",
    "train_df = pd.read_csv(\"../data/train_features.csv\")\n",
    "test_df = pd.read_csv(\"../data/test_features_to_predict.csv\")\n",
    "\n",
    "print(f\"\\n‚úì Loaded train: {train_df.shape}\")\n",
    "print(f\"‚úì Loaded test: {test_df.shape}\")\n",
    "\n",
    "# Convert and sort by date\n",
    "if DATE_COL in train_df.columns:\n",
    "    train_df[DATE_COL] = pd.to_datetime(train_df[DATE_COL])\n",
    "    train_df = train_df.sort_values(DATE_COL).reset_index(drop=True)\n",
    "\n",
    "if DATE_COL in test_df.columns:\n",
    "    test_df[DATE_COL] = pd.to_datetime(test_df[DATE_COL])\n",
    "    test_df = test_df.sort_values(DATE_COL).reset_index(drop=True)\n",
    "\n",
    "# =============================================================================\n",
    "# FEATURE PREPARATION - TEMPORAL ONLY\n",
    "# =============================================================================\n",
    "def prepare_features_for_target():\n",
    "    \"\"\"\n",
    "    For PURELY FUTURE predictions: Use ONLY temporal features.\n",
    "\n",
    "    No lags available because:\n",
    "    - No historical pollution data for future dates\n",
    "    - No weather data (forecasts not included)\n",
    "\n",
    "    What we CAN use:\n",
    "    - Time-based patterns (hour, day of week, holidays, etc.)\n",
    "    - Model learns from historical temporal patterns in training\n",
    "    \"\"\"\n",
    "    return TEMPORAL_FEATURES\n",
    "\n",
    "# Display features\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"FEATURE CONFIGURATION - PURELY FUTURE FORECASTING\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "features = prepare_features_for_target()\n",
    "print(f\"\\nFeatures for prediction: {len(features)}\")\n",
    "for i, f in enumerate(features, 1):\n",
    "    print(f\"  {i}. {f}\")\n",
    "\n",
    "# Clean training data - remove rows with missing temporal features\n",
    "train_clean = train_df[TEMPORAL_FEATURES + TARGETS].dropna().reset_index(drop=True)\n",
    "print(f\"\\n‚úì Clean train samples: {len(train_clean)}\")\n",
    "\n",
    "# =============================================================================\n",
    "# TIME SERIES CROSS-VALIDATION (5 SPLITS)\n",
    "# =============================================================================\n",
    "def time_series_cv_split(df, n_splits=5):\n",
    "    \"\"\"Time series expanding window CV with multiple splits.\"\"\"\n",
    "    n = len(df)\n",
    "    min_train_size = int(n * 0.4)  # Minimum 40% for training\n",
    "\n",
    "    splits = []\n",
    "\n",
    "    # Create n_splits by expanding the validation window\n",
    "    test_size = int(n * 0.1)  # 10% per fold\n",
    "\n",
    "    for i in range(n_splits):\n",
    "        val_end = n - (n_splits - i - 1) * (test_size // 2)\n",
    "        val_start = max(min_train_size, val_end - test_size)\n",
    "        train_end = val_start\n",
    "\n",
    "        if train_end < min_train_size or val_start >= val_end:\n",
    "            continue\n",
    "\n",
    "        train_idx = df.index[:train_end]\n",
    "        val_idx = df.index[val_start:val_end]\n",
    "        splits.append((train_idx, val_idx))\n",
    "\n",
    "    return splits\n",
    "\n",
    "# =============================================================================\n",
    "# HYPERPARAMETER TUNING\n",
    "# =============================================================================\n",
    "def tune_hyperparameters(df, target_col, param_grid, cv_splits):\n",
    "    \"\"\"\n",
    "    Quick hyperparameter tuning using CV.\n",
    "    Evaluates each param combination on CV folds.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"HYPERPARAMETER TUNING: {target_col}\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    best_rmse = float('inf')\n",
    "    best_params = None\n",
    "    best_cv_scores = []\n",
    "\n",
    "    param_combinations = list(ParameterGrid(param_grid))\n",
    "    print(f\"Testing {len(param_combinations)} parameter combinations with {len(cv_splits)} CV folds\\n\")\n",
    "\n",
    "    for combo_idx, params in enumerate(param_combinations, 1):\n",
    "        fold_rmses = []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(cv_splits, 1):\n",
    "            try:\n",
    "                train_data = df.loc[train_idx]\n",
    "                val_data = df.loc[val_idx]\n",
    "\n",
    "                X_train = train_data[TEMPORAL_FEATURES]\n",
    "                y_train = train_data[target_col]\n",
    "                X_val = val_data[TEMPORAL_FEATURES]\n",
    "                y_val = val_data[target_col]\n",
    "\n",
    "                # Create model with current params\n",
    "                model_params = {\n",
    "                    'iterations': params['iterations'],\n",
    "                    'learning_rate': params['learning_rate'],\n",
    "                    'depth': params['depth'],\n",
    "                    'l2_leaf_reg': params['l2_leaf_reg'],\n",
    "                    'loss_function': 'RMSE',\n",
    "                    'eval_metric': 'RMSE',\n",
    "                    'random_seed': 42,\n",
    "                    'verbose': False,\n",
    "                    'early_stopping_rounds': 30,\n",
    "                    'task_type': 'CPU',\n",
    "                    'thread_count': -1\n",
    "                }\n",
    "\n",
    "                train_pool = Pool(X_train, y_train)\n",
    "                val_pool = Pool(X_val, y_val)\n",
    "\n",
    "                model = CatBoostRegressor(**model_params)\n",
    "                model.fit(train_pool, eval_set=val_pool, use_best_model=True, plot=False)\n",
    "\n",
    "                predictions = model.predict(X_val)\n",
    "                predictions = np.maximum(predictions, 0)\n",
    "\n",
    "                rmse = np.sqrt(mean_squared_error(y_val, predictions))\n",
    "                fold_rmses.append(rmse)\n",
    "\n",
    "            except Exception as e:\n",
    "                fold_rmses.append(float('inf'))\n",
    "\n",
    "        mean_rmse = np.mean(fold_rmses)\n",
    "\n",
    "        print(f\"  [{combo_idx}/{len(param_combinations)}] \"\n",
    "              f\"iter={params['iterations']:>3} lr={params['learning_rate']:.3f} \"\n",
    "              f\"depth={params['depth']} l2={params['l2_leaf_reg']} ‚Üí \"\n",
    "              f\"CV RMSE: {mean_rmse:.2f}\")\n",
    "\n",
    "        if mean_rmse < best_rmse:\n",
    "            best_rmse = mean_rmse\n",
    "            best_params = params\n",
    "            best_cv_scores = fold_rmses\n",
    "\n",
    "    print(f\"\\n‚úì Best params found: {best_params}\")\n",
    "    print(f\"  Best CV RMSE: {best_rmse:.2f} ¬± {np.std(best_cv_scores):.2f}\")\n",
    "\n",
    "    return best_params, best_rmse, best_cv_scores\n",
    "\n",
    "# =============================================================================\n",
    "# TRAIN FINAL MODELS WITH BEST PARAMS\n",
    "# =============================================================================\n",
    "def train_final_model(df, target_col, best_params, cv_splits):\n",
    "    \"\"\"Train final model using best hyperparameters with CV evaluation.\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"TRAINING FINAL MODEL: {target_col}\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    cv_scores = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv_splits, 1):\n",
    "        print(f\"\\nFold {fold}/{len(cv_splits)}\", end=\" \")\n",
    "\n",
    "        train_data = df.loc[train_idx]\n",
    "        val_data = df.loc[val_idx]\n",
    "\n",
    "        X_train = train_data[TEMPORAL_FEATURES]\n",
    "        y_train = train_data[target_col]\n",
    "        X_val = val_data[TEMPORAL_FEATURES]\n",
    "        y_val = val_data[target_col]\n",
    "\n",
    "        model_params = {\n",
    "            'iterations': best_params['iterations'],\n",
    "            'learning_rate': best_params['learning_rate'],\n",
    "            'depth': best_params['depth'],\n",
    "            'l2_leaf_reg': best_params['l2_leaf_reg'],\n",
    "            'loss_function': 'RMSE',\n",
    "            'eval_metric': 'RMSE',\n",
    "            'random_seed': 42,\n",
    "            'verbose': False,\n",
    "            'early_stopping_rounds': 30,\n",
    "            'task_type': 'CPU',\n",
    "            'thread_count': -1\n",
    "        }\n",
    "\n",
    "        train_pool = Pool(X_train, y_train)\n",
    "        val_pool = Pool(X_val, y_val)\n",
    "\n",
    "        model = CatBoostRegressor(**model_params)\n",
    "        model.fit(train_pool, eval_set=val_pool, use_best_model=True, plot=False)\n",
    "\n",
    "        predictions = model.predict(X_val)\n",
    "        predictions = np.maximum(predictions, 0)\n",
    "\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, predictions))\n",
    "        mae = mean_absolute_error(y_val, predictions)\n",
    "        r2 = r2_score(y_val, predictions)\n",
    "\n",
    "        cv_scores.append({'fold': fold, 'rmse': rmse, 'mae': mae, 'r2': r2})\n",
    "        print(f\"‚Üí RMSE: {rmse:.2f}, MAE: {mae:.2f}, R¬≤: {r2:.3f}\")\n",
    "\n",
    "    # Train final model on ALL data\n",
    "    print(f\"\\nüîß Training final model on full dataset...\", end=\" \")\n",
    "    X_full = df[TEMPORAL_FEATURES]\n",
    "    y_full = df[target_col]\n",
    "\n",
    "    model_params = {\n",
    "        'iterations': best_params['iterations'],\n",
    "        'learning_rate': best_params['learning_rate'],\n",
    "        'depth': best_params['depth'],\n",
    "        'l2_leaf_reg': best_params['l2_leaf_reg'],\n",
    "        'loss_function': 'RMSE',\n",
    "        'eval_metric': 'RMSE',\n",
    "        'random_seed': 42,\n",
    "        'verbose': False,\n",
    "        'task_type': 'CPU',\n",
    "        'thread_count': -1\n",
    "    }\n",
    "\n",
    "    full_pool = Pool(X_full, y_full)\n",
    "    final_model = CatBoostRegressor(**model_params)\n",
    "    final_model.fit(full_pool, plot=False)\n",
    "\n",
    "    print(f\"‚úì Done\")\n",
    "\n",
    "    return final_model, cv_scores\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN PIPELINE\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"SETTING UP CROSS-VALIDATION\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "cv_splits = time_series_cv_split(train_clean, n_splits=N_SPLITS)\n",
    "print(f\"‚úì Created {len(cv_splits)} time series CV splits\")\n",
    "\n",
    "# Store results\n",
    "models = {}\n",
    "all_best_params = {}\n",
    "all_cv_scores = {}\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "for i, target in enumerate(TARGETS, 1):\n",
    "    print(f\"\\n\\n{'#'*70}\")\n",
    "    print(f\"[{i}/{len(TARGETS)}] {target}\")\n",
    "    print(f\"{'#'*70}\")\n",
    "\n",
    "    try:\n",
    "        # Hyperparameter tuning\n",
    "        best_params, _, _ = tune_hyperparameters(\n",
    "            train_clean,\n",
    "            target,\n",
    "            CATBOOST_PARAM_GRID,\n",
    "            cv_splits\n",
    "        )\n",
    "        all_best_params[target] = best_params\n",
    "\n",
    "        # Train final model with best params\n",
    "        model, cv_scores = train_final_model(\n",
    "            train_clean,\n",
    "            target,\n",
    "            best_params,\n",
    "            cv_splits\n",
    "        )\n",
    "        models[target] = model\n",
    "        all_cv_scores[target] = cv_scores\n",
    "\n",
    "        # Print summary\n",
    "        cv_df = pd.DataFrame(cv_scores)\n",
    "        print(f\"\\nüìä Final CV Summary:\")\n",
    "        print(f\"   RMSE: {cv_df['rmse'].mean():.2f} ¬± {cv_df['rmse'].std():.2f}\")\n",
    "        print(f\"   MAE:  {cv_df['mae'].mean():.2f} ¬± {cv_df['mae'].std():.2f}\")\n",
    "        print(f\"   R¬≤:   {cv_df['r2'].mean():.3f} ¬± {cv_df['r2'].std():.3f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚úó Failed: {str(e)[:100]}\")\n",
    "        models[target] = None\n",
    "        all_best_params[target] = None\n",
    "        all_cv_scores[target] = []\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "successful = sum(1 for m in models.values() if m is not None)\n",
    "\n",
    "print(f\"\\n\\n{'='*70}\")\n",
    "print(f\"‚úì Training Complete: {successful}/{len(TARGETS)} models successful\")\n",
    "print(f\"‚è± Total time: {elapsed/60:.1f} minutes\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# =============================================================================\n",
    "# FEATURE IMPORTANCE\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"FEATURE IMPORTANCE\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "for target in TARGETS:\n",
    "    if models[target] is not None:\n",
    "        feature_importance = models[target].get_feature_importance()\n",
    "\n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': TEMPORAL_FEATURES,\n",
    "            'importance': feature_importance\n",
    "        }).sort_values('importance', ascending=False)\n",
    "\n",
    "        print(f\"\\n{target}:\")\n",
    "        print(importance_df.to_string(index=False))\n",
    "\n",
    "# =============================================================================\n",
    "# PREDICTIONS ON TEST SET\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"GENERATING PREDICTIONS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "if DATE_COL in test_df.columns:\n",
    "    predictions_df = test_df[[DATE_COL]].copy()\n",
    "else:\n",
    "    predictions_df = pd.DataFrame(index=test_df.index)\n",
    "\n",
    "X_test = test_df[TEMPORAL_FEATURES].fillna(0)\n",
    "\n",
    "for target in TARGETS:\n",
    "    if models[target] is None:\n",
    "        print(f\"‚úó {target}: No model\")\n",
    "        predictions_df[target] = 0\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        preds = models[target].predict(X_test)\n",
    "        preds = np.maximum(preds, 0)\n",
    "        predictions_df[target] = preds\n",
    "        print(f\"‚úì {target}: [{preds.min():.1f}, {preds.max():.1f}], \"\n",
    "              f\"mean={preds.mean():.1f}, median={np.median(preds):.1f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚úó {target}: {str(e)[:50]}\")\n",
    "        predictions_df[target] = 0\n",
    "\n",
    "# =============================================================================\n",
    "# SAVE RESULTS\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"SAVING RESULTS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "predictions_df.to_csv('submission.csv', index=False)\n",
    "print(f\"‚úì Submission saved: submission.csv ({predictions_df.shape})\")\n",
    "\n",
    "# Save CV scores summary\n",
    "cv_summary = []\n",
    "for target, scores in all_cv_scores.items():\n",
    "    if scores:\n",
    "        cv_df = pd.DataFrame(scores)\n",
    "        cv_summary.append({\n",
    "            'target': target,\n",
    "            'mean_rmse': cv_df['rmse'].mean(),\n",
    "            'std_rmse': cv_df['rmse'].std(),\n",
    "            'mean_mae': cv_df['mae'].mean(),\n",
    "            'std_mae': cv_df['mae'].std(),\n",
    "            'mean_r2': cv_df['r2'].mean(),\n",
    "            'std_r2': cv_df['r2'].std()\n",
    "        })\n",
    "\n",
    "if cv_summary:\n",
    "    cv_summary_df = pd.DataFrame(cv_summary)\n",
    "    cv_summary_df.to_csv('cv_scores_summary.csv', index=False)\n",
    "    print(f\"‚úì CV scores saved: cv_scores_summary.csv\\n\")\n",
    "    print(cv_summary_df.to_string(index=False))\n",
    "\n",
    "# Save best hyperparameters\n",
    "params_summary = []\n",
    "for target, params in all_best_params.items():\n",
    "    if params:\n",
    "        params_summary.append({\n",
    "            'target': target,\n",
    "            'iterations': params['iterations'],\n",
    "            'learning_rate': params['learning_rate'],\n",
    "            'depth': params['depth'],\n",
    "            'l2_leaf_reg': params['l2_leaf_reg']\n",
    "        })\n",
    "\n",
    "if params_summary:\n",
    "    params_df = pd.DataFrame(params_summary)\n",
    "    params_df.to_csv('best_hyperparameters.csv', index=False)\n",
    "    print(f\"‚úì Best hyperparameters saved: best_hyperparameters.csv\\n\")\n",
    "    print(params_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"‚úÖ PIPELINE COMPLETE!\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nüìã Summary:\")\n",
    "print(f\"   Models: {successful}/{len(TARGETS)} successful\")\n",
    "print(f\"   CV Folds: {N_SPLITS}\")\n",
    "print(f\"   Hyperparameter tuning: {len(list(ParameterGrid(CATBOOST_PARAM_GRID)))} combinations\")\n",
    "print(f\"   Features: {len(TEMPORAL_FEATURES)} temporal features\")\n",
    "print(f\"   Runtime: {elapsed/60:.1f} minutes\")\n",
    "print(f\"\\n‚ö†Ô∏è  APPROACH:\")\n",
    "print(f\"   ‚úì Temporal features only (hour, dow, holidays, etc.)\")\n",
    "print(f\"   ‚úì {N_SPLITS}-fold time series CV\")\n",
    "print(f\"   ‚úì Hyperparameter tuning with limited grid\")\n",
    "print(f\"   ‚úó No lags (not available for future dates)\")\n",
    "print(f\"   ‚úó No weather data (not available for future dates)\")\n",
    "print(f\"\\nüí° Model learns temporal patterns from historical data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912c36d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CATBOOST AUTOREGRESSIVE PIPELINE - FUTURE PREDICTIONS\n",
      "======================================================================\n",
      "\n",
      "‚úì Loaded train: (40991, 213)\n",
      "‚úì Loaded test: (504, 208)\n",
      "\n",
      "‚úì Autoregressive features: 10\n",
      "  - Temporal: 10\n",
      "  - Weather (current): 0\n",
      "  - Pollutant lags: 0\n",
      "\n",
      "‚úì Clean train samples: 40991\n",
      "\n",
      "======================================================================\n",
      "TRAINING AUTOREGRESSIVE MODELS\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "Training: valeur_NO2\n",
      "======================================================================\n",
      "Fold 1/2 - Train: 31769, Val: 6148 ‚Üí RMSE: 14.73, MAE: 10.50, R¬≤: 0.117\n",
      "Fold 2/2 - Train: 34843, Val: 6148 ‚Üí RMSE: 12.31, MAE: 10.27, R¬≤: -0.105\n",
      "Training final model... ‚úì CV: RMSE=13.52¬±1.71\n",
      "\n",
      "======================================================================\n",
      "Training: valeur_CO\n",
      "======================================================================\n",
      "Fold 1/2 - Train: 31769, Val: 6148 ‚Üí RMSE: 0.11, MAE: 0.06, R¬≤: 0.010\n",
      "Fold 2/2 - Train: 34843, Val: 6148 ‚Üí RMSE: 0.10, MAE: 0.06, R¬≤: -0.024\n",
      "Training final model... ‚úì CV: RMSE=0.10¬±0.01\n",
      "\n",
      "======================================================================\n",
      "Training: valeur_O3\n",
      "======================================================================\n",
      "Fold 1/2 - Train: 31769, Val: 6148 ‚Üí RMSE: 21.93, MAE: 17.40, R¬≤: 0.086\n",
      "Fold 2/2 - Train: 34843, Val: 6148 ‚Üí RMSE: 20.50, MAE: 16.19, R¬≤: 0.131\n",
      "Training final model... ‚úì CV: RMSE=21.21¬±1.01\n",
      "\n",
      "======================================================================\n",
      "Training: valeur_PM10\n",
      "======================================================================\n",
      "Fold 1/2 - Train: 31769, Val: 6148 ‚Üí RMSE: 8.92, MAE: 7.15, R¬≤: -0.067\n",
      "Fold 2/2 - Train: 34843, Val: 6148 ‚Üí RMSE: 8.00, MAE: 6.15, R¬≤: -0.031\n",
      "Training final model... ‚úì CV: RMSE=8.46¬±0.65\n",
      "\n",
      "======================================================================\n",
      "Training: valeur_PM25\n",
      "======================================================================\n",
      "Fold 1/2 - Train: 31769, Val: 6148 ‚Üí RMSE: 6.75, MAE: 5.48, R¬≤: -0.083\n",
      "Fold 2/2 - Train: 34843, Val: 6148 ‚Üí RMSE: 6.15, MAE: 5.03, R¬≤: -0.143\n",
      "Training final model... ‚úì CV: RMSE=6.45¬±0.42\n",
      "\n",
      "======================================================================\n",
      "‚úì Training Complete\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "AUTOREGRESSIVE FORECASTING - 24 steps ahead\n",
      "======================================================================\n",
      "Step 1/24 - Predictions: NO2=23.1, CO=0.2, O3=46.8, PM10=17.3, PM25=11.1\n",
      "Step 6/24 - Predictions: NO2=18.3, CO=0.2, O3=42.4, PM10=14.8, PM25=9.6\n",
      "Step 12/24 - Predictions: NO2=26.0, CO=0.2, O3=45.0, PM10=22.3, PM25=11.8\n",
      "Step 18/24 - Predictions: NO2=21.1, CO=0.2, O3=58.4, PM10=19.1, PM25=10.2\n",
      "Step 24/24 - Predictions: NO2=25.5, CO=0.2, O3=46.8, PM10=18.1, PM25=11.9\n",
      "\n",
      "======================================================================\n",
      "FORECAST SUMMARY\n",
      "======================================================================\n",
      "            step  valeur_NO2  valeur_CO  valeur_O3  valeur_PM10  valeur_PM25\n",
      "count  24.000000   24.000000  24.000000  24.000000    24.000000    24.000000\n",
      "mean   12.500000   23.781317   0.213582  47.070109    18.431206    11.028589\n",
      "std     7.071068    4.546202   0.019319   8.787821     2.222146     1.004800\n",
      "min     1.000000   17.421184   0.188615  30.211699    14.748068     9.528930\n",
      "25%     6.750000   19.655356   0.197454  44.318373    16.959527    10.267577\n",
      "50%    12.500000   23.316220   0.211082  46.994221    18.885142    10.994059\n",
      "75%    18.250000   26.918827   0.224114  53.907572    19.589408    11.633745\n",
      "max    24.000000   32.433880   0.256959  59.214804    22.445058    13.149058\n",
      "\n",
      "======================================================================\n",
      "SAVING RESULTS\n",
      "======================================================================\n",
      "‚úì Forecast saved: autoregressive_forecast.csv ((24, 6))\n",
      "‚úì CV scores saved: cv_scores_autoregressive.csv\n",
      "\n",
      "üìä VALIDATION RESULTS:\n",
      "     target  mean_rmse  std_rmse  mean_mae  std_mae   mean_r2   std_r2\n",
      " valeur_NO2  13.519646  1.713668 10.387004 0.159969  0.005986 0.157637\n",
      "  valeur_CO   0.101393  0.005649  0.061452 0.001138 -0.007294 0.023863\n",
      "  valeur_O3  21.214064  1.007180 16.793933 0.852381  0.108670 0.031414\n",
      "valeur_PM10   8.461425  0.652241  6.649621 0.706660 -0.048876 0.025498\n",
      "valeur_PM25   6.452036  0.421028  5.255040 0.322882 -0.113234 0.042755\n",
      "\n",
      "======================================================================\n",
      "‚úÖ AUTOREGRESSIVE FORECASTING COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "üí° Configuration:\n",
      "   Forecast Horizon: 24 hours\n",
      "   Features: Temporal + Current Weather + Recent Pollutant Lags (1-3)\n",
      "   Approach: Step-by-step predictions using previous outputs as inputs\n",
      "   Predictions: 24 steps √ó 5 pollutants\n",
      "\n",
      "‚ö†Ô∏è  NOTES:\n",
      "   ‚úì Can forecast multiple hours ahead\n",
      "   ‚úì Uses temporal continuity through lag features\n",
      "   ‚úó Error accumulates over longer horizons (24+ hours may degrade)\n",
      "   ‚úó Depends on accurate weather data for each step ahead\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "TARGETS = ['valeur_NO2', 'valeur_CO', 'valeur_O3', 'valeur_PM10', 'valeur_PM25']\n",
    "\n",
    "TEMPORAL_FEATURES = ['hour', 'is_day', 'hour_sin', 'hour_cos', 'dow', 'dow_sin',\n",
    "                     'dow_cos', 'is_holiday', 'is_weekend', 'lockdown_code']\n",
    "\n",
    "WEATHER_BASE = [\n",
    "    'temperature_2m', 'relative_humidity_2m', 'dew_point_2m', 'apparent_temperature',\n",
    "    'pressure_msl', 'wind_speed_10m', 'wind_direction_10m', 'precipitation',\n",
    "    'cloud_cover', 'cloud_cover_low', 'cloud_cover_mid', 'cloud_cover_high',\n",
    "    'shortwave_radiation', 'direct_radiation', 'diffuse_radiation',\n",
    "    'global_tilted_irradiance', 'wind_gusts_10m', 'vapour_pressure_deficit',\n",
    "    'et0_fao_evapotranspiration', 'snowfall', 'rain', 'showers', 'weather_code'\n",
    "]\n",
    "\n",
    "DATE_COL = 'date'\n",
    "\n",
    "N_SPLITS = 2\n",
    "TEST_SIZE_RATIO = 0.15\n",
    "\n",
    "CATBOOST_PARAMS = {\n",
    "    'iterations': 1000,\n",
    "    'learning_rate': 0.05,\n",
    "    'depth': 6,\n",
    "    'l2_leaf_reg': 3,\n",
    "    'loss_function': 'RMSE',\n",
    "    'eval_metric': 'RMSE',\n",
    "    'random_seed': 42,\n",
    "    'verbose': False,\n",
    "    'early_stopping_rounds': 50,\n",
    "    'task_type': 'CPU',\n",
    "    'thread_count': -1\n",
    "}\n",
    "\n",
    "# Autoregressive settings\n",
    "FORECAST_HORIZON = 24  # Hours ahead to forecast\n",
    "LOOKBACK_WINDOW = 24   # Hours of history to use\n",
    "\n",
    "# =============================================================================\n",
    "# LOAD AND PREPARE DATA\n",
    "# =============================================================================\n",
    "print(\"=\"*70)\n",
    "print(\"CATBOOST AUTOREGRESSIVE PIPELINE - FUTURE PREDICTIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "train_df = pd.read_csv(\"../data/train_features.csv\")\n",
    "test_df = pd.read_csv(\"../data/test_features_to_predict.csv\")\n",
    "\n",
    "print(f\"\\n‚úì Loaded train: {train_df.shape}\")\n",
    "print(f\"‚úì Loaded test: {test_df.shape}\")\n",
    "\n",
    "if DATE_COL in train_df.columns:\n",
    "    train_df[DATE_COL] = pd.to_datetime(train_df[DATE_COL])\n",
    "    train_df = train_df.sort_values(DATE_COL).reset_index(drop=True)\n",
    "\n",
    "if DATE_COL in test_df.columns:\n",
    "    test_df[DATE_COL] = pd.to_datetime(test_df[DATE_COL])\n",
    "    test_df = test_df.sort_values(DATE_COL).reset_index(drop=True)\n",
    "\n",
    "# =============================================================================\n",
    "# AUTOREGRESSIVE FEATURE PREPARATION\n",
    "# =============================================================================\n",
    "def get_autoregressive_features():\n",
    "    \"\"\"\n",
    "    Features for autoregressive prediction:\n",
    "    - Temporal features (we know these at prediction time)\n",
    "    - Current weather (assuming we have forecast or current data)\n",
    "    - Recent history of all pollutants (lag 1, 2, 3)\n",
    "    \"\"\"\n",
    "    features = []\n",
    "\n",
    "    # Temporal features\n",
    "    features.extend(TEMPORAL_FEATURES)\n",
    "\n",
    "    # Current weather (not lagged - we know this)\n",
    "    features.extend(WEATHER_BASE)\n",
    "\n",
    "    # Recent pollutant history (short lags that work for step-ahead)\n",
    "    for target in TARGETS:\n",
    "        features.extend([\n",
    "            f'{target}_lag_1',\n",
    "            f'{target}_lag_2',\n",
    "            f'{target}_lag_3'\n",
    "        ])\n",
    "\n",
    "    return features\n",
    "\n",
    "def prepare_autoregressive_data(df):\n",
    "    \"\"\"Prepare data for autoregressive training.\"\"\"\n",
    "    features = get_autoregressive_features()\n",
    "    available_features = [f for f in features if f in df.columns]\n",
    "\n",
    "    return available_features\n",
    "\n",
    "# Get feature list\n",
    "feature_cols = prepare_autoregressive_data(train_df)\n",
    "print(f\"\\n‚úì Autoregressive features: {len(feature_cols)}\")\n",
    "print(f\"  - Temporal: {len([f for f in feature_cols if f in TEMPORAL_FEATURES])}\")\n",
    "print(f\"  - Weather (current): {len([f for f in feature_cols if any(w in f for w in WEATHER_BASE)])}\")\n",
    "print(f\"  - Pollutant lags: {len([f for f in feature_cols if 'valeur_' in f and '_lag_' in f])}\")\n",
    "\n",
    "# Clean training data\n",
    "train_clean = train_df[feature_cols + TARGETS].dropna().reset_index(drop=True)\n",
    "print(f\"\\n‚úì Clean train samples: {len(train_clean)}\")\n",
    "\n",
    "# =============================================================================\n",
    "# TRAIN MODELS\n",
    "# =============================================================================\n",
    "def train_models(df, feature_cols, n_splits=2):\n",
    "    \"\"\"Train one model per target using autoregressive features.\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"TRAINING AUTOREGRESSIVE MODELS\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    splits = []\n",
    "    n = len(df)\n",
    "    test_size = int(n * TEST_SIZE_RATIO)\n",
    "    min_train_size = int(n * 0.6)\n",
    "\n",
    "    for i in range(n_splits):\n",
    "        val_end = n - (n_splits - i - 1) * (test_size // 2)\n",
    "        val_start = val_end - test_size\n",
    "        train_end = val_start\n",
    "\n",
    "        if train_end < min_train_size:\n",
    "            continue\n",
    "\n",
    "        train_idx = df.index[:train_end]\n",
    "        val_idx = df.index[val_start:val_end]\n",
    "        splits.append((train_idx, val_idx))\n",
    "\n",
    "    models = {}\n",
    "    cv_scores_all = {}\n",
    "\n",
    "    for target in TARGETS:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Training: {target}\")\n",
    "        print(f\"{'='*70}\")\n",
    "\n",
    "        cv_scores = []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(splits, 1):\n",
    "            print(f\"Fold {fold}/{len(splits)} - Train: {len(train_idx)}, Val: {len(val_idx)}\", end=\" \")\n",
    "\n",
    "            X_train = df.loc[train_idx, feature_cols].fillna(0)\n",
    "            y_train = df.loc[train_idx, target]\n",
    "            X_val = df.loc[val_idx, feature_cols].fillna(0)\n",
    "            y_val = df.loc[val_idx, target]\n",
    "\n",
    "            try:\n",
    "                train_pool = Pool(X_train, y_train)\n",
    "                val_pool = Pool(X_val, y_val)\n",
    "\n",
    "                model = CatBoostRegressor(**CATBOOST_PARAMS)\n",
    "                model.fit(train_pool, eval_set=val_pool, use_best_model=True, plot=False)\n",
    "\n",
    "                preds = np.maximum(model.predict(X_val), 0)\n",
    "                rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
    "                mae = mean_absolute_error(y_val, preds)\n",
    "                r2 = r2_score(y_val, preds)\n",
    "\n",
    "                cv_scores.append({\n",
    "                    'fold': fold,\n",
    "                    'rmse': rmse,\n",
    "                    'mae': mae,\n",
    "                    'r2': r2,\n",
    "                    'best_iteration': model.get_best_iteration()\n",
    "                })\n",
    "\n",
    "                print(f\"‚Üí RMSE: {rmse:.2f}, MAE: {mae:.2f}, R¬≤: {r2:.3f}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚úó Error: {str(e)[:50]}\")\n",
    "                continue\n",
    "\n",
    "        # Train final model on all data\n",
    "        print(f\"Training final model...\", end=\" \")\n",
    "        X_full = df[feature_cols].fillna(0)\n",
    "        y_full = df[target]\n",
    "        full_pool = Pool(X_full, y_full)\n",
    "\n",
    "        final_model = CatBoostRegressor(**CATBOOST_PARAMS)\n",
    "        final_model.fit(full_pool, plot=False)\n",
    "\n",
    "        models[target] = final_model\n",
    "        cv_scores_all[target] = cv_scores\n",
    "\n",
    "        if cv_scores:\n",
    "            cv_df = pd.DataFrame(cv_scores)\n",
    "            print(f\"‚úì CV: RMSE={cv_df['rmse'].mean():.2f}¬±{cv_df['rmse'].std():.2f}\")\n",
    "\n",
    "    return models, cv_scores_all\n",
    "\n",
    "models, cv_scores_all = train_models(train_clean, feature_cols)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"‚úì Training Complete\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# =============================================================================\n",
    "# AUTOREGRESSIVE FORECASTING\n",
    "# =============================================================================\n",
    "def autoregressive_forecast(df_init, models, feature_cols, horizon=24):\n",
    "    \"\"\"\n",
    "    Forecast multiple steps ahead using autoregressive approach.\n",
    "\n",
    "    For each step:\n",
    "    1. Use current features (temporal + weather)\n",
    "    2. Use previous predictions as input for next step\n",
    "    3. Predict all targets for this step\n",
    "    4. Move to next timestep\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"AUTOREGRESSIVE FORECASTING - {horizon} steps ahead\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    # Start from the last known data\n",
    "    current_state = df_init.iloc[-1:].copy()\n",
    "    all_predictions = []\n",
    "\n",
    "    for step in range(horizon):\n",
    "        step_preds = {'step': step + 1}\n",
    "\n",
    "        # Get features for this step\n",
    "        X_current = current_state[feature_cols].fillna(0)\n",
    "\n",
    "        # Predict all targets\n",
    "        for target in TARGETS:\n",
    "            if models[target] is not None:\n",
    "                pred = np.maximum(models[target].predict(X_current)[0], 0)\n",
    "                step_preds[target] = pred\n",
    "            else:\n",
    "                step_preds[target] = 0\n",
    "\n",
    "        all_predictions.append(step_preds)\n",
    "\n",
    "        # Update state for next iteration\n",
    "        # Shift lags: lag_1 becomes lag_2, current becomes lag_1\n",
    "        new_state = current_state.copy()\n",
    "\n",
    "        for target in TARGETS:\n",
    "            if f'{target}_lag_3' in new_state.columns:\n",
    "                new_state[f'{target}_lag_3'] = new_state[f'{target}_lag_2'].values[0]\n",
    "            if f'{target}_lag_2' in new_state.columns:\n",
    "                new_state[f'{target}_lag_2'] = new_state[f'{target}_lag_1'].values[0]\n",
    "            if f'{target}_lag_1' in new_state.columns:\n",
    "                new_state[f'{target}_lag_1'] = step_preds[target]\n",
    "\n",
    "        # Update temporal features for next hour\n",
    "        if DATE_COL in new_state.columns:\n",
    "            new_state[DATE_COL] = new_state[DATE_COL] + pd.Timedelta(hours=1)\n",
    "\n",
    "        # Update hour-related features (this is simplified - adjust based on your feature engineering)\n",
    "        if 'hour' in new_state.columns:\n",
    "            new_state['hour'] = (new_state['hour'].values[0] + 1) % 24\n",
    "            # Recalculate hour_sin, hour_cos if they exist\n",
    "            if 'hour_sin' in new_state.columns:\n",
    "                new_state['hour_sin'] = np.sin(2 * np.pi * new_state['hour'] / 24)\n",
    "            if 'hour_cos' in new_state.columns:\n",
    "                new_state['hour_cos'] = np.cos(2 * np.pi * new_state['hour'] / 24)\n",
    "\n",
    "        current_state = new_state\n",
    "\n",
    "        if (step + 1) % 6 == 0 or step == 0:\n",
    "            print(f\"Step {step + 1}/{horizon} - Predictions: \"\n",
    "                  f\"NO2={step_preds['valeur_NO2']:.1f}, CO={step_preds['valeur_CO']:.1f}, \"\n",
    "                  f\"O3={step_preds['valeur_O3']:.1f}, PM10={step_preds['valeur_PM10']:.1f}, \"\n",
    "                  f\"PM25={step_preds['valeur_PM25']:.1f}\")\n",
    "\n",
    "    return pd.DataFrame(all_predictions)\n",
    "\n",
    "# Generate forecasts for the test set (or last data point)\n",
    "forecast_df = autoregressive_forecast(train_clean, models, feature_cols, horizon=FORECAST_HORIZON)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"FORECAST SUMMARY\")\n",
    "print(f\"{'='*70}\")\n",
    "print(forecast_df.describe())\n",
    "\n",
    "# =============================================================================\n",
    "# SAVE RESULTS\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"SAVING RESULTS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "forecast_df.to_csv('autoregressive_forecast.csv', index=False)\n",
    "print(f\"‚úì Forecast saved: autoregressive_forecast.csv ({forecast_df.shape})\")\n",
    "\n",
    "# Save CV summary\n",
    "cv_summary = []\n",
    "for target, scores in cv_scores_all.items():\n",
    "    if scores:\n",
    "        cv_df = pd.DataFrame(scores)\n",
    "        cv_summary.append({\n",
    "            'target': target,\n",
    "            'mean_rmse': cv_df['rmse'].mean(),\n",
    "            'std_rmse': cv_df['rmse'].std(),\n",
    "            'mean_mae': cv_df['mae'].mean(),\n",
    "            'std_mae': cv_df['mae'].std(),\n",
    "            'mean_r2': cv_df['r2'].mean(),\n",
    "            'std_r2': cv_df['r2'].std()\n",
    "        })\n",
    "\n",
    "if cv_summary:\n",
    "    cv_summary_df = pd.DataFrame(cv_summary)\n",
    "    cv_summary_df.to_csv('cv_scores_autoregressive.csv', index=False)\n",
    "    print(f\"‚úì CV scores saved: cv_scores_autoregressive.csv\")\n",
    "    print(f\"\\nüìä VALIDATION RESULTS:\")\n",
    "    print(cv_summary_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"‚úÖ AUTOREGRESSIVE FORECASTING COMPLETE!\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nüí° Configuration:\")\n",
    "print(f\"   Forecast Horizon: {FORECAST_HORIZON} hours\")\n",
    "print(f\"   Features: Temporal + Current Weather + Recent Pollutant Lags (1-3)\")\n",
    "print(f\"   Approach: Step-by-step predictions using previous outputs as inputs\")\n",
    "print(f\"   Predictions: {forecast_df.shape[0]} steps √ó {len(TARGETS)} pollutants\")\n",
    "print(f\"\\n‚ö†Ô∏è  NOTES:\")\n",
    "print(f\"   ‚úì Can forecast multiple hours ahead\")\n",
    "print(f\"   ‚úì Uses temporal continuity through lag features\")\n",
    "print(f\"   ‚úó Error accumulates over longer horizons (24+ hours may degrade)\")\n",
    "print(f\"   ‚úó Depends on accurate weather data for each step ahead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518d0a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "IMPROVED AUTOREGRESSIVE PIPELINE - WITH WEATHER & LAGS\n",
      "======================================================================\n",
      "\n",
      "‚úì Loaded train: (40991, 213)\n",
      "‚úì Loaded test: (504, 208)\n",
      "\n",
      "======================================================================\n",
      "FEATURE ENGINEERING\n",
      "======================================================================\n",
      "‚úì Weather features engineered\n",
      "‚úì Lag features created\n",
      "‚úì Rolling statistics computed\n",
      "‚úì Pollutant interactions added\n",
      "\n",
      "======================================================================\n",
      "FEATURE SUMMARY\n",
      "======================================================================\n",
      "Total features: 37\n",
      "  - Temporal: 10\n",
      "  - Weather: 0\n",
      "  - Weather derived: 0\n",
      "  - Pollutant lags: 15\n",
      "  - Rolling stats: 10\n",
      "  - Interactions: 2\n",
      "\n",
      "‚úì Clean train samples: 40988 (after removing NaN from lags)\n",
      "\n",
      "======================================================================\n",
      "TRAINING ENHANCED AUTOREGRESSIVE MODELS\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "Training: valeur_NO2\n",
      "======================================================================\n",
      "Fold 1/3 - Train: 28692, Val: 6148 ‚Üí RMSE: 5.06, MAE: 3.04, R¬≤: 0.885\n",
      "Fold 2/3 - Train: 31766, Val: 6148 ‚Üí RMSE: 5.29, MAE: 3.28, R¬≤: 0.886\n",
      "Fold 3/3 - Train: 34840, Val: 6148 ‚Üí RMSE: 4.31, MAE: 2.66, R¬≤: 0.865\n",
      "Training final model... ‚úì CV: RMSE=4.89¬±0.51, R¬≤=0.879\n",
      "\n",
      "======================================================================\n",
      "Training: valeur_CO\n",
      "======================================================================\n",
      "Fold 1/3 - Train: 28692, Val: 6148 ‚Üí RMSE: 0.03, MAE: 0.02, R¬≤: 0.870\n",
      "Fold 2/3 - Train: 31766, Val: 6148 ‚Üí RMSE: 0.05, MAE: 0.02, R¬≤: 0.795\n",
      "Fold 3/3 - Train: 34840, Val: 6148 ‚Üí RMSE: 0.05, MAE: 0.02, R¬≤: 0.703\n",
      "Training final model... ‚úì CV: RMSE=0.04¬±0.01, R¬≤=0.789\n",
      "\n",
      "======================================================================\n",
      "Training: valeur_O3\n",
      "======================================================================\n",
      "Fold 1/3 - Train: 28692, Val: 6148 ‚Üí RMSE: 6.19, MAE: 4.25, R¬≤: 0.948\n",
      "Fold 2/3 - Train: 31766, Val: 6148 ‚Üí RMSE: 6.02, MAE: 4.15, R¬≤: 0.931\n",
      "Fold 3/3 - Train: 34840, Val: 6148 ‚Üí RMSE: 5.90, MAE: 4.15, R¬≤: 0.928\n",
      "Training final model... ‚úì CV: RMSE=6.04¬±0.14, R¬≤=0.936\n",
      "\n",
      "======================================================================\n",
      "Training: valeur_PM10\n",
      "======================================================================\n",
      "Fold 1/3 - Train: 28692, Val: 6148 ‚Üí RMSE: 3.05, MAE: 1.91, R¬≤: 0.852\n",
      "Fold 2/3 - Train: 31766, Val: 6148 ‚Üí RMSE: 3.06, MAE: 1.94, R¬≤: 0.875\n",
      "Fold 3/3 - Train: 34840, Val: 6148 ‚Üí RMSE: 2.73, MAE: 1.72, R¬≤: 0.880\n",
      "Training final model... ‚úì CV: RMSE=2.95¬±0.19, R¬≤=0.869\n",
      "\n",
      "======================================================================\n",
      "Training: valeur_PM25\n",
      "======================================================================\n",
      "Fold 1/3 - Train: 28692, Val: 6148 ‚Üí RMSE: 1.93, MAE: 1.17, R¬≤: 0.898\n",
      "Fold 2/3 - Train: 31766, Val: 6148 ‚Üí RMSE: 1.89, MAE: 1.17, R¬≤: 0.915\n",
      "Fold 3/3 - Train: 34840, Val: 6148 ‚Üí RMSE: 1.69, MAE: 1.09, R¬≤: 0.913\n",
      "Training final model... ‚úì CV: RMSE=1.84¬±0.13, R¬≤=0.909\n",
      "\n",
      "======================================================================\n",
      "TOP 10 FEATURE IMPORTANCE PER TARGET\n",
      "======================================================================\n",
      "\n",
      "valeur_NO2:\n",
      "  valeur_NO2_lag_1                           61.7\n",
      "  hour_sin                                    5.5\n",
      "  hour_cos                                    4.4\n",
      "  hour                                        2.5\n",
      "  valeur_NO2_lag_2                            2.2\n",
      "  O3_NO2_ratio                                2.2\n",
      "  valeur_O3_lag_2                             1.8\n",
      "  valeur_O3_lag_1                             1.7\n",
      "  valeur_CO_lag_1                             1.7\n",
      "  valeur_O3_lag_3                             1.4\n",
      "\n",
      "valeur_CO:\n",
      "  valeur_CO_lag_1                            55.4\n",
      "  valeur_CO_rolling_std_3                     3.3\n",
      "  hour_sin                                    2.8\n",
      "  valeur_PM25_lag_1                           2.8\n",
      "  O3_NO2_ratio                                2.4\n",
      "  valeur_CO_lag_2                             2.4\n",
      "  valeur_O3_lag_1                             2.3\n",
      "  valeur_NO2_rolling_std_3                    2.1\n",
      "  hour_cos                                    2.1\n",
      "  valeur_PM10_rolling_std_3                   2.1\n",
      "\n",
      "valeur_O3:\n",
      "  valeur_O3_lag_1                            72.2\n",
      "  hour_cos                                    5.0\n",
      "  O3_NO2_ratio                                3.6\n",
      "  valeur_O3_lag_2                             2.4\n",
      "  hour_sin                                    2.0\n",
      "  hour                                        1.6\n",
      "  is_day                                      1.5\n",
      "  valeur_O3_rolling_std_3                     1.3\n",
      "  valeur_O3_rolling_mean_3                    1.3\n",
      "  valeur_NO2_lag_2                            1.0\n",
      "\n",
      "valeur_PM10:\n",
      "  valeur_PM10_lag_1                          66.5\n",
      "  valeur_PM10_rolling_mean_3                  4.0\n",
      "  valeur_PM25_lag_1                           3.6\n",
      "  NO2_PM10_interaction                        2.1\n",
      "  hour_sin                                    2.1\n",
      "  hour_cos                                    1.7\n",
      "  valeur_PM10_lag_2                           1.5\n",
      "  valeur_O3_rolling_std_3                     1.2\n",
      "  valeur_PM25_lag_2                           1.2\n",
      "  valeur_PM10_rolling_std_3                   1.0\n",
      "\n",
      "valeur_PM25:\n",
      "  valeur_PM25_lag_1                          72.3\n",
      "  valeur_PM25_lag_2                           3.6\n",
      "  valeur_PM25_rolling_mean_3                  3.3\n",
      "  valeur_PM10_lag_1                           1.8\n",
      "  hour_sin                                    1.5\n",
      "  valeur_CO_lag_1                             1.4\n",
      "  NO2_PM10_interaction                        1.3\n",
      "  hour_cos                                    1.2\n",
      "  valeur_PM25_rolling_std_3                   1.1\n",
      "  valeur_PM25_lag_3                           0.9\n",
      "\n",
      "======================================================================\n",
      "ENHANCED AUTOREGRESSIVE FORECASTING - 24 steps\n",
      "======================================================================\n",
      "Step  1/24 - NO2= 29.4, CO=0.22, O3= 30.0, PM10= 10.0, PM25=  5.4\n",
      "Step  6/24 - NO2= 17.0, CO=0.18, O3= 39.0, PM10=  8.7, PM25=  5.2\n",
      "Step 12/24 - NO2= 29.2, CO=0.23, O3= 30.4, PM10= 17.0, PM25=  8.0\n",
      "Step 18/24 - NO2= 18.0, CO=0.19, O3= 55.5, PM10= 13.9, PM25=  6.2\n",
      "Step 24/24 - NO2= 19.5, CO=0.22, O3= 47.7, PM10= 12.6, PM25=  7.3\n",
      "\n",
      "======================================================================\n",
      "SAVING RESULTS\n",
      "======================================================================\n",
      "‚úì Forecast: enhanced_autoregressive_forecast.csv\n",
      "‚úì CV scores: cv_scores_enhanced_autoregressive.csv\n",
      "\n",
      "     target  mean_rmse  std_rmse  mean_mae  mean_r2   std_r2\n",
      " valeur_NO2   4.885353  0.514294  2.993753 0.878725 0.012156\n",
      "  valeur_CO   0.044783  0.009614  0.017896 0.789407 0.083342\n",
      "  valeur_O3   6.035323  0.144292  4.181925 0.935574 0.010493\n",
      "valeur_PM10   2.946845  0.187773  1.857382 0.868909 0.014795\n",
      "valeur_PM25   1.836615  0.125287  1.142152 0.908932 0.009205\n",
      "\n",
      "======================================================================\n",
      "‚úÖ ENHANCED AUTOREGRESSIVE PIPELINE COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "üí° Improvements over basic version:\n",
      "   ‚úì Weather features: 0 (wind, temp, humidity, pressure)\n",
      "   ‚úì Pollutant lags: 1-3 hours (short-term history)\n",
      "   ‚úì Rolling statistics: Recent trends (3-hour windows)\n",
      "   ‚úì Pollutant interactions: NO2-PM10, O3-NO2 relationships\n",
      "   ‚úì Weather-derived: Wind intensity, calm conditions, precipitation effects\n",
      "   ‚úì Total features: 37 (vs 10 in basic version)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "TARGETS = ['valeur_NO2', 'valeur_CO', 'valeur_O3', 'valeur_PM10', 'valeur_PM25']\n",
    "\n",
    "TEMPORAL_FEATURES = ['hour', 'is_day', 'hour_sin', 'hour_cos', 'dow', 'dow_sin',\n",
    "                     'dow_cos', 'is_holiday', 'is_weekend', 'lockdown_code']\n",
    "\n",
    "# Weather features that are typically available in forecasts\n",
    "WEATHER_FORECAST = [\n",
    "    'temperature_2m', 'relative_humidity_2m', 'dew_point_2m', 'apparent_temperature',\n",
    "    'pressure_msl', 'wind_speed_10m', 'wind_direction_10m', 'precipitation',\n",
    "    'cloud_cover', 'shortwave_radiation', 'wind_gusts_10m',\n",
    "    'rain', 'weather_code'\n",
    "]\n",
    "\n",
    "# Additional derived weather features for air quality\n",
    "WEATHER_DERIVED = [\n",
    "    'wind_speed_squared',  # Wind intensity for dispersion\n",
    "    'temp_humidity_interaction',  # Temperature-humidity interaction\n",
    "    'is_calm_wind',  # Low wind = poor dispersion\n",
    "    'is_precipitation'  # Rain = washout effect\n",
    "]\n",
    "\n",
    "DATE_COL = 'date'\n",
    "N_SPLITS = 3\n",
    "TEST_SIZE_RATIO = 0.15\n",
    "\n",
    "CATBOOST_PARAMS = {\n",
    "    'iterations': 1500,\n",
    "    'learning_rate': 0.03,\n",
    "    'depth': 7,\n",
    "    'l2_leaf_reg': 3,\n",
    "    'loss_function': 'RMSE',\n",
    "    'eval_metric': 'RMSE',\n",
    "    'random_seed': 42,\n",
    "    'verbose': False,\n",
    "    'early_stopping_rounds': 100,\n",
    "    'task_type': 'CPU',\n",
    "    'thread_count': -1\n",
    "}\n",
    "\n",
    "FORECAST_HORIZON = 24\n",
    "\n",
    "# =============================================================================\n",
    "# LOAD AND PREPARE DATA\n",
    "# =============================================================================\n",
    "print(\"=\"*70)\n",
    "print(\"IMPROVED AUTOREGRESSIVE PIPELINE - WITH WEATHER & LAGS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "train_df = pd.read_csv(\"../data/train_features.csv\")\n",
    "test_df = pd.read_csv(\"../data/test_features_to_predict.csv\")\n",
    "\n",
    "print(f\"\\n‚úì Loaded train: {train_df.shape}\")\n",
    "print(f\"‚úì Loaded test: {test_df.shape}\")\n",
    "\n",
    "if DATE_COL in train_df.columns:\n",
    "    train_df[DATE_COL] = pd.to_datetime(train_df[DATE_COL])\n",
    "    train_df = train_df.sort_values(DATE_COL).reset_index(drop=True)\n",
    "\n",
    "if DATE_COL in test_df.columns:\n",
    "    test_df[DATE_COL] = pd.to_datetime(test_df[DATE_COL])\n",
    "    test_df = test_df.sort_values(DATE_COL).reset_index(drop=True)\n",
    "\n",
    "# =============================================================================\n",
    "# FEATURE ENGINEERING\n",
    "# =============================================================================\n",
    "def engineer_weather_features(df):\n",
    "    \"\"\"Create derived weather features for better air quality prediction.\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Wind intensity (strong winds disperse pollutants)\n",
    "    if 'wind_speed_10m' in df.columns:\n",
    "        df['wind_speed_squared'] = df['wind_speed_10m'] ** 2\n",
    "        df['is_calm_wind'] = (df['wind_speed_10m'] < 2).astype(int)\n",
    "\n",
    "    # Temperature-humidity interaction (affects chemical reactions)\n",
    "    if 'temperature_2m' in df.columns and 'relative_humidity_2m' in df.columns:\n",
    "        df['temp_humidity_interaction'] = df['temperature_2m'] * df['relative_humidity_2m'] / 100\n",
    "\n",
    "    # Precipitation effect (washout of pollutants)\n",
    "    if 'precipitation' in df.columns:\n",
    "        df['is_precipitation'] = (df['precipitation'] > 0.1).astype(int)\n",
    "    elif 'rain' in df.columns:\n",
    "        df['is_precipitation'] = (df['rain'] > 0.1).astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "def create_lag_features(df, targets, lags=[1, 2, 3, 6, 12, 24]):\n",
    "    \"\"\"Create lag features for pollutants (recent history).\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    for target in targets:\n",
    "        if target in df.columns:\n",
    "            for lag in lags:\n",
    "                df[f'{target}_lag_{lag}'] = df[target].shift(lag)\n",
    "\n",
    "    return df\n",
    "\n",
    "def create_rolling_features(df, targets, windows=[3, 6, 12, 24]):\n",
    "    \"\"\"Create rolling statistics (trends in pollution).\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    for target in targets:\n",
    "        if target in df.columns:\n",
    "            for window in windows:\n",
    "                df[f'{target}_rolling_mean_{window}'] = df[target].shift(1).rolling(window).mean()\n",
    "                df[f'{target}_rolling_std_{window}'] = df[target].shift(1).rolling(window).std()\n",
    "\n",
    "    return df\n",
    "\n",
    "def create_pollutant_interactions(df, targets):\n",
    "    \"\"\"Create interaction features between pollutants (they're correlated).\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # NO2 and PM often correlate (traffic/combustion)\n",
    "    if 'valeur_NO2_lag_1' in df.columns and 'valeur_PM10_lag_1' in df.columns:\n",
    "        df['NO2_PM10_interaction'] = df['valeur_NO2_lag_1'] * df['valeur_PM10_lag_1']\n",
    "\n",
    "    # O3 inversely correlates with NO2 (NO2 consumes O3)\n",
    "    if 'valeur_O3_lag_1' in df.columns and 'valeur_NO2_lag_1' in df.columns:\n",
    "        df['O3_NO2_ratio'] = df['valeur_O3_lag_1'] / (df['valeur_NO2_lag_1'] + 1)\n",
    "\n",
    "    return df\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE ENGINEERING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Apply feature engineering to training data\n",
    "train_df = engineer_weather_features(train_df)\n",
    "train_df = create_lag_features(train_df, TARGETS, lags=[1, 2, 3, 6, 12, 24])\n",
    "train_df = create_rolling_features(train_df, TARGETS, windows=[3, 6, 12, 24])\n",
    "train_df = create_pollutant_interactions(train_df, TARGETS)\n",
    "\n",
    "test_df = engineer_weather_features(test_df)\n",
    "\n",
    "print(\"‚úì Weather features engineered\")\n",
    "print(\"‚úì Lag features created\")\n",
    "print(\"‚úì Rolling statistics computed\")\n",
    "print(\"‚úì Pollutant interactions added\")\n",
    "\n",
    "# =============================================================================\n",
    "# FEATURE SELECTION FOR AUTOREGRESSIVE MODEL\n",
    "# =============================================================================\n",
    "def get_autoregressive_features(df):\n",
    "    \"\"\"\n",
    "    Select features suitable for autoregressive forecasting:\n",
    "    1. Temporal features (always available)\n",
    "    2. Weather features (from forecast)\n",
    "    3. Derived weather features\n",
    "    4. Pollutant lags (short-term: 1-3 hours for autoregressive)\n",
    "    5. Rolling features (recent trends)\n",
    "    6. Pollutant interactions\n",
    "    \"\"\"\n",
    "    features = []\n",
    "\n",
    "    # Temporal\n",
    "    features.extend([f for f in TEMPORAL_FEATURES if f in df.columns])\n",
    "\n",
    "    # Weather (forecasted)\n",
    "    features.extend([f for f in WEATHER_FORECAST if f in df.columns])\n",
    "\n",
    "    # Derived weather\n",
    "    features.extend([f for f in WEATHER_DERIVED if f in df.columns])\n",
    "\n",
    "    # Short-term lags (1-3 hours for autoregressive step-by-step)\n",
    "    for target in TARGETS:\n",
    "        for lag in [1, 2, 3]:\n",
    "            col = f'{target}_lag_{lag}'\n",
    "            if col in df.columns:\n",
    "                features.append(col)\n",
    "\n",
    "    # Recent rolling statistics (3-hour window)\n",
    "    for target in TARGETS:\n",
    "        for col in [f'{target}_rolling_mean_3', f'{target}_rolling_std_3']:\n",
    "            if col in df.columns:\n",
    "                features.append(col)\n",
    "\n",
    "    # Pollutant interactions\n",
    "    for col in ['NO2_PM10_interaction', 'O3_NO2_ratio']:\n",
    "        if col in df.columns:\n",
    "            features.append(col)\n",
    "\n",
    "    return features\n",
    "\n",
    "feature_cols = get_autoregressive_features(train_df)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"FEATURE SUMMARY\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Total features: {len(feature_cols)}\")\n",
    "print(f\"  - Temporal: {len([f for f in feature_cols if f in TEMPORAL_FEATURES])}\")\n",
    "print(f\"  - Weather: {len([f for f in feature_cols if any(w in f for w in WEATHER_FORECAST)])}\")\n",
    "print(f\"  - Weather derived: {len([f for f in feature_cols if any(w in f for w in WEATHER_DERIVED)])}\")\n",
    "print(f\"  - Pollutant lags: {len([f for f in feature_cols if 'lag_' in f])}\")\n",
    "print(f\"  - Rolling stats: {len([f for f in feature_cols if 'rolling_' in f])}\")\n",
    "print(f\"  - Interactions: {len([f for f in feature_cols if 'interaction' in f or 'ratio' in f])}\")\n",
    "\n",
    "# Clean data\n",
    "train_clean = train_df[feature_cols + TARGETS].dropna().reset_index(drop=True)\n",
    "print(f\"\\n‚úì Clean train samples: {len(train_clean)} (after removing NaN from lags)\")\n",
    "\n",
    "# =============================================================================\n",
    "# TRAIN MODELS\n",
    "# =============================================================================\n",
    "def train_models(df, feature_cols, n_splits=3):\n",
    "    \"\"\"Train autoregressive models with expanded features.\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"TRAINING ENHANCED AUTOREGRESSIVE MODELS\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    splits = []\n",
    "    n = len(df)\n",
    "    test_size = int(n * TEST_SIZE_RATIO)\n",
    "    min_train_size = int(n * 0.5)\n",
    "\n",
    "    for i in range(n_splits):\n",
    "        val_end = n - (n_splits - i - 1) * (test_size // 2)\n",
    "        val_start = val_end - test_size\n",
    "        train_end = val_start\n",
    "\n",
    "        if train_end < min_train_size:\n",
    "            continue\n",
    "\n",
    "        train_idx = df.index[:train_end]\n",
    "        val_idx = df.index[val_start:val_end]\n",
    "        splits.append((train_idx, val_idx))\n",
    "\n",
    "    models = {}\n",
    "    cv_scores_all = {}\n",
    "\n",
    "    for target in TARGETS:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Training: {target}\")\n",
    "        print(f\"{'='*70}\")\n",
    "\n",
    "        cv_scores = []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(splits, 1):\n",
    "            print(f\"Fold {fold}/{len(splits)} - Train: {len(train_idx)}, Val: {len(val_idx)}\", end=\" \")\n",
    "\n",
    "            X_train = df.loc[train_idx, feature_cols].fillna(0)\n",
    "            y_train = df.loc[train_idx, target]\n",
    "            X_val = df.loc[val_idx, feature_cols].fillna(0)\n",
    "            y_val = df.loc[val_idx, target]\n",
    "\n",
    "            try:\n",
    "                train_pool = Pool(X_train, y_train)\n",
    "                val_pool = Pool(X_val, y_val)\n",
    "\n",
    "                model = CatBoostRegressor(**CATBOOST_PARAMS)\n",
    "                model.fit(train_pool, eval_set=val_pool, use_best_model=True, plot=False)\n",
    "\n",
    "                preds = np.maximum(model.predict(X_val), 0)\n",
    "                rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
    "                mae = mean_absolute_error(y_val, preds)\n",
    "                r2 = r2_score(y_val, preds)\n",
    "\n",
    "                cv_scores.append({\n",
    "                    'fold': fold,\n",
    "                    'rmse': rmse,\n",
    "                    'mae': mae,\n",
    "                    'r2': r2,\n",
    "                    'best_iteration': model.get_best_iteration()\n",
    "                })\n",
    "\n",
    "                print(f\"‚Üí RMSE: {rmse:.2f}, MAE: {mae:.2f}, R¬≤: {r2:.3f}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚úó Error: {str(e)[:50]}\")\n",
    "                continue\n",
    "\n",
    "        # Train final model\n",
    "        print(f\"Training final model...\", end=\" \")\n",
    "        X_full = df[feature_cols].fillna(0)\n",
    "        y_full = df[target]\n",
    "        full_pool = Pool(X_full, y_full)\n",
    "\n",
    "        final_model = CatBoostRegressor(**CATBOOST_PARAMS)\n",
    "        final_model.fit(full_pool, plot=False)\n",
    "\n",
    "        models[target] = final_model\n",
    "        cv_scores_all[target] = cv_scores\n",
    "\n",
    "        if cv_scores:\n",
    "            cv_df = pd.DataFrame(cv_scores)\n",
    "            print(f\"‚úì CV: RMSE={cv_df['rmse'].mean():.2f}¬±{cv_df['rmse'].std():.2f}, R¬≤={cv_df['r2'].mean():.3f}\")\n",
    "\n",
    "    return models, cv_scores_all\n",
    "\n",
    "models, cv_scores_all = train_models(train_clean, feature_cols, n_splits=N_SPLITS)\n",
    "\n",
    "# =============================================================================\n",
    "# FEATURE IMPORTANCE\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"TOP 10 FEATURE IMPORTANCE PER TARGET\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "for target in TARGETS:\n",
    "    if models[target] is not None:\n",
    "        importance = models[target].get_feature_importance()\n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': feature_cols,\n",
    "            'importance': importance\n",
    "        }).sort_values('importance', ascending=False).head(10)\n",
    "\n",
    "        print(f\"\\n{target}:\")\n",
    "        for idx, row in importance_df.iterrows():\n",
    "            print(f\"  {row['feature']:40s} {row['importance']:6.1f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# AUTOREGRESSIVE FORECASTING\n",
    "# =============================================================================\n",
    "def autoregressive_forecast_enhanced(df_init, models, feature_cols, horizon=24):\n",
    "    \"\"\"\n",
    "    Enhanced autoregressive forecasting with proper lag updating.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ENHANCED AUTOREGRESSIVE FORECASTING - {horizon} steps\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    current_state = df_init.iloc[-1:].copy()\n",
    "    all_predictions = []\n",
    "\n",
    "    for step in range(horizon):\n",
    "        step_preds = {'step': step + 1}\n",
    "\n",
    "        # Prepare features\n",
    "        X_current = current_state[feature_cols].fillna(0)\n",
    "\n",
    "        # Predict all targets\n",
    "        for target in TARGETS:\n",
    "            if models[target] is not None:\n",
    "                pred = np.maximum(models[target].predict(X_current)[0], 0)\n",
    "                step_preds[target] = pred\n",
    "            else:\n",
    "                step_preds[target] = 0\n",
    "\n",
    "        all_predictions.append(step_preds)\n",
    "\n",
    "        # Update state for next iteration\n",
    "        new_state = current_state.copy()\n",
    "\n",
    "        # Update lags\n",
    "        for target in TARGETS:\n",
    "            # Shift all lags\n",
    "            if f'{target}_lag_3' in new_state.columns:\n",
    "                new_state[f'{target}_lag_3'] = new_state[f'{target}_lag_2'].values[0]\n",
    "            if f'{target}_lag_2' in new_state.columns:\n",
    "                new_state[f'{target}_lag_2'] = new_state[f'{target}_lag_1'].values[0]\n",
    "            if f'{target}_lag_1' in new_state.columns:\n",
    "                new_state[f'{target}_lag_1'] = step_preds[target]\n",
    "\n",
    "            # Update rolling mean (simplified - 3-hour window)\n",
    "            if f'{target}_rolling_mean_3' in new_state.columns:\n",
    "                recent_vals = [\n",
    "                    new_state[f'{target}_lag_3'].values[0] if f'{target}_lag_3' in new_state.columns else step_preds[target],\n",
    "                    new_state[f'{target}_lag_2'].values[0] if f'{target}_lag_2' in new_state.columns else step_preds[target],\n",
    "                    new_state[f'{target}_lag_1'].values[0] if f'{target}_lag_1' in new_state.columns else step_preds[target]\n",
    "                ]\n",
    "                new_state[f'{target}_rolling_mean_3'] = np.mean(recent_vals)\n",
    "\n",
    "        # Update interactions\n",
    "        if 'NO2_PM10_interaction' in new_state.columns:\n",
    "            new_state['NO2_PM10_interaction'] = (\n",
    "                new_state['valeur_NO2_lag_1'].values[0] *\n",
    "                new_state['valeur_PM10_lag_1'].values[0]\n",
    "            )\n",
    "\n",
    "        if 'O3_NO2_ratio' in new_state.columns:\n",
    "            new_state['O3_NO2_ratio'] = (\n",
    "                new_state['valeur_O3_lag_1'].values[0] /\n",
    "                (new_state['valeur_NO2_lag_1'].values[0] + 1)\n",
    "            )\n",
    "\n",
    "        # Update temporal features\n",
    "        if 'hour' in new_state.columns:\n",
    "            new_state['hour'] = (new_state['hour'].values[0] + 1) % 24\n",
    "            if 'hour_sin' in new_state.columns:\n",
    "                new_state['hour_sin'] = np.sin(2 * np.pi * new_state['hour'] / 24)\n",
    "            if 'hour_cos' in new_state.columns:\n",
    "                new_state['hour_cos'] = np.cos(2 * np.pi * new_state['hour'] / 24)\n",
    "\n",
    "        current_state = new_state\n",
    "\n",
    "        if (step + 1) % 6 == 0 or step == 0:\n",
    "            print(f\"Step {step + 1:2d}/{horizon} - NO2={step_preds['valeur_NO2']:5.1f}, \"\n",
    "                  f\"CO={step_preds['valeur_CO']:4.2f}, O3={step_preds['valeur_O3']:5.1f}, \"\n",
    "                  f\"PM10={step_preds['valeur_PM10']:5.1f}, PM25={step_preds['valeur_PM25']:5.1f}\")\n",
    "\n",
    "    return pd.DataFrame(all_predictions)\n",
    "\n",
    "forecast_df = autoregressive_forecast_enhanced(train_clean, models, feature_cols, horizon=FORECAST_HORIZON)\n",
    "\n",
    "# =============================================================================\n",
    "# SAVE RESULTS\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"SAVING RESULTS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "forecast_df.to_csv('enhanced_autoregressive_forecast.csv', index=False)\n",
    "print(f\"‚úì Forecast: enhanced_autoregressive_forecast.csv\")\n",
    "\n",
    "cv_summary = []\n",
    "for target, scores in cv_scores_all.items():\n",
    "    if scores:\n",
    "        cv_df = pd.DataFrame(scores)\n",
    "        cv_summary.append({\n",
    "            'target': target,\n",
    "            'mean_rmse': cv_df['rmse'].mean(),\n",
    "            'std_rmse': cv_df['rmse'].std(),\n",
    "            'mean_mae': cv_df['mae'].mean(),\n",
    "            'mean_r2': cv_df['r2'].mean(),\n",
    "            'std_r2': cv_df['r2'].std()\n",
    "        })\n",
    "\n",
    "if cv_summary:\n",
    "    cv_summary_df = pd.DataFrame(cv_summary)\n",
    "    cv_summary_df.to_csv('cv_scores_enhanced_autoregressive.csv', index=False)\n",
    "    print(f\"‚úì CV scores: cv_scores_enhanced_autoregressive.csv\\n\")\n",
    "    print(cv_summary_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"‚úÖ ENHANCED AUTOREGRESSIVE PIPELINE COMPLETE!\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nüí° Improvements over basic version:\")\n",
    "print(f\"   ‚úì Weather features: {len([f for f in feature_cols if any(w in f for w in WEATHER_FORECAST)])} (wind, temp, humidity, pressure)\")\n",
    "print(f\"   ‚úì Pollutant lags: 1-3 hours (short-term history)\")\n",
    "print(f\"   ‚úì Rolling statistics: Recent trends (3-hour windows)\")\n",
    "print(f\"   ‚úì Pollutant interactions: NO2-PM10, O3-NO2 relationships\")\n",
    "print(f\"   ‚úì Weather-derived: Wind intensity, calm conditions, precipitation effects\")\n",
    "print(f\"   ‚úì Total features: {len(feature_cols)} (vs 10 in basic version)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
