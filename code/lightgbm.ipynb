{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd2a86f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data with memory optimization...\n",
      "Train shape: (40991, 213)\n",
      "Test shape: (504, 208)\n",
      "\n",
      "Preparing features...\n",
      "Total features: 204\n",
      "Train samples: 40991\n",
      "X_train shape: (34842, 204)\n",
      "X_val shape: (6149, 204)\n",
      "\n",
      "======================================================================\n",
      "TRAINING LIGHTGBM MODELS (FAST)\n",
      "======================================================================\n",
      "\n",
      "========================================\n",
      "Training valeur_NO2...\n",
      "========================================\n",
      "‚úÖ Validation MAE: 3.7313\n",
      "   Best iteration: 115\n",
      "\n",
      "========================================\n",
      "Training valeur_CO...\n",
      "========================================\n",
      "‚úÖ Validation MAE: 0.0222\n",
      "   Best iteration: 129\n",
      "\n",
      "========================================\n",
      "Training valeur_O3...\n",
      "========================================\n",
      "‚úÖ Validation MAE: 6.2799\n",
      "   Best iteration: 299\n",
      "\n",
      "========================================\n",
      "Training valeur_PM10...\n",
      "========================================\n",
      "‚úÖ Validation MAE: 2.5006\n",
      "   Best iteration: 170\n",
      "\n",
      "========================================\n",
      "Training valeur_PM25...\n",
      "========================================\n",
      "‚úÖ Validation MAE: 1.6679\n",
      "   Best iteration: 187\n",
      "\n",
      "======================================================================\n",
      "VALIDATION RESULTS\n",
      "======================================================================\n",
      "valeur_NO2: 3.7313\n",
      "valeur_CO: 0.0222\n",
      "valeur_O3: 6.2799\n",
      "valeur_PM10: 2.5006\n",
      "valeur_PM25: 1.6679\n",
      "\n",
      "üéØ Average MAE: 2.8404\n",
      "üéØ Your Tuned Model: 2.9069\n",
      "üéâ LightGBM is BETTER by 0.0665!\n",
      "\n",
      "======================================================================\n",
      "PREPARING TEST DATA\n",
      "======================================================================\n",
      "Test features shape: (504, 204)\n",
      "\n",
      "======================================================================\n",
      "MAKING PREDICTIONS\n",
      "======================================================================\n",
      "‚úÖ valeur_NO2: mean=24.09, range=[16.81, 33.55]\n",
      "‚úÖ valeur_CO: mean=0.22, range=[0.20, 0.25]\n",
      "‚úÖ valeur_O3: mean=43.17, range=[30.25, 55.45]\n",
      "‚úÖ valeur_PM10: mean=13.06, range=[10.03, 15.31]\n",
      "‚úÖ valeur_PM25: mean=6.24, range=[4.68, 8.04]\n",
      "\n",
      "======================================================================\n",
      "CREATING SUBMISSIONS\n",
      "======================================================================\n",
      "‚úÖ Saved: lgbm_fast.csv\n",
      "‚úÖ Saved: ensemble_lgbm_nn_5050.csv\n",
      "\n",
      "Using weights: LightGBM=0.6, NN=0.4\n",
      "‚úÖ Saved: ensemble_lgbm_nn_smart.csv\n",
      "\n",
      "======================================================================\n",
      "SUMMARY\n",
      "======================================================================\n",
      "\n",
      "üìÅ Submissions created:\n",
      "  1. lgbm_fast.csv - Pure LightGBM\n",
      "  2. ensemble_lgbm_nn_5050.csv - 50/50 blend\n",
      "  3. ensemble_lgbm_nn_smart.csv - Smart weighted blend\n",
      "\n",
      "üöÄ SUBMIT ALL 3 TO KAGGLE!\n",
      "\n",
      "‚è±Ô∏è Estimated time: 15-20 minutes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# SETUP\n",
    "# ============================================================================\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "TARGETS = ['valeur_NO2', 'valeur_CO', 'valeur_O3', 'valeur_PM10', 'valeur_PM25']\n",
    "TEMPORAL_FEATURES = ['hour', 'is_day', 'hour_sin', 'hour_cos', 'dow', 'dow_sin', \n",
    "                     'dow_cos', 'is_holiday', 'is_weekend', 'lockdown_code']\n",
    "\n",
    "print(\"Loading data with memory optimization...\")\n",
    "# Load with chunks to avoid memory error\n",
    "train_df = pd.read_csv(\"../data/train_features.csv\")\n",
    "test_df = pd.read_csv(\"../data/test_features_to_predict.csv\")\n",
    "\n",
    "# Convert to float32 immediately to save memory\n",
    "float_cols = train_df.select_dtypes(include=['float64']).columns\n",
    "train_df[float_cols] = train_df[float_cols].astype('float32')\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PREPARE FEATURES\n",
    "# ============================================================================\n",
    "print(\"\\nPreparing features...\")\n",
    "\n",
    "all_cols = train_df.columns.tolist()\n",
    "lag_roll_cols = [c for c in all_cols if 'lag_' in c or 'roll_' in c]\n",
    "feature_cols = lag_roll_cols + TEMPORAL_FEATURES\n",
    "\n",
    "print(f\"Total features: {len(feature_cols)}\")\n",
    "\n",
    "# Remove NaNs\n",
    "train_clean = train_df[feature_cols + TARGETS].dropna()\n",
    "print(f\"Train samples: {len(train_clean)}\")\n",
    "\n",
    "# Split\n",
    "split_idx = int(0.85 * len(train_clean))\n",
    "\n",
    "X_train = train_clean.iloc[:split_idx][feature_cols].values\n",
    "Y_train = train_clean.iloc[:split_idx][TARGETS].values\n",
    "X_val = train_clean.iloc[split_idx:][feature_cols].values\n",
    "Y_val = train_clean.iloc[split_idx:][TARGETS].values\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# TRAIN ONE MODEL PER POLLUTANT (FAST VERSION)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING LIGHTGBM MODELS (FAST)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "models = {}\n",
    "val_predictions = np.zeros_like(Y_val)\n",
    "\n",
    "for i, target in enumerate(TARGETS):\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"Training {target}...\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    # Prepare data\n",
    "    lgb_train = lgb.Dataset(X_train, Y_train[:, i], free_raw_data=False)\n",
    "    lgb_val = lgb.Dataset(X_val, Y_val[:, i], reference=lgb_train, free_raw_data=False)\n",
    "    \n",
    "    # Fast parameters - optimized for speed\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'mae',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'learning_rate': 0.1,  # Higher for speed\n",
    "        'num_leaves': 31,\n",
    "        'max_depth': -1,\n",
    "        'min_data_in_leaf': 20,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': -1,\n",
    "        'seed': SEED,\n",
    "        'force_col_wise': True  # Faster\n",
    "    }\n",
    "    \n",
    "    # Train quickly\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        lgb_train,\n",
    "        num_boost_round=300,  # Reduced from 1000\n",
    "        valid_sets=[lgb_val],\n",
    "        valid_names=['val'],\n",
    "        callbacks=[lgb.early_stopping(30, verbose=False)]\n",
    "    )\n",
    "    \n",
    "    models[target] = model\n",
    "    \n",
    "    # Validate\n",
    "    val_predictions[:, i] = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "    mae = mean_absolute_error(Y_val[:, i], val_predictions[:, i])\n",
    "    \n",
    "    print(f\"‚úÖ Validation MAE: {mae:.4f}\")\n",
    "    print(f\"   Best iteration: {model.best_iteration}\")\n",
    "\n",
    "# Overall performance\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VALIDATION RESULTS\")\n",
    "print(\"=\"*70)\n",
    "for i, target in enumerate(TARGETS):\n",
    "    mae = mean_absolute_error(Y_val[:, i], val_predictions[:, i])\n",
    "    print(f\"{target}: {mae:.4f}\")\n",
    "\n",
    "avg_mae = np.mean([mean_absolute_error(Y_val[:, i], val_predictions[:, i]) for i in range(len(TARGETS))])\n",
    "print(f\"\\nüéØ Average MAE: {avg_mae:.4f}\")\n",
    "print(f\"üéØ Your Tuned Model: 2.9069\")\n",
    "\n",
    "if avg_mae < 2.9069:\n",
    "    print(f\"üéâ LightGBM is BETTER by {2.9069 - avg_mae:.4f}!\")\n",
    "else:\n",
    "    print(f\"üìä Tuned model still better by {avg_mae - 2.9069:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PREPARE TEST DATA - USE LAST ROW\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PREPARING TEST DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "last_row = train_df.iloc[-1:].copy()\n",
    "\n",
    "test_features_list = []\n",
    "for idx in range(len(test_df)):\n",
    "    test_row = test_df.iloc[idx].copy()\n",
    "    \n",
    "    features = []\n",
    "    for col in feature_cols:\n",
    "        if col in TEMPORAL_FEATURES and col in test_row.index:\n",
    "            features.append(float(test_row[col]))\n",
    "        elif col in last_row.columns:\n",
    "            features.append(float(last_row[col].values[0]))\n",
    "        else:\n",
    "            features.append(0.0)\n",
    "    \n",
    "    test_features_list.append(features)\n",
    "\n",
    "X_test = np.array(test_features_list, dtype='float32')\n",
    "print(f\"Test features shape: {X_test.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# MAKE PREDICTIONS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MAKING PREDICTIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "predictions = np.zeros((len(test_df), len(TARGETS)), dtype='float32')\n",
    "\n",
    "for i, target in enumerate(TARGETS):\n",
    "    predictions[:, i] = models[target].predict(X_test, num_iteration=models[target].best_iteration)\n",
    "    print(f\"‚úÖ {target}: mean={predictions[:, i].mean():.2f}, range=[{predictions[:, i].min():.2f}, {predictions[:, i].max():.2f}]\")\n",
    "\n",
    "# ============================================================================\n",
    "# CREATE SUBMISSIONS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CREATING SUBMISSIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Submission 1: Pure LightGBM\n",
    "submission_lgbm = pd.DataFrame()\n",
    "submission_lgbm['id'] = test_df['id'].values\n",
    "for i, target in enumerate(TARGETS):\n",
    "    submission_lgbm[target] = predictions[:, i]\n",
    "\n",
    "submission_lgbm.to_csv('lgbm_fast.csv', index=False)\n",
    "print(\"‚úÖ Saved: lgbm_fast.csv\")\n",
    "\n",
    "# Submission 2: Ensemble with tuned model\n",
    "try:\n",
    "    tuned_sub = pd.read_csv('ffnn_tuned_submission.csv')\n",
    "    \n",
    "    # 50/50 ensemble\n",
    "    ensemble = submission_lgbm.copy()\n",
    "    for target in TARGETS:\n",
    "        ensemble[target] = 0.5 * submission_lgbm[target] + 0.5 * tuned_sub[target]\n",
    "    \n",
    "    ensemble.to_csv('ensemble_lgbm_nn_5050.csv', index=False)\n",
    "    print(\"‚úÖ Saved: ensemble_lgbm_nn_5050.csv\")\n",
    "    \n",
    "    # Smart weight based on validation\n",
    "    if avg_mae < 2.9069:\n",
    "        weight_lgbm = 0.6\n",
    "        weight_nn = 0.4\n",
    "        print(f\"\\nUsing weights: LightGBM={weight_lgbm}, NN={weight_nn}\")\n",
    "    else:\n",
    "        weight_lgbm = 0.4\n",
    "        weight_nn = 0.6\n",
    "        print(f\"\\nUsing weights: LightGBM={weight_lgbm}, NN={weight_nn}\")\n",
    "    \n",
    "    ensemble_smart = submission_lgbm.copy()\n",
    "    for target in TARGETS:\n",
    "        ensemble_smart[target] = weight_lgbm * submission_lgbm[target] + weight_nn * tuned_sub[target]\n",
    "    \n",
    "    ensemble_smart.to_csv('ensemble_lgbm_nn_smart.csv', index=False)\n",
    "    print(\"‚úÖ Saved: ensemble_lgbm_nn_smart.csv\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not create ensemble: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nüìÅ Submissions created:\")\n",
    "print(\"  1. lgbm_fast.csv - Pure LightGBM\")\n",
    "print(\"  2. ensemble_lgbm_nn_5050.csv - 50/50 blend\")\n",
    "print(\"  3. ensemble_lgbm_nn_smart.csv - Smart weighted blend\")\n",
    "print(\"\\nüöÄ SUBMIT ALL 3 TO KAGGLE!\")\n",
    "print(f\"\\n‚è±Ô∏è Estimated time: 15-20 minutes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
